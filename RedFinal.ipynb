{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auJ2yClw527_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats.mstats import winsorize\n",
        "from google.colab import drive, files\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar datos y dividir dataset"
      ],
      "metadata": {
        "id": "rBFpCmouf3Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.random import set_seed\n",
        "set_seed(234730)"
      ],
      "metadata": {
        "id": "iRskxHDSvIB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test_without_label.csv')"
      ],
      "metadata": {
        "id": "EDu6L8kKvMio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['id'] = train['id'].astype(str)\n",
        "train['tweet'] = train['tweet'].astype(str)\n",
        "train['label'] = train['label'].astype(str)"
      ],
      "metadata": {
        "id": "8bBGRjnTxdsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['id'], axis=1)\n",
        "train.set_index(\"id\", inplace = True)"
      ],
      "metadata": {
        "id": "XwO2hMspxjLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# parseo de category\n",
        "train[['label']] = train[['label']].apply(lambda col: label_encoder.fit_transform(col))"
      ],
      "metadata": {
        "id": "yI7GxIR9W6xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopwords, lemmatize, punctuacion\n",
        "Hay muchas palabras que estan repetidas como \"august\", \"august,\", \"august.\", \"august:\", etc. Para resolver esto vamos a sacar la punctuación antes de hacer el lemmatizer. Por ahora vamos a dejar algunos símbolos como los \"#\", quizas los hastags pueden tener información importante.\n",
        "\n",
        "Como en el órden de ejecución del CountVectorizer primero se hace el lemmatizing,  no podemos ponerlo en las stop words. Por lo tanto lo vamos a hacer en el mismo método de lemmatizing."
      ],
      "metadata": {
        "id": "fv52mEwudEkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "#analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_loc = '/root/nltk_data/corpora/wordnet.zip'\n",
        "with ZipFile(file_loc, 'r') as z:\n",
        "  z.extractall('/root/nltk_data/corpora/')"
      ],
      "metadata": {
        "id": "q_vBq9se2qMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7098a5a5-6d7a-4ff3-e811-6c876e17e935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All_punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "All_punct = '''!()-[]{};:'\"“”‘’\\,<>./?%^&*_~'''\n",
        "#CountVectorizer con stopwords de Natural Language Toolkit\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def is_Not_Link(word):\n",
        "  return word[0:4] != \"http\"\n",
        "\n",
        "def remove_Punctuation(doc_split):\n",
        "  for i in range(len(doc_split)):\n",
        "    word = doc_split[i];\n",
        "    if is_Not_Link(word):\n",
        "      for elements in word:\n",
        "        if elements in All_punct:\n",
        "          doc_split[i] = word.replace(elements, \"\")\n",
        "  return doc_split\n",
        "\n",
        "def remove_Stopwords(doc_split):\n",
        "  doc_with_Stopwords = doc_split.copy();\n",
        "  for i in range(len(doc_split)):\n",
        "    word = doc_split[i];\n",
        "    if word in nltk.corpus.stopwords.words('english'):\n",
        "      doc_with_Stopwords.remove(word);\n",
        "\n",
        "  return doc_with_Stopwords\n",
        "\n",
        "def new_analyzer(doc):\n",
        "  doc_split = doc.split();\n",
        "  doc_split = remove_Punctuation(doc_split);\n",
        "  doc_split = remove_Stopwords(doc_split);\n",
        "  return (Lemmatizer.lemmatize(w.lower()) for w in doc_split);\n",
        "\n",
        "\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV02dxaTsbyP",
        "outputId": "7229e357-70fe-480e-efc1-9973baefe390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingenieria de atributos"
      ],
      "metadata": {
        "id": "sReTyoQ6OFv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Largo del documento\n",
        "Uno de los atributos que nos interesa investigar es el largo de los atributos"
      ],
      "metadata": {
        "id": "4jN4WAX6PSh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letters = \"abcdefghijklmnñopqrstuvwxyz\"\n",
        "def contarLetras(row):\n",
        "  count = 0;\n",
        "  for letter in row['tweet']:\n",
        "    if letter in letters:\n",
        "      count = count +1;\n",
        "  return count\n",
        "\n",
        "def contarCovid(row):\n",
        "  count = 0;\n",
        "  if \"covid\" in row['tweet']:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "def contarHashtags(row):\n",
        "  count = 0;\n",
        "  for letter in row['tweet']:\n",
        "    if letter == \"#\":\n",
        "      count = count +1;\n",
        "  return count * 10\n",
        "\n",
        "emojis = \"ℹ️↗️⏺️▪️◾▶️☎️☑☺⚖️⛪✅✈✉️✔️❄️❌❌❗❤️➡➡️�🆕🆙🌍🌐🏠🏪🏥🏫👇👉👉🏾👨👩⚕️💉💊📃📈📉📍📏📢📨📺🔰🔴🔹️🕌🕐😷🙏🚶♀️🛡️🟢🤔🤱🏿🥼🧤🧪\"\n",
        "def contarEmojis(row):\n",
        "  count = 0;\n",
        "  for letter in row['tweet']:\n",
        "    if letter in emojis:\n",
        "      count = count + 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "71xXnfVT0dKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['largoDocumento'] = train.tweet.str.len()\n",
        "train['CantidadPalabras'] = train.apply(lambda row : len(row['tweet'].split()), axis=1)\n",
        "train['cantidad de letras'] = train.apply(lambda row : contarLetras(row), axis=1)\n",
        "train['cantidad de covid'] = train.apply(lambda row : contarLetras(row), axis=1)\n",
        "train['cantidad de hashtag'] = train.apply(lambda row : contarHashtags(row), axis=1)\n",
        "train['cantidad de emojis'] = train.apply(lambda row : contarEmojis(row), axis=1)"
      ],
      "metadata": {
        "id": "3dGgC6kpOX52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train / Validation\n",
        "Al final de la ingeniería dividimoms en train y validation"
      ],
      "metadata": {
        "id": "lJcxI3B8Pv7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
        "    train.drop('label', axis=1),\n",
        "    train['label'],\n",
        "    test_size=(1.0/3), random_state=42)"
      ],
      "metadata": {
        "id": "FXppDGXJxsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit"
      ],
      "metadata": {
        "id": "1Sqi2438Ibd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_IDF_Vectorizer = TfidfVectorizer(analyzer=new_analyzer, max_features=15000)\n",
        "bag_of_words = TF_IDF_Vectorizer.fit(X_train[\"tweet\"])\n",
        "\n",
        "print(bag_of_words.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aBmH9uJtACD",
        "outputId": "d2d58135-9ed2-4b90-9c1f-998a741d73d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '!', '\"[the', '\"akira', '\"chaotic\"', '\"covid-(1).', '\"covid19', '\"exterminated\"', '\"heres', '\"hoax\"', '\"huge', '\"hydroxychloroquine', '\"im', '\"in', '\"its', '\"negative\"', '\"plandemia\"', '\"reclassified\"', '\"sarscov2', '\"selfdiagnostic', '\"this', '\"vaccine\"', '\"well', '\"weve', '\"yes', '#', '##3600mg', '#1', '#2', '#2020presidentialelection', '#21dayschallenge', '#21dayslockdown', '#251', '#46', '#a', '#ableg', '#achristmascarol', '#acog2020', '#active', '#activecases', '#actnow', '#acuteflaccidmyelitis', '#afaracare', '#afoolat60', '#ahmedabad', '#airline', '#aliens', '#allergies', '#alllivesmatter', '#alzheimers', '#amazon', '#america', '#amitabhbachchan', '#andhrapradesh', '#anteater', '#antibiotics', '#aoc', '#apocalypse', '#appeal', '#area', '#arrestfauci', '#arrestgates', '#arunachalpradesh', '#arvindkejriwal', '#asco20', '#ashas', '#asians', '#asymptomatic', '#athens', '#auspol', '#autism', '#autoimmune', '#avifavir', '#aworldindisorder', '#azimpremji', '#backtoschool', '#bacteria', '#bailout', '#bankerhaipolicenahi', '#baptism', '#barackobama', '#baseball', '#basketball', '#beatncds', '#beer', '#bengali', '#berniesanders', '#be…', '#bharatbiotech', '#bigpharmapuppets', '#bihar', '#binaxnow', '#bioweapon', '#boycottchineseproduct', '#boycottmadeinchina', '#breakfast', '#breakin', '#breaking', '#breakinghot', '#breastfeed', '#bronxzoo', '#brooklyn', '#buddhism', '#bulls', '#burgerking', '#burglars', '#burrgate', '#business', '#c19', '#california', '#californ…', '#canada', '#cancelcacsexams', '#cancer', '#cardiotwitter', '#caregivers', '#carona', '#cases', '#cashewchicken', '#ccc19', '#ccp', '#ccpvirus', '#cdc', '#cdcgrandrounds', '#cdctravelnotice', '#cdnpoli', '#cdntv', '#celebrities', '#cerb', '#chandigarh', '#charleslieber', '#cheating', '#chennai', '#chenqiushi', '#children', '#china', '#china@drtedros', '#chinacoronavirus', '#chinaindiafaceoff', '#chinese', '#chinesecommunistparty', '#chinesevirus', '#chloroquine', '#christmas', '#cia', '#classof2020', '#clinicaltrials', '#clinicians', '#codecheck', '#coevolution', '#coexistence', '#colorado', '#computers', '#connecticut', '#conspiracy', '#conspiracytheories', '#contacttracing', '#containmentzones', '#convalescent', '#cornavirusfacts', '#corona', '#coronabeer', '#coronacheck', '#coronainpakistan', '#coronaoutbreak', '#coronaupdate', '#coronaupdates', '#coronaupdatesindia', '#coronaupdatesinindia', '#coronavacccine', '#coronavaccine', '#coronavirus', '#coronavirus.', '#coronaviruscanada', '#coronavirusfacts', '#coronavirusincontext', '#coronavirusindia', '#coronaviruslockdown', '#coronavirusoutbreak', '#coronaviruspandemic', '#coronavirustruth', '#coronavirusupdate', '#coronavirusupdates', '#coronavirususa', '#coronavirus…', '#coronawarriors', '#coronawatch', '#coronil', '#corononavirus', '#coronovirus', '#corruption', '#covax', '#covaxin', '#covaxine', '#covid', '#covid-19', '#covid19', '#covid19.@drtedros', '#covid19@drtedros', '#covid19affected', '#covid19asserts', '#covid19associated', '#covid19india', '#covid19like', '#covid19my', '#covid19nc', '#covid19nigeria', '#covid19nz', '#covid19pakistan', '#covid19pandemic', '#covid19related', '#covid19science', '#covid19toronto', '#covid19updates', '#covid19vaccine', '#covid19…', '#covid1…', '#covid2019', '#covid_19', '#covidactnow', '#covidcanada', '#covidindiaseva', '#covidlockdown', '#covidpandemic', '#covidstopswithme', '#covidtesting', '#covidupdate', '#covidupdates', '#covidview', '#covidwarriors', '#covidwarriortips', '#covid…', '#covidー19', '#covidー19…', '#cowurinesteambar', '#cpd', '#criminals', '#crook', '#cruise', '#cruiseships', '#cure', '#curfewinindia', '#dallascowboys', '#data', '#datoscoronavirus', '#day2lockdown', '#dearicaitake', '#death', '#defense', '#delhi', '#delhifightscorona', '#dementia', '#democrats', '#denmark', '#dexamethasone', '#dialysis', '#diapers', '#dictatorship', '#disease', '#diseasedetective', '#disinfectant', '#disney', '#dna', '#domesticviolence', '#donaldtrump', '#doortodoordeworming', '#doublingrate', '#doyourpart', '#dranthonyfauci', '#drugs', '#duckdynasty', '#dyk', '#ears', '#easyoff', '#ebolavirus', '#echinacea', '#economy', '#eha2020', '#eidaladha', '#elonmusk', '#endtb', '#epass', '#epidemic', '#erscongress', '#esccongress', '#essentialworker', '#eular2020', '#evin', '#evinindia', '#exercise', '#facebook', '#facecover', '#facemask', '#facemasks', '#factcheck', '#factchecking', '#factsmatter', '#fake', '#fakenews', '#fakenewsalert', '#fakenews�', '#families', '#family', '#famine', '#fangbin', '#faq', '#fatality', '#fatalityrate', '#fauci', '#favipiravir', '#fbi', '#fda', '#febreeze', '#feelbetter', '#feeling', '#fidelcastro', '#fightagainstcoronavirus', '#fightflu', '#firefighters', '#fitness', '#flattenthecurve', '#flight', '#florida', '#flu', '#foghornleghorn', '#food', '#foodsafety', '#foodshortages', '#footballamerican', '#ford', '#fourthofjuly', '#foxnews', '#freedom', '#friendship', '#fullyimmunizeeverychild', '#fun', '#gandhinagar', '#gaumutr_steaming', '#gautambuddhnagar', '#germs', '#ghaziabad', '#globalwarming', '#god', '#godelhiites', '#goingbust', '#golf', '#government', '#governor', '#goyabeans', '#grafitti', '#great', '#greece🇬🇷', '#groupies', '#gujarat', '#gujaratcoronaupdate', '#gurugram', '#guyana', '#hairstylist', '#hallmark', '#hamburger', '#hands', '#handwashing', '#hantavirus', '#harrymaguire', '#harvarduniversity', '#haryana', '#hcp', '#hcps', '#hcq', '#health', '#healthcare', '#healthequity', '#healthforall', '#healthoverexams', '#healthworkers', '#healthy', '#healthylife', '#heartattacks', '#heat', '#heidiklum', '#heneryhawk', '#himachalpradesh', '#hit2equity', '#hitsolutions', '#hiv', '#hoarding', '#hockey', '#hollywood', '#homeisolation', '#homelessness', '#homemade', '#homeopathic', '#homequarantine', '#hongkongs', '#howwehospitalist', '#huaweiwatchgt2', '#hurricane', '#hurricanelaura', '#hydroxychloroquine', '#hypertension', '#ibs', '#icairespondnow', '#icmrfightscovid19', '#icu', '#igot', '#illegalimmigrants', '#immunesystem', '#immunity', '#immunitybooster', '#immunizationforall', '#impeachment', '#importantinformation', '#incontext', '#india', '#indiafightscirona', '#indiafightscorona', '#indiafightscoronavirus', '#indiafightscovid19', '#indiawillwin', '#india…', '#indigo', '#infections', '#inflammation', '#ingenuity', '#institutionalquarantine', '#introvert', '#ireland', '#irony', '#istandwithmashpee', '#italy', '#iud', '#jamalkhashoggi', '#japan', '#jaredkushner', '#jarkhand', '#jennymccarthy', '#jharkhand', '#jlo', '#jobs', '#johntravolta', '#josephbiden', '#journalist', '#kag', '#kano', '#karakaxlist', '#karnataka', '#karnatakas', '#kayburley', '#keeppushing', '#keithholdskeytovirusvaccine', '#kerala', '#kidneytransplant', '#kids', '#killingvirus', '#kishanganj', '#kitchen', '#knowthefacts', '#kolkataairport', '#laborday', '#lachupacabra', '#lakshadweep', '#language', '#laura', '#lcsm', '#lego', '#lgbtquarantine', '#lies', '#life', '#list', '#livelife', '#lockdown', '#lockdown2', '#lockdown21', '#lockdown4', '#lockdownextension', '#lockdownnow', '#lockdownquery', '#london', '#louisiana', '#lucknow', '#lysol', '#madhyapradesh', '#maga', '#maga�', '#maharashtra', '#maharastra', '#mailinvoting', '#mainbhinewschecker', '#majorleaguebaseball', '#malaria', '#malnutrition', '#malpractice', '#manafort', '#manipur', '#marchmadness', '#marijuana', '#mascot', '#mask', '#maskingforafriend', '#maskonnaija', '#masks', '#mauritius', '#mayans', '#meat', '#media', '#medical', '#medicaldoctor', '#medicines', '#medtwitter', '#mentalhealth', '#mergecaexamsjulyandnov', '#metformin', '#metro', '#metrobackontrack', '#mexico', '#michigan', '#minnesota', '#miraclesoftrueworship', '#missiles', '#missionkarmayog…', '#mitchmcconnell', '#mizoram', '#modicovidaddress', '#modigovtfailed', '#modijipostponejeeneet', '#money', '#moneylaundering', '#morningmotivation', '#mother', '#mouthwash', '#movies', '#mrna', '#msvirtual2020', '#mumbai', '#muradabad', '#n95', '#nagpur', '#nails', '#nancypelosi', '#napoleon', '#nashville', '#nba', '#ncdclabnetwork', '#ncdcrrt', '#ncdcteam', '#ncdhhs', '#ncpol', '#nepotism', '#newhampshire', '#news', '#newschecker', '#newsinphoto', '#newssatire', '#newyork', '#newyorkcity', '#newyorktimes', '#newzealand', '#nhl', '#nigeria', '#nigerian', '#nigerians', '#noahsark', '#noida', '#norway', '#notdying4wallstreet', '#notmypresident', '#novel', '#nursinghome', '#nyc', '#obamagate', '#obesewomen', '#oct1stprotest', '#odisha', '#odishafightscorona', '#office', '#officialsecretsact', '#ohio', '#olympicgames', '#online', '#onpoli', '#opthalmology', '#orlando', '#oslo', '#panamacanal', '#pandas', '#pandemic', '#panic', '#panicbuying', '#parasites', '#parent', '#parents', '#patientzero', '#pcrtest', '#peepingtom', '#philrobertson', '#physicaldistance', '#physique', '#pibfactcheck', '#placebopills', '#plandemic', '#plasmatherapy', '#plastic', '#pmqs', '#poker', '#politicalcorrectness', '#politicians', '#politics', '#pope', '#potsales', '#potus', '#ppe', '#prep', '#prescriptions', '#preventcovid19', '#prevention', '#prioritycovidresearch', '#privacy', '#propaganda', '#property', '#prostatecancer', '#ptfcovid19', '#pti', '#pui', '#qanda', '#quarantine', '#queens', '#rackets', '#rajahthan', '#rajasthan', '#rapidantigentest', '#rc70afro', '#recession', '#recoveryrate', '#religion', '#remdesivir', '#remedy', '#rentfreezenow', '#reopeningsafely', '#reopensafely', '#republicans', '#research', '#revolutionnow', '#rheaarrested', '#rice', '#richardnixon', '#ridge', '#rnc2020', '#roadtrips', '#rockandrollvaccine', '#rollingstones', '#rollingstonevaccineforcv', '#rpharmcoronavir', '#rtpcr', '#russia', '#russiaeverywhere', '#russianvaccine', '#russie', '#sacrifice', '#safe', '#safetyfirst', '#sally', '#sam2020', '#santa', '#sarscov2', '#satire', '#saturdaynightfever', '#saudiarabia', '#school', '#schoolsreopening', '#schwabeindia', '#science', '#seanhannity', '#selfcare', '#selfisolation', '#sens', '#sepsis', '#sex', '#sexyteens', '#share', '#sheep', '#sickness', '#simoncowell', '#sitamarhi', '#slowthespread', '#smallpox', '#smartnews', '#socialdistance', '#socialdistancing', '#sofi2020', '#sofiavergara', '#southcarolina', '#southdelhi', '#spain', '#spokesman', '#sponsors', '#sport', '#sports', '#springst', '#sputnikv', '#stayalert', '#stayathome', '#stayathomesavelives', '#stayhealthy', '#stayhome', '#stayhomestaysafe', '#staysafe', '#staystrong', '#std', '#stds', '#stevenseagal', '#stimuluschecks', '#stop', '#stopthespread', '#stopthespreadofcorona', '#strategicreserve', '#stress', '#strokes', '#suicide', '#summer', '#sunbathing', '#swasthabharat', '#swedish', '#symptomatic', '#t1d', '#takeaction', '#takebreaks', '#takeresponsibility', '#takeresponsibilty', '#tamilnadu', '#tan', '#tb', '#teamoffivemillion', '#tech', '#telangana', '#telemedicine', '#televangelist', '#telugunews', '#teravolt', '#testing', '#tests', '#texas', '#thailand🇹🇭', '#thane', '#thankshealthheroes', '#thedevil', '#thenewnormal', '#thesun', '#thewiderwiserview', '#tigers', '#time', '#tipsadvice', '#togetheralone', '#toilet', '#toiletpaper', '#toiletrollhorders', '#tomhanks', '#travel', '#trinitybellwoodspark', '#tripura', '#trophywife', '#trump2020', '#trumpcouldhavesavedvalet', '#trumppressconf', '#trumpsjealousofobama', '#trumpuniversity', '#tsunami', '#tuberculosis', '#tuesdaylive', '#tuesdaymotivation', '#tulsatrumprally', '#tv', '#tīmarimamiriona', '#ufo', '#uighurs', '#un75', '#unemployment', '#unga', '#unitednations', '#unlock1', '#unlock2', '#unlock3', '#unlock3guidelines', '#unlock4', '#unlock4guidelines', '#unlock4👇', '#update', '#uruguay', '#usa', '#uttarpradesh', '#uva', '#uvc', '#uvdisinfection', '#uvlamp', '#uvled', '#uvlight', '#uvsolution', '#vacation', '#vaccine', '#vaccines', '#vaccineswork', '#vadodara', '#vegan', '#vermont', '#vicepresidentmikepence', '#vicpol', '#viral', '#viralvideo', '#virtualconferenceafrica', '#virus', '#viruses', '#visualabstract', '#vitamind', '#vladimirputin', '#war', '#warcrimes', '#warning', '#warnings', '#washington', '#waterpistols', '#wear', '#wearamask', '#wearamask…', '#weather', '#weneedthedenominator', '#westbengal', '#westvirginia', '#wha73', '#wha74', '#whatsapp', '#whitehouse', '#whitesupremacy', '#who', '#whoimpact', '#wildfire', '#wildfires', '#williambarr', '#williambryan', '#woodwardtapes', '#work', '#workfromhome', '#worldbreastfeedingweek', '#worldmaskweek', '#worldmosquitoday', '#worldzoonosesday', '#worried', '#wor…', '#wtd20', '#wuhan', '#wuhancoronavirus', '#wuhaninstituteofvirologylaboratory', '#wuhanviruspandemic', '#xijinping', '#yavatmal', '#yourviewtv', '#zhangzhan', '#zoodirector', '#張展', '#陳秋實', '$$', '$1', '$1+', '$100', '$1000', '$10000', '$100b', '$1200', '$17', '$17500', '$2000', '$200m', '$225+m', '$2340', '$25', '$26000', '$2m', '$3', '$340', '$37', '$370', '$38', '$3800000', '$4', '$451', '$472', '$5', '$5$100', '$50', '$54', '$61', '$63400', '$700', '$750', '$7trn', '$8', '$abt', '$millions', '&amp', '&amp;', '&gt', '&gt&gt&gt', '&gt65', '&gt;3000day', '&gt;60', '&gt;70', '&gt;70%', '&lt1', \"'false'\", \"'gam-covid-vac'\", \"'usgovernment\", '(!', '(#makhi', '(#pmsby', '(*', '(...', '(0.5%', '(0.6%', '(1.6%', '(1.60%', '(1.62%', '(1.7', '(1.7%', '(1.8%', '(1.9%', '(1/10', '(1/2', '(1/3', '(1/4', '(1003299', '(1008', '(1009976', '(1010824', '(1013964', '(1046470)', '(1172179', '(1178)', '(12.3%', '(12k+', '(13%', '(134)', '(1341', '(1427', '(147', '(164%)', '(17.54%', '(18.3%', '(18.7%', '(19.52%', '(19.7%', '(19423', '(2.3%', '(2.8', '(2/2', '(2/3', '(2/4', '(20.4%', '(20.5%', '(20.6%', '(20.7%', '(207%)', '(21.0%', '(21.2%', '(21.3%', '(21.9%', '(22.2%', '(22.3%', '(22.9%', '(23%', '(24.4%', '(2523771', '(2648998', '(267)', '(2713933', '(2774801', '(2970492', '(3.3%', '(3/4', '(3/5', '(3015103)', '(3107223', '(3180865', '(32-year-old)', '(326971', '(34.5%', '(3542663', '(3702595', '(3859399', '(3942360', '(4.5-5.5%)', '(4/4', '(4/5-4/6', '(4/8', '(4025079', '(4208431', '(4303043', '(4396399', '(4497867', '(4587613', '(4674987', '(48.45%', '(48.8%', '(52k', '(568', '(5735', '(580', '(59k', '(60472', '(60k)', '(62550', '(63498', '(64469', '(65k', '(6680', '(67376', '(69561', '(6pm', '(70.40%', '(70.72%', '(704348', '(70626', '(713k', '(71k)', '(725991', '(74.21%', '(74.85%', '(74.91%', '(7406', '(75.3%👍', '(75.34%', '(75.65%', '(75.9%👍', '(752424', '(758k', '(75k', '(76.2%', '(76.3%👍', '(76.81%', '(76.9%👍', '(76271', '(765302', '(77.07%', '(77.1%👍', '(77.2%👍', '(77.6%👍', '(77.8%👍', '(77.9%👍', '(77k', '(78.0%👍', '(78.6%👍', '(78.9%', '(781975', '(78586', '(79.28%', '(79.7%👍', '(80.1%👍', '(80.86%', '(80776', '(815538', '(82066', '(83198', '(831k', '(846395', '(85.92%', '(852k', '(85619', '(862320', '(86752', '(87882', '(88935', '(899864', '(90020', '(943480', '(9628', '(966382', '(968377', '(972)', '(973175', '(975861', '(990061', '(995933', '(@icmrdelhi', '(a', '(ace2)', '(act', '(afm', '(aiims', '(allegedly', '(antibody', '(antigens', '(asymptomatic', '(asymptomatic)', '(avg', '(bad', '(bad)', '(barcelona', '(bcg', '(brazil)', '(bribe', '(california', '(cbac', '(cccs)', '(centre', '(cfr', '(china', '(co-payment', '(comedk)', '(congress', '(cont.', '(continued', '(controversial', '(coronavirus', '(covid', '(covid-19', '(covid-19)', '(cow-dung', '(cow-urine', '(dcgi', '(deaths', '(dma', '(dmk', '(dtp3', '(eamc)', '(eg', '(epic', '(fbi', '(fda', '(georgia)', '(good', '(good)', '(have', '(health', '(hyderabad)', '(hydroxychloroquine', '(icmr', '(ie', '(iebc', '(ihip)idsp', '(india', '(india)', '(india)s', '(infected1', '(infected2', '(ipc)', '(is', '(italy', '(jan', '(japan)', '(kirklandwa)', '(la', '(lagging', '(me/cfs', '(meat', '(mha', '(mis-c', '(missouri', '(morning/night', '(mrna-1273', '(murcia', '(newsom', '(nhs', '(nigella', '(night', '(niv)', '(note', '(ohio', '(pa', '(pakisthan', '(pbcom', '(pheoc', '(pheoc)', '(picture)', '(plasvirec', '(pmjjby', '(pmnrf', '(pmsby', '(pna', '(ppe)', '(pre-symptomatic', '(quicktake', '(rat', '(rdrp', '(rrt', '(rss', '(rsv', '(sars', '(sars-cov-2', '(sdsm', '(sic', '(sic)', '(sii', '(sp', '(today', '(tpm', '(ttsi', '(uae)', '(up)', '(wef', '(who', '(who)', '(who).', '(yesterday', '(yet', '(~60k)', '(~8%', ')', '*demand*', '*next', '+', '+1', '+10000', '+40%', '+91-85078-85079', '+ozone', '+ve', ',pope', '--&gt', '-11', '-32', '-37', '-400', '-50', '-68', '-@alexismadrigal.', '-japan', '.', '..', '...�', '.?', '.@mohfwindia', '0', '0.054', '0.06', '01', '0106', '01072020', '014', '02', '03', '03323412600', '04', '0400', '05', '0528', '06', '062454254', '0625', '063661060', '06512490104', '07', '0700', '0710', '075', '079', '08', '0800', '0805', '082', '085', '0881911', '09', '0900', '0910', '0920', '0930', '093020408', '0940', '0950', '0…', '1', '1%', '1.25', '1.4', '1.64', '1.70', '1.70%', '1.75', '1.82', '1.84', '1.94%', '1/2', '1/26', '1/4', '1/5th', '10', '10%', '10,000', '10.5l', '10.6', '100', '100%', '100+', '1000', '1000+', '1000/', '10000', '10000+', '100000', '100000+', '1000000', '10001100000', '1000190000', '100046', '1000bed', '1002', '1003299', '100407', '1006615', '1008', '1009976', '100bed', '100k', '101', '1010', '1010824', '1013', '1013refund', '101468', '1015', '10162', '1016920', '1017754', '1018', '101951', '102', '1022', '1023', '1040', '105', '1054', '1061', '107', '1076', '10k', '10m', '10pm', '10th', '10x', '11', '1100', '110000', '111', '1115', '1120', '1125', '113', '1130', '1130pm', '114', '115', '115000', '1154', '1155pm', '1159', '116', '117', '1170', '1172', '1176', '1178', '118', '1184', '119', '1192', '1194', '11fct', '11th', '12', '120', '12000', '120000', '1206', '1217', '1219', '123', '1249', '125', '126', '1261', '128', '129', '12sokoto', '12story', '12th', '12yobe', '13', '13.7', '130', '130000', '130792', '130billion', '131', '1315', '1316', '13175', '131lagos', '132', '1320', '1326', '133', '1339', '133lagos', '134', '13419', '1344', '13447', '135', '135000+', '1351', '1353', '135k', '1363', '1365', '1366', '13671', '1368', '137', '1371', '137385', '1376', '1378\\u200b', '137k', '138', '1380', '138521', '138k', '139', '13989', '139lagos', '13borno', '13kaduna', '13m', '13ogun', '13plateau', '13th', '13yobe', '14', '14.3', '140', '1400', '14000', '140000', '140000+', '1401', '1408', '140k', '1411', '14139', '1416', '142', '1421', '1425', '1428', '143', '143000', '1431', '1433', '1441', '1442', '1444', '145', '1455', '1481', '14day', '14plateau', '14th', '14yearold', '14zamfara', '14–29', '15', '15+', '15.9', '150', '1500', '15000', '150000', '15001100000', '15001110000', '1503', '1504', '15042', '1504\\u2063', '151', '1510', '1519', '152020', '1524', '1529', '152k', '1530', '153118', '153504', '1535743', '154', '155', '15500', '1551', '1556138', '15568', '155k', '156', '15604', '1561', '157', '1573159', '158', '158)', '15882', '15th', '16', '160', '16151', '167', '16th', '17', '170', '174', '176', '179', '17th', '18', '18009855990', '182', '18371', '184', '1874', '188', '189', '18th', '19', '190', '19000', '192', '195', '197', '1981', '19th', '19zamfara', '1adamawa', '1bauchi', '1bayelsa', '1enugu', '1kebbi', '1m', '1ondo', '1oyo', '1plateau', '1pm', '1sokoto', '1st', '1zamfara', '1…', '1⃣', '2', '20', '20%', '200', '2000', '20000', '200000', '2001', '2001.', '2003', '2004', '2005', '2008', '2009', '200k', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2020👇', '2021', '2022', '2027', '204', '20k', '20th', '21', '210', '21000', '214', '2159', '219', '21k', '22', '2200', '221', '223k', '22k', '22nd', '23', '232', '233', '238', '23k', '23rd', '24', '2400', '2404585', '24077', '24106535', '242', '2425', '243838\\u2063', '244', '245', '2450', '24545', '2461190', '246216', '2467758', '247', '2473', '2481', '249', '249%', '2490125', '2490127', '2490128', '2492', '2497', '24h', '24hrs', '24k', '24ogun', '24th', '24x7', '24×7', '24\\u200b', '24…', '25', '25%', '25%\\u200b', '25.', '25.7', '250', '2500', '2500+', '25000', '2500000', '252', '2523771', '253%', '253190', '2540', '254000', '25574', '2558', '2560', '25694', '2570', '2575', '2583948', '25edo', '25k', '25ogun', '25th', '26', '26-27c', '26000', '260k', '261', '2621', '263156', '2635', '2644', '2647663', '2649', '265', '265k', '266', '266796', '26685', '267', '267435', '268', '26802', '26845688', '269', '2697', '2699', '26th', '27', '27-04', '27.3', '270', '2700', '27000', '270000', '2702742', '27110', '271690', '27287', '273', '2733', '2736', '27450', '2746', '2756', '27564', '276', '27694416', '278872', '2789', '279', '2792', '2794', '27th', '27—with', '28', '28%', '28000', '281', '2816', '281609', '282', '282263', '282511', '2839882', '285', '28500', '2856', '28615', '286174', '2867', '2868', '287', '28711', '288', '289%', '2893', '28edo', '28k', '28kano', '28oyo', '28th', '28yearold', '29', '29.', '29.64', '2900', '29000', '291994', '292000', '2922', '29286', '294', '294k', '2950', '296', '29648', '29676', '29687', '2970492', '29879', '299', '29k', '29kano', '29th', '29yearold', '2adamawa', '2akwa', '2anambra', '2bauchi', '2brilliant', '2delta', '2edo', '2enugu', '2gombe', '2if', '2inches', '2k', '2kwara', '2m', '2nasarawa', '2nd', '2ndlowest', '2niger', '2ondo', '2pm', '2rivers', '2stay', '2x', '2yobe', '2\\u200b', '2…', '3', '3%', '3.2', '3.3', '3.33', '3.5', '3.5%', '3.7', '3/10/20', '3/11', '3/17/20.', '3/23/20', '30', '30%', '30.06.2020', '300', '3000', '3000-4000day', '30000', '300000', '30041400', '3007', '300k', '3020', '30249', '302k', '303000', '3035', '3037151', '303k', '3044940', '3048%', '3051', '306', '3067', '307', '30748', '30920', '30941264', '30c', '30k', '30kano', '30second', '30th', '31', '31.03.2021_', '31.37', '3105', '3106348', '3107223', '311', '311121', '31142', '3122', '313', '313000', '3140', '3145', '315', '31520', '31585', '3167323', '317', '3172319b1', '318', '318k', '3194', '31k', '31oyo', '31st', '32', '3200', '32020', '321', '32165', '322', '323', '3234474', '324', '32430', '325', '32558', '328', '328%)', '329', '32kano', '33', '33%', '33%world', '330', '3300', '3310234', '331146', '33153', '33186', '3319', '332', '333', '3330', '3343', '3354', '3359', '33620', '337', '338', '3387500', '3387948', '339', '3395', '3398844', '33yr', '34', '340', '34000', '342', '343', '34309', '3445', '345', '34654', '347', '348822', '34k', '34oyo', '35', '35%', '35.5', '350', '3500', '35000', '35001', '3526', '35292220', '3535', '354', '3542663', '355', '3573', '358', '358%', '35840', '3590', '35902137', '35998', '35jigawa', '35k', '36', '360k', '361', '362', '3624196', '363', '364', '366', '36703', '36827520', '36834', '368432\\u2063', '3691166', '3696', '36985', '36l', '37', '3701', '3702595', '3703', '3704', '371', '371125', '373', '37304', '37651512', '3772', '3779', '378', '3780107', '37885', '378k', '379', '3793', '379k', '37k', '37–78', '38', '380', '380k', '381', '382', '3826', '384', '385', '3853406', '38576510', '385936', '386', '387', '387435', '389', '38945', '3899', '38k', '39', '39.�', '3912', '3918', '392', '392756', '393', '3936747', '39477848', '39539', '396', '3968', '396k', '3978', '3989', '399', '3991', '3992', '39k', '39lagos', '3abia', '3akwa', '3anambra', '3bauchi', '3borno', '3delta', '3edo', '3fct', '3kaduna', '3katsina', '3kwara', '3m', '3nasarawa', '3niger', '3oyo', '3pointers', '3rd', '3rd…', '3rivers', '3sokoto', '3ts', '3wash', '3x', '3\\u2063', '3⃣we', '4', '4-5-6%', '4.3', '4/21', '4/3', '4/4', '40', '40%', '40%.�', '400', '4000', '40000', '400000', '4003', '400500', '4006', '400k', '4014', '4019', '402000', '4023179', '4025079', '403', '404', '4040', '404k', '405000', '40532', '407', '409032', '40k', '41', '410', '4112551', '411932', '41297', '414', '4140', '415283', '41552', '416', '41638', '416924', '417', '41804', '418810', '41k', '42', '420', '420k', '4211\\u2063\\u2063\\u2063\\u2063', '422000', '42208', '4225', '42307914', '4236', '424719', '4249', '425', '4255', '4261', '426776', '42689', '427', '4279', '428', '42922', '429643', '429664', '42k', '43', '430', '430-700', '4300', '43000', '4303', '4303043', '43151', '4322', '43231', '43324834', '43334', '433k', '435', '43537', '436', '43610', '4367436', '437', '4370128', '438', '4384', '438720', '4396', '4396399', '43998', '43k', '43lagos', '44', '44000', '44035', '44088', '44129', '441k', '4420', '4422', '44430', '4453', '4468', '44890', '44jigawa', '44k', '45', '450', '4500', '45000', '452', '45244', '4530', '453923', '453k', '454', '455', '45509380', '4560', '456227', '4562414', '4563', '457', '457377', '457k', '4589', '45k', '46', '460', '4600', '460067', '46121', '46131', '4619', '461k', '462', '462590', '4641', '46577', '4659984', '465k', '46679145', '4687', '469', '46kano', '47', '4700', '470469', '4735', '475', '4752', '4754356', '475k', '477909', '47872', '47980', '47k', '48', '48000', '481', '48116', '484', '484068', '48431', '48445', '4846427', '485', '486', '48674', '486943', '487', '4889', '48900', '48k', '49', '490', '49000', '4911/140293', '4926', '4927', '492k', '494481', '49485', '49551507', '496k', '497', '499', '49k', '49katsina', '4adamawa', '4am', '4bauchi', '4borno', '4c', '4ebonyi', '4ekiti', '4imo', '4jigawa', '4kaduna', '4nasarawa', '4niger', '4ogun', '4pm', '4pmet', '4sokoto', '4th', '4x', '5', '5%', '5.4', '5/2', '5/24', '5/31', '50', '50%', '500', '5000', '50000', '50000+', '500000', '500k', '500th', '501', '5020', '502705', '503', '50488', '5057', '506', '5080', '508k', '50k', '50–64', '51', '51(b', '510', '51000', '5118253', '511k', '5126', '51304', '5136', '5162', '517', '51706', '5178', '518', '518k', '519', '519388', '5194', '52', '5214677', '522', '5220', '52227', '523', '5246', '525', '525430', '528', '52934433', '52k', '53', '53%', '5300', '5302', '5313', '5321', '533', '534', '53879', '53k', '54', '5400619', '54008', '541', '5417', '542', '5423', '544', '5445', '54587', '5487580', '54905', '54k', '54m', '55', '550', '55000', '550000', '55160', '553', '5542', '55456', '555', '556', '55632', '558', '55k', '55kano', '56', '560', '56017', '561', '56110', '56177', '5621', '5623', '563000', '56383', '56478', '566', '56604', '567', '569k', '56k', '57', '571', '57145', '572', '57239428', '5731', '5734', '57437', '575', '57542', '5783', '57937', '57k', '58', '582020', '58390', '584k', '586k', '587', '58lagos', '59', '590', '5900', '591', '591k', '593', '59449', '595', '5955', '5959', '5967', '598778', '5adamawa', '5day', '5fct', '5g', '5gombe', '5k', '5kaduna', '5katsina', '5kebbi', '5ogun', '5oyo', '5plateau', '5th', '5x', '5years', '6', '6%', '6+', '6,114.�', '6.5', '6/14', '6/21', '6/7', '60', '60%', '60.77', '600', '6000', '60000', '60091', '600k', '600pm', '600…', '601', '60177', '603k', '60472', '606', '60710', '609917', '61', '610', '611', '6113', '611k', '613', '6136', '61529', '61572343', '616', '61700', '6178', '618k', '619', '619088', '62', '62.86', '620000', '621400', '62282', '624', '62538', '626', '626667', '627', '628', '6286%', '6297', '62k', '62l', '63', '63.8', '6307', '631', '63231', '635', '636', '63631', '637', '6370', '637k', '63k', '64', '640', '640000', '6401', '6423', '643k', '645', '646400', '648k', '64k', '64kano', '65', '65+', '65000', '65081', '65288', '654', '656', '6568', '6581', '658k', '65k', '66', '66.31', '661', '663', '664949', '665', '66500', '66550', '6666', '667', '66746', '669', '6698', '66k', '67', '6704', '6718', '6730', '67376', '675', '675k', '6762%', '677422', '68', '68%', '68.32', '68.78', '680', '68000', '680000@drtedros', '681k', '684', '68584', '6879', '689', '69', '690', '692k', '6938', '694k', '695', '69561', '696k', '697070', '6borno', '6ft+', '6gombe', '6jigawa', '6k', '6k+', '6months', '6ogun', '6oyo', '6plateau', '6pm', '6th', '6th.�', '6⃣', '7', '7%', '7.5', '7.7', '7/23', '7/9', '70', '70%', '70.38', '700', '7000', '70000', '700000', '700087', '70009000', '700k', '7016', '704348', '705am', '707267', '7077', '7091', '70cr', '70k', '71', '710', '7103', '710771', '7109', '710am', '7126', '713—this', '714', '7150', '7153', '716', '716k', '717pm', '719320\\u200b', '719364', '72', '720', '720362', '720k', '7211', '721k', '724k', '725991', '7261', '7283', '7287', '73', '73.18', '73000', '731k', '732835', '733449', '7338', '733k', '735704', '735k', '737', '73890', '73923', '739k', '73k', '74', '740', '740321', '74082', '740k', '742023', '74270', '743k', '744', '745', '746', '749k', '75', '75%', '75.27', '75.92', '75.92%', '7500', '75000', '750808', '7526', '758', '76', '76.28', '76.30', '76.47', '76.94', '76.98', '7617', '76271', '7628%', '762k', '763k', '764', '766626', '766k', '769k', '77', '77%', '77.32', '77.65', '77.74', '772k', '77472', '775', '777k', '779', '78', '78%', '78.28', '78.64', '78.86', '780000', '78343', '78586', '785996', '79', '79.1', '79.68', '79000', '7950', '796', '79722', '798k', '7borno', '7day', '7fct', '7k', '7kaduna', '7kwara', '7ogun', '7pm', '7taraba', '7th', '8', '8-20', '8.4', '8.5', '8.81', '8.84', '8.89', '80', '80%', '80%\"', '80.', '80.86%', '800', '8000', '8000+', '80000', '800000', '800k', '803552', '8068', '807460', '80789', '81', '81.25', '81000', '81533', '815538', '818629', '819k', '82', '821', '82287', '823992', '824', '82961', '82lagos', '83', '8300', '8303', '8316', '83198', '83311', '83347', '8344', '83600', '836k', '837', '839467', '83and', '84', '840k', '84372', '845', '846278', '846395', '848420', '84k', '85', '85%', '85000', '85000+', '855', '856k', '857258', '858', '85859', '8599', '86', '86.7%', '86073', '8625', '863', '864469', '86508', '867', '8671', '86752', '868', '86927', '86961', '87', '87000', '872', '873', '87374', '87604', '878', '87882', '879', '88', '883', '8838', '884%', '889', '88lagos', '89', '8953', '896', '897', '89706', '897394', '89746', '897k', '8am', '8borno', '8gombe', '8kano', '8katsina', '8kwara', '8niger', '8oyo', '8pm6am', '8th', '9', '9&amp12', '9,210.�', '9-12', '9-17-2020', '9.8', '90', '900', '900-1130', '9000', '90000', '90000+', '900185000', '901', '902', '903k', '909', '91', '910', '910853', '911', '91261', '916', '9178', '92', '924000', '924637', '924998', '925383', '9257', '927', '9286)', '93', '930', '9302', '930k', '930pm', '934', '94', '941', '943480', '94352', '944854', '945', '9470', '95', '951', '95735', '958316', '95l', '95lagos', '96', '96.3', '960', '963', '966', '968', '97', '973', '973175', '9746', '977', '978500', '97k', '98', '981', '985', '9855', '986598', '986k', '99', '99%', '99.2', '99.7', '99.9', '99031', '990deduction', '99104', '996', '998', '9991', '9am', '9borno', '9ebonyi', '9fct', '9kaduna', '9katsina', '9ogun', '9oyo', '9rivers', '9th', '9th16th', '=', '=89700000', '?', \"?'s\", '??', '???clearly', '???covid19', '???dr', '???ive', '@04051952n', '@1000frolly', '@20manny07', '@3ghtweets', '@4523i5', '@aadajoli', '@aaiofficial', '@aajtak', '@aamaadmiparty', '@aamctoday', '@abbottnews', '@abcfactcheck', '@abcmediawatch', '@abledoc', '@abpnews', '@acoss', '@adamjkucharski', '@adammccu', '@africacdc', '@aiimsnewdelhi', '@aintropy', '@airnewsalerts', '@aitonline', '@ajdlinux', '@ajenglish', '@alamerqld', '@alanlcit', '@alaskadhss', '@alcoholchangeuk', '@alexharv074', '@alexismadrigal', '@alexkx3', '@alexmahadevan', '@alikodangotefdn', '@alistairhaimes', '@alykatzz', '@amermedicalassn', '@amtrehan', '@amysherman1', '@anak2422anak', '@andrewlawrence', '@andyspecht', '@angieholan', '@angierasmussen', '@ani', '@ani_digital', '@anjan1588', '@anjanaomkashyap', '@annagconnell', '@antonioguterres', '@appalachia100', '@apple', '@aqtime', '@archillect', '@arielbogle', '@ariellesophia', '@arifleischer', '@arisetv', '@arthurcaplan', '@arvindersoin', '@arvindkejriwal', '@asantos24', '@ashishkjha', '@ashishskynews', '@ashokepandit', '@ashoswai', '@ashwinikchoubey', '@aslavitt', '@asxgold', '@atlantic', '@ayushmanhwcs', '@ballouxfrancois', '@bananenrijperij', '@bancheneproduct', '@banjelope', '@bankofamerica', '@barbarajdurkin', '@barda', '@bbcnews', '@belladonamodels', '@bendepear', '@benfordham', '@benzorn', '@bepdelta', '@bethrigby', '@bharatbiotech', '@biharhealthdept', '@billdmccarthy', '@biocomca', '@biomedj', '@bkum2000', '@blackie', '@bloombergquint', '@boomlivein', '@borisjohnson', '@brikeilarcnn', '@brittajewell', '@brknman', '@broomeinwelly', '@brucelambert', '@bsybjp', '@buffalotracedhd', '@butchthorne', '@c4etech', '@caalkeshkasliwa', '@canada', '@captshaktilumba', '@careeningspace', '@carlhan30554840', '@carlosdelrio7', '@carolhakios', '@cassandragoldie', '@cdc', '@cdc_hivaids', '@cdc_tb', '@cdcdirector', '@cdcemergency', '@cdcenvironment', '@cdcflu', '@cdcglobal', '@cdcgov', '@cdcheart_stroke', '@cdcinjury', '@cdcmmwr', '@cdctravel', '@cd…', '@cebmoxford', '@ceccgov', '@cepivaccines', '@cernovich', '@chaddystacksdfs', '@chancine', '@changeorgindia', '@channelstv', '@charliekirk11', '@chicagosmayor', '@chikwei', '@childrensphila', '@chinweochu', '@chrisfairchild', '@chrisgulli', '@chrismartenson', '@chrissytn1', '@cjtjgeol', '@climatekids2', '@cmofficeup', '@cmoguj', '@cmohry', '@cmomaharashtra', '@cmsgov', '@cnbc', '@cnbcafrica', '@cnn', '@cnni', '@cnnnews18', '@coimmunity', '@collectorjamngr', '@colleenkraftmd', '@columbiamed', '@conceptualjames', '@connectgeeta', '@conservvoice', '@contactkdsg', '@couchmaria', '@covid19crusher', '@covid19nccc', '@covid19tracking', '@covidactnow', '@covidindiaseva', '@covidnewsbymib', '@cre8d', '@cryptowalter', '@csirind', '@csogok', '@ctbergstrom', '@ctrevettnzh', '@cybertiiger', '@cyborgnot', '@dallasbarnett3', '@damienhamilto17', '@dandiemann', '@danforestnc', '@danielandrewsmp', '@danielleiwood', '@danielsierra81', '@dardedar', '@data4blacklives', '@daveman19802', '@dawntj90', '@dbaerwald1', '@dbtindiabirac', '@ddindialive', '@ddnewslive', '@deborahzinger', '@deepaltrevedie', '@dekoustav', '@delegatestewart', '@delibrolawrence', '@deplorabledebrn', '@depsechargan', '@dfiduk', '@dgpgujarat', '@dharmen46587056', '@dhscgovuk', '@dhswi', '@digdougftw', '@dlandthebeard', '@dmiliband', '@domsinainyc', '@dougburgum', '@dovmichaeli', '@dpfunke', '@dpkpillay12', '@dralisanders', '@drashwathcn', '@drccostelloe', '@drdoindia', '@drellie', '@dreoehanire', '@drharshvardhan', '@drhvoffice', '@dribram', '@drinkaware', '@drjitendrasingh', '@drjohnm', '@drjohnwhyte', '@drmamora', '@drnancym_cdc', '@drsamirbhatt', '@drsanjaygupta', '@drsourabhkp', '@drtedros', '@drtomfrieden', '@dunsanyjack', '@dwagswpb', '@dwildemuth', '@econstandard', '@edconwaysky', '@edinburghuni', '@elijahschaffer', '@ellencutch', '@elsieilori', '@elsieilorifor', '@emmawehipeihana', '@ericcolson', '@esmo', '@eucommission', '@euecho', '@factchecknet', '@factchecknets', '@faheemyounus', '@familiafeeling', '@fao', '@fatherbob', '@fauntleroy1934', '@fema', '@feynmanfreaky', '@flaxter', '@fmohnigeria', '@followlasg', '@fox5atlanta', '@foxnews', '@foxnewssundays', '@frasernelson', '@free67847229', '@ftwrharry', '@g0leary', '@g20org', '@gaonconnection', '@garnerforest', '@garysaintdooley', '@gavi', '@gavinnewsom', '@georgetown', '@geraintmeysydd', '@ghs', '@github', '@gladysb', '@globalhlthtwit', '@globaltimesnews', '@globuleaks', '@godblsmnymkr', '@govlarryhogan', '@govmurphy', '@govricketts', '@govrondesantis', '@govsisolak', '@govtofimostate', '@govwhitmer', '@gracieluann24', '@grahamscooke', '@gretchenwhitmer', '@gtg46338929', '@guardian', '@gunarockya', '@gv9195', '@g…', '@hackingdata', '@harvardgh', '@harvardmed', '@he11totheno', '@healthwiremedia', '@healthyfla', '@hedgeyedj', '@heymanitshayden', '@hhs_ash', '@hhsash', '@hhsgov', '@hmoindia', '@hollywoodcurry', '@homer4k', '@hopkinscdhs', '@hselive', '@htservadac', '@huntsonmark', '@iamadunnii', '@iammisstrees', '@ianuragthakur', '@ibergwiesel', '@icahnmountsinai', '@icmr', '@icmr_niv', '@icmrdelhi', '@icmrdelhis', '@icmrnirrh', '@icphhomeless', '@idorigatti', '@ifad', '@ihstowers', '@imdanthompson', '@imperialcollege', '@imperialem', '@imperialjidea', '@inconvenienttr5', '@independent', '@india', '@indiainguyana', '@indiatv', '@indsupremecourt', '@infointerest', '@ingrahamangle', '@iprnewsradio', '@ismmskidney', '@jabalpursafety', '@jacindaardern', '@jackwestmd', '@jamesdsteinberg', '@jamesgross', '@jbalsich', '@jburnmurdoch', '@jc1381a', '@jco_asco', '@jdeely', '@jdmaresco', '@jennymikakos', '@jhuber', '@jimcramer', '@jimdtweet', '@jjmalina', '@jmcstarbug', '@jninstitute', '@joebiden', '@joewasserman', '@johnabrahamclub', '@johnkubie', '@johnpavlovitz', '@johnshopkinsepi', '@jonashworth', '@joncraig', '@joshtpm', '@joyannreid', '@jsolomonreports', '@jsssms', '@julie34479', '@justinhart', '@justintrudeau', '@kagashley', '@kamathgurudutt', '@kanganateam', '@karluskap', '@kayburley', '@kcpubhealth', '@kctaz', '@kdhauck', '@keir_starmers', '@keirstarmer', '@kenyaphysicians', '@kevinfurr', '@kevinlyfather', '@kff', '@khaleesyd', '@khaliahhh', '@khnews', '@khoneyfordstats', '@kikimarfat', '@kitchencone', '@kitmalthouse', '@kmccready', '@kmedved', '@knsmoh', '@krisbeknowin', '@krisparag1', '@ktwopines', '@kytheanticomguy', '@lastwordwilliam', '@latimeralder', '@lbgoodnessgrows', '@lifescihiggins', '@lolageek', '@lshtm', '@lsmoh', '@lsunder1', '@ltgrusselhonore', '@luvhopecourage', '@lynnrahn1', '@madavidj', '@mahesh10816', '@malarianomoreuk', '@mamataofficial', '@mandilovell', '@mantralayaroom', '@marakont', '@marshablackburn', '@martindaubney', '@marvinbrite', '@mathguy7', '@matthancock', '@mazjobrani', '@mbiegovtnz', '@mbuhari', '@mcuban', '@medbennett', '@medscape', '@methodsmanmd', '@mexiwi', '@mhfwgoup', '@michaelmina_lab', '@michaelminalab', '@microsoft', '@midorik0a', '@mike_hixenbaugh', '@mikedel21893959', '@mikejgallant', '@minhealthnz', '@minhealthnz\\u2063', '@ministrywcd', '@mkehealth', '@mlasudhakar', '@mmaniac90', '@mmmhappiness1', '@moayush', '@mocagoi', '@modiji', '@mohfw_india', '@mohfwindia', '@mohit0175', '@moh…', '@morris1k', '@mountsinairmti', '@mrcoutbreak', '@mrdelvan', '@msisodia', '@mskatemcd', '@mumbaipolice', '@mumbaipolice@rajputramesh', '@mumbaiyb', '@munchbunch87', '@mvankerkhove', '@mybmcs', '@mygovindia', '@myogiadityanath', '@myyogiadityanath', '@n3113n', '@nagatrooper', '@narendramodi', '@narvuntien', '@nastysurf', '@nataleedesotell', '@nataliehats', '@natesilver538', '@nature', '@nbpaustralia', '@ncdcgov', '@ndgov', '@ndmaindia', '@nealkhosla', '@neil_ferguson', '@neilferguson', '@nfidvaccines', '@nickapalmer', '@nickcradio', '@nicprnoida', '@nigeducation', '@nigeriafeltp', '@nighealthwatch', '@nih', '@nihrresearchsupported', '@niosh', '@nitiaayog', '@njdeptofhealth', '@nmhheartdoc', '@no2wind', '@noahpinion', '@norcalpunkman', '@normanbrennan', '@novakglobal', '@nresearchnews', '@nsitharaman', '@ntanewsnow', '@nvgovernment', '@nypostより', '@nytimes', '@nytscience', '@odoylecharlotte', '@officeofut', '@officialaitlive', '@officialdmrc', '@officialosgfng', '@omarkelly', '@ons', '@ooaswaho', '@osmosismed', '@osprey0', '@outofthedarkage', '@over400ppm', '@pabloperguz', '@pallavivedic', '@pantherman45', '@paprikalady', '@pathogenscribe', '@paulmromer', '@paulpauwaert', '@pawan90311', '@peatapann', '@peterj_walker', '@peterwa97559477', '@peterzeihan', '@phillyinquirer', '@piabizlaw', '@pib_india', '@pibhomeaffairs', '@pibindia', '@pibmumbai', '@pjpaton', '@pmoindia', '@pnouvellet', '@politifact', '@politifactnc', '@politifacttexas', '@politifactwisc', '@pommylee', '@potus', '@prakashjavdekar', '@pratimbose', '@presssec', '@prisonplanet', '@pritipatel', '@profakinabayomi', '@profbhargava', '@profkarolsikora', '@profsushmagupta', '@projectlincoln', '@ptamom7', '@ptfcovid19', '@ptinews', '@p…', '@qanda', '@questdiag', '@raffi', '@ranaayyub', '@randpaul', '@ranudhillon', '@rapidtests', '@rashlessdoctor', '@ravenrider2020', '@ravikundurthi', '@realdonaldtrump', '@realdonaldtrumps', '@reckedrik', '@redcross', '@renukajain6', '@rglobalism', '@ribbleboy15', '@riccigeri', '@riccisergienko', '@ricksheatcool', '@ridgeonsunday', '@rightsindia', '@rijpew', '@riktheozfrog', '@rmack2x', '@robchandigarh', '@robertbuckland', '@robertsfinkle', '@roboskis', '@robreiner', '@rosannarago', '@rosnovsky', '@roviir', '@roypentland', '@rspathania', '@rushhourp', '@rustyaway', '@sadhvipragyamp', '@saketgokhale', '@salaambaalakngo', '@saleyhaahsan', '@samarjeetn', '@sangeeta0312', '@sbrown6262', '@scaramangi', '@scclemons', '@sciencemagazine', '@scottgottliebmd', '@senatorkapengas', '@sentomcotton', '@septateneuf', '@shaskell12', '@shelby58617786', '@shevanthin', '@silent_deserts', '@sjforkids', '@skynews', '@skynewsbreak', '@skynewsmichelle', '@smileygirl19683', '@soapituphard', '@sophyridgesky', '@sormasopen', '@spavis', '@speakerpelosi', '@srbachchan', '@sreesub', '@srileyidd', '@ssfarouk', '@statedept', '@statnews', '@stepheneglen', '@stevefda', '@stjeffreystodd', '@stormsignalsa', '@suesensus', '@surgeon_general', '@surgeongeneral', '@susankilfoy', '@suzanneevans1', '@swannyqld', '@tackinfl', '@tamazonx', '@tangerinelaw', '@tatahealth', '@tazyas', '@teamtrump', '@teddysmom1', '@thatamartya', '@theatlantic', '@thecityny', '@thecyberdagger', '@thedisproof', '@thefauxy', '@thehill', '@theicai', '@thejohnabraham', '@thelancet', '@thepolldude', '@therealstoryplz', '@therealtruther', '@thereidout', '@theworrygames', '@thinksaboutit', '@thirdeyeblind9', '@thyrocare', '@tlowdon', '@tomaspueyo', '@tony80554056', '@tonybaldeagle', '@tqmka', '@trvrb', '@tuckercarlson', '@tvcconnect', '@twang0518', '@twt2abhi', '@uklabour', '@undark', '@undiction', '@undp', '@unicef', '@unicefindia', '@unicefmedia', '@uninindia', '@uniofoxford', '@unipadova', '@univcordoba', '@unreliefchief', '@upgovt', '@uressien', '@us_fda', '@usaid', '@usatoday', '@usponline', '@vaccineepi', '@veryvirology', '@vetsree', '@vicrollison', '@vinguptamd', '@vinlew', '@viruswatch2021', '@vmaledew', '@vonderleyen', '@vp', '@wacotrib', '@wadepthealth', '@wapflondon', '@washingtonpost', '@wbur', '@weare54gene', '@webmd', '@wevotedtoleave', '@wfp', '@wgrz', '@whatsapp', '@whitwyatt', '@who', '@whoafro', '@whophilippines', '@whos', '@whosearo', '@wh…', '@wionews', '@wolfiecindy', '@wordpressdotcom', '@worldhealthorg2', '@wvumediacollege', '@xanderarmstrong', '@xpressbengaluru', '@yahoo', '@yashuahawkeye', '@yatezy84', '@yayitsrob', '@yogrishiramdev', '@yorkshirebri', '@youtube', '@youyanggu', '@ywoga', '@zeenews', '@zevdr', '@…', '[covid-19]”', '[people', '[people]', '[sic', '_kenyas', '_russians', 'a', 'a&ampe', 'a&ampes', 'aa', 'aaj', 'aamir', 'aap', 'ab', 'ababa', 'abacha', 'abakaliki', 'abandon', 'abandoned', 'abating', 'abbasi', 'abbott', 'abdicated', 'abdul', 'abdulaziz', 'abhigyan', 'abia', 'abia1', 'abia10', 'abia11', 'abia14', 'abia15', 'abia2', 'abia20', 'abia23', 'abia28', 'abia31', 'abia48', 'abia5', 'abia6', 'abia7', 'abia8', 'abia9', 'abide', 'ability', 'able', 'aboard', 'abortion', 'abound', 'about', 'aboveinflation', 'abraham', 'abruptly', 'abs-cbn', 'absence', 'absent', 'absentee', 'absolute', 'absolutely', 'absorb', 'abubakar', 'abuja', 'abundantly', 'abused', 'abysmal', 'ab…', 'ac', 'academic', 'academy', 'acalabrutinib', 'acc', 'accelerate', 'accelerates', 'accelerating', 'acceleration', 'accelerator', 'accelerator@drtedros', 'accept', 'acceptable', 'accepted', 'access', 'access@drtedros', 'accessibility', 'accessible', 'accident', 'accidental', 'accidentally', 'accommodation', 'accompanies', 'accompany', 'accompanying', 'according', 'accordingly', 'account', 'accountable', 'accounted', 'accounting', 'accredited', 'accunalysis', 'accuracy', 'accurate', 'accurately', 'accuse', 'accused', 'accusing', 'acetylcysteine', 'ache', 'achievable', 'achieve', 'achievement', 'achieves', 'achieve…', 'achieving', 'acid', 'acidosis', 'acknowledge', 'acquire', 'acquired', 'acronym', 'across', 'act', 'act-accelerator', 'act.', 'actaccelerator', 'acting', 'action', 'activated', 'activates', 'activation', 'active', 'actively', 'active\\u2063', 'activist', 'activity', 'actor', 'actress', 'actual', 'actually', 'act�', 'acute', 'ac…', 'ad', 'ad5-ncov', 'adaab', 'adamawa', 'adamawa1', 'adamawa10', 'adamawa11', 'adamawa2', 'adamawa21', 'adamawa23', 'adamawa25', 'adamawa3', 'adamawa4', 'adamawa5', 'adamawa7', 'adaptable', 'adapted', 'add', 'added', 'adding', 'addis', 'addition', 'additional', 'additionally', 'additive', 'address', 'addressing', 'adeline', 'adequate', 'adequately', 'adf', 'adhaan', 'adhanom', 'adhere', 'adherence', 'adhering', 'adhesive', 'adiabo', 'aditya', 'adjust', 'adjusted', 'adjusting', 'adjustment', 'adjusts', 'admin', 'administer', 'administered', 'administered.', 'administration', 'administrator', 'admins', 'admission', 'admit', 'admited', 'admits', 'admittance', 'admitted', 'admitting', 'adolescent', 'adolescents@drtedros', 'adopted', 'adoption', 'adtd', 'adult', 'advance', 'advanced', 'advantage', 'adventure', 'adverse', 'advertisement', 'advice', 'adviced', 'advise', 'advised', 'adviser', 'advises', 'advising', 'advisor', 'advisory', 'advocacy', 'advocate', 'aerobridges', 'aerosol', 'afaik', 'affair', 'affect', 'affected', 'affecting', 'afffecting', 'affiliated', 'afford', 'affordable', 'afm', 'afp', 'afraid', 'afresh', 'africa', 'african', 'africathe', 'africa🇿🇦', 'after', 'afterhours', 'afternoon', 'afterwards', 'ag', 'again', 'again.', 'again.�', 'again@drtedros', 'against', 'againtoday', 'agarwal', 'age', 'age-wise', 'aged', 'agedcare', 'agency', 'agendas.�', 'agent', 'aggregate', 'aggregated', 'aggregation', 'aggression', 'aggressive', 'aggressively', 'agniveer', 'ago', 'agowe', 'agra', 'agree', 'agreed', 'agreement', 'agrees', 'aground', 'ahead', 'ahmedabad', 'ai', 'aid', 'aid\"thousands', 'aide', 'aiding', 'aiims', 'ailment', 'aim', 'aimed', 'aimim', 'air', \"air'\", 'airborne', 'aire', 'aired', 'aires)', 'airflow', 'airing', 'airline', 'airport', 'airspace', 'airway', 'ak', 'aka', 'akbar', 'akl', 'akwa', 'al', 'alabama', 'alaikum', 'alameda', 'alappuzha', 'alarm', 'alarming', 'alas-salah', 'alaska', 'alas…', 'alazhar', 'albany', 'albendazole', 'alberta', 'alberto', 'album', 'album30', 'alcohol', 'alcoholbased', 'aldi', 'aled', 'alegre', 'alert', 'alerted', 'alertness', 'alfa', 'alfa-2b)', 'alfa-2b,[565', 'algeria', 'algerian', 'ali', 'alien', 'alive', 'alive.', 'alkaline', 'all', 'all-time', 'all.👉https:t.comufdaoexiq', 'allah', 'allahu', 'alledegedly', 'allegation', 'alleged', 'allegedly', 'allegheny', 'allergic', 'allergy', 'alleviate', 'allocation', 'allow', 'allowance', 'allowed', 'allowing', 'allows', 'alltime', 'ally', 'almost', 'alone', 'along', 'alongside', 'alphons', 'already', 'also', 'also.�', 'alsolike', 'alsounder', 'alt', 'alter', 'altered', 'alternate', 'alternative', 'although', 'alumnus', 'always', 'alyoubi', 'am', 'amal', 'amatitlán', 'amazing', 'amazon', 'amazona', 'ambiguous', 'ambitious', 'ambulance', 'amd', 'america', 'american', 'americold', 'amid', 'amidst', 'aminu', 'amish', 'amit', 'amitabh', 'among', 'amongst', 'among…', 'amount', 'amounting', 'amoxi', 'amplified', 'amplitude', 'amusement', 'an', 'anaesthesia', 'analyse', 'analysing', 'analysis', 'analyst', 'analytics', 'anambra', 'anambra1', 'anambra13', 'anambra17', 'anambra2', 'anambra20', 'anambra21', 'anambra3', 'anambra7', 'anambra8', 'anand', 'anant', 'anchor', 'and', 'and100', 'anderson', 'andhra', 'andor', 'andrew', 'andrey', 'android', 'andry', 'andré', 'andy', 'and…', 'and…dodge', 'angel', 'angela', 'angeles', 'anger', 'angiotensinconverting', 'angry', 'anil', 'animal', 'anistons', 'announce', 'announced', 'announcement', 'announcement…', 'announces', 'announcing', 'annoying', 'annoyingly', 'annual', 'annually', 'anonymously', 'another', 'ansari', 'answer', 'answer.', 'answered', 'antenna', 'anthem', 'anthony', 'anti', 'anti-blackness', 'anti-viral', 'antibiotic', 'antibody', 'antichinese', 'anticipated', 'anticoagulant', 'anticorona', 'anticoronavirus', 'anticovid', 'antidote', 'antidotes.', 'antifa', 'antigen', 'antihistamine', 'antiinflammatories', 'antimalaria', 'antimalarial', 'antipandemic', 'antiparasitic', 'antiracist', 'antiseptic', 'antivaccine', 'antivaxxers', 'antiviral', 'antivirus', 'antivirus�', 'antonio', 'anttibiotics', 'anxiety', 'anxiousness', 'any', 'any.', 'any.�', 'anybody', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anyway,', 'anyways', 'anywhere', 'aoc', 'apart', 'apa…', 'api', 'apocalyptic', 'apologise', 'apologises', 'apologising', 'apologizes', 'apology', 'apology�', 'apolog…', 'app', 'appalling', 'apparently', 'appeal', 'appealed', 'appear', 'appeared', 'appearing', 'appears', 'appendix', 'applaud', 'applauded', 'applause', 'apple', 'application', 'applied', 'applies', 'apply', 'applying', 'appointed', 'appointment', 'appoints', 'appraisal', 'appreciate', 'apprises', 'approach', 'approached', 'approaching', 'appropriate', 'approval', 'approved', 'approves', 'approx', 'approximately', 'apps', 'apr', 'apr)', 'april', 'april)', 'aprilearly', 'apron', 'apronax', 'apturi', 'aquino', 'ar', 'arab', 'arabia', 'arbidol', 'archie', 'archived', 'ardern', 'ards', 'are', 'are.�', 'are341', 'area', 'area.', 'area…', 'arent', 'argar', 'argentina', 'argentina)', 'argentine', 'argentinian', 'arguably', 'argue', 'argued', 'argues', 'arif', 'arise', 'arisen', 'ariseswhere', 'arizona', 'arizonan', 'arkansas', 'arlene', 'arm', 'armed', 'army', 'arogya', 'aroha', 'arora', 'around', 'arrange', 'arranged', 'arrangement', 'arrest', 'arrested', 'arrested.', 'arresting', 'arrival', 'arrive', 'arrived', 'arriving', 'arse', 'arsehole', 'arsenicum', 'art', 'arthritis', 'article', 'artifact', 'artificial', 'artificially', 'artiste', 'artois', 'arvind', 'as', 'asaduddin', 'ash', 'asha', 'ashamed', 'ashley', 'ashworth', 'asia', 'asian', 'aside', 'ask', 'askd', 'asked', 'asking', 'asks', 'aspect', 'aspirin', 'aspirine', 'asprin', 'ass', 'assalamu', 'assam', 'assaulting', 'assemble', 'assembly', 'assertion', 'asserts', 'assessment', 'assign', 'assigned', 'assigning', 'assigns', 'assist', 'assistance', 'assistant', 'assisted', 'assisting', 'assoc', 'associate', 'associated', 'association', 'assume', 'assuming', 'assumption', 'assured', 'assures', 'assuring', 'asthma', 'astonishingly', 'astounding', 'astrazeneca', 'astrologer', 'astute', 'asunción', 'asymmetry', 'asymptomatic', 'asympt…', 'at', 'at&ampt', 'athlete', 'athome', 'atishi', 'atlanta', 'atrisk', 'attack', 'attacked', 'attacking', 'attempt', 'attempted', 'attempting', 'attend', 'attendance', 'attended', 'attendee', 'attending', 'attention', 'attitude', 'attorney', 'attract', 'attractive', 'attributable', 'attribute', 'attributed', 'atul', 'at—or', 'at…', 'at�', 'auckland', 'aucklandbased', 'auckland\\u200b', 'auckland\\u2063', 'auckland⠀', 'audi', 'audience', 'audio', 'aug', 'augmentation', 'august', 'augusto', 'aung', 'aunt', 'aurangaba', 'aurangabad', 'aussie', 'australia', 'australian', 'authenticity', 'author', 'authoritarian', 'authoritie…', 'authority', 'authorization', 'authorized', 'authorizes', 'autism', 'autohemotherapy', 'autoimmunity', 'automated', 'automatically', 'autopsy', 'avail', 'availability', 'available', 'availing', 'avenue', 'average', 'average)', 'averaged', 'averaging', 'avian', 'avifavir', 'avigan', 'avigan(favipiravir', 'avoid', 'avoidable', 'avoiding', 'await', 'awaiting', 'award', 'awarded', 'aware', 'awareness', 'away', 'away.', 'aw…', 'axel', 'ayodhya', 'aytac', 'aytu', 'ayurveda', 'ayurvedic', 'ayush', 'ayushman', 'az', 'azcafltx', 'azim', 'azithromycin', 'azithromycindoxycycline', 'a…', 'a🆕who', 'b', 'b1', 'baap', 'baba', 'baby', 'bacchan', 'bachchan', 'back', 'backbone', 'backdate', 'backend', 'backfill', 'backhand', 'backlog', 'backlogged', 'backlog—it', 'backtoback', 'backtrack', 'backtracked', 'backwards', 'bacon', 'bacteria', 'bacteriaeating', 'bacterial', 'bacterium', 'bad', 'badly', 'badminton', 'badusha', 'bag', 'bagh', 'bahia', 'baijal', 'bail', 'bailed', 'bailout', 'bajaav', 'bajao', 'bakersfield', 'bakery', 'baking', 'bakker', 'balance', 'balanced', 'balancing', 'balasubrahmanyams', 'ball', 'ballisticmissile', 'balloon', 'bame', 'ban', 'bandhugan', 'bandwagon', 'bangalore', 'bangladesh', 'banish', 'bank', 'banknote', 'bankrupt', 'banned', 'banner', 'banning', 'banwarilal', 'baptism', 'bar', 'barack', 'barak', 'bardhaman', 'bare', 'barely', 'bargain', 'barmer', 'baroda', 'baroness', 'barotrauma', 'barr', 'barranquilla', 'barrier', 'barrier.', 'barsclubs', 'base', 'baseball', 'based', 'baseless', 'baseline', 'bashed', 'basic', 'basically', 'basis', 'basis@drtedros', 'basketball', 'bat', 'batching', 'bath', 'batman', 'bats/pangolins', 'battle', 'battled', 'bauchi', 'bauchi1', 'bauchi10', 'bauchi11', 'bauchi13', 'bauchi15', 'bauchi17', 'bauchi19', 'bauchi2', 'bauchi25', 'bauchi3', 'bauchi36', 'bauchi4', 'bauchi5', 'bauchi6', 'bauchi69', 'bauchi7', 'bauchi8', 'bauchi9', 'bay', 'bayelsa1', 'bayelsa11', 'bayelsa13', 'bayelsa14', 'bayelsa17', 'bayelsa23', 'bayelsa25', 'bayelsa27', 'bayelsa3', 'bayelsa54', 'bayelsa6', 'bayelsa7', 'bayelsa8', 'bayelsa9', 'bayero', 'bazar', 'bbc', 'bbibp-corv', 'bc', 'bcg', 'bcoz', 'bd', 'be', 'beach', 'bean', 'bear', 'beard', 'bearing', 'beast.', 'beat', 'beaten', 'beating', 'beautician', 'beautiful', 'became', 'because', 'become', 'becomes', 'becoming', 'becoz', 'bed', 'bedroom', 'beds…', 'beef', 'been', 'beer', 'beet', 'before', 'before\"', 'before)', 'before.', 'before.�', 'began', 'begin', 'beginning', 'begun', 'behavior', 'behaviour', 'behind', 'beijing', 'being', 'belarus', 'belgian', 'belgium', 'belief', 'believe', 'believed', 'believing', 'belize', 'bellends', 'bello', 'belong', 'belongs', 'below', 'belsky', 'belt', 'ben', 'benchmark', 'bendigo', 'beneath', 'beneficiary', 'benefit', 'benefited', 'bengal', 'bengali', 'bent', 'benue', 'benue1', 'benue2', 'benue21', 'benue24', 'benue3', 'benue32', 'benue4', 'benue43', 'benue5', 'benzalkonium', 'bereaved', 'bereavement', 'berejiklians', 'berger', 'berlin', 'berry', 'bersani', 'beshear', 'besides', 'best', 'bet', 'betacoronaviruses', 'betadine', 'better', 'bettiah', 'between', 'beverage', 'beware', 'beyond', 'bezgate', 'bfast', 'bhabhi', 'bhagalpur', 'bhagwants', 'bhan', 'bharat', 'bharath', 'bhi', 'bhima', 'bhopal', 'bhopals', 'bicarbonate', 'bidding', 'biden', 'bidens', 'bidensoetoro', 'bidensooetoro', 'bidhuri\"', 'big', 'bigger', 'biggest', 'bihar', 'bihar)', 'biil', 'bilateral', 'biliary', 'bill', 'billiion', 'billion', 'billion.�', 'billionaire', 'bima', 'binaxnow', 'bind', 'binding', 'bio', 'bio-engineered', 'bio-weapon', 'bioengineered', 'biological', 'biologist', 'biology', 'biomagnetism', 'biomedical', 'biopharma', 'biosafety', 'bioscience', 'biosecurity', 'bioshield\"', 'biotech', 'bioweapon', 'bird', 'birnin', 'birth', 'birthday', 'birx', 'biscuit', 'bit', 'bite', 'bitter', 'bizarre', 'bjp', 'bjprun', 'bjps', 'black', 'blackled', 'blackpool', 'bladder', 'blame', 'blamed', 'blarney', 'blasio', 'blatantly', 'bleach', 'bleachbased', 'bleak', 'bless', 'blessed', 'blindingly', 'blindly.', 'blindlyfollowing', 'block', 'blocked', 'blocking', 'blog', 'blogger', 'blood', 'blooded', 'bloodletting', 'bloomfield', 'blow', 'blowing', 'blue', 'bluff', 'bmc', 'bmj', 'board', 'boast', 'boasting', 'boat', 'bob', 'bobby', 'body', 'bogotá', 'bogy', 'boiled', 'boiling', 'bolivar', 'bolivia', 'bolivian', 'bollywood', 'bollywoof', 'bolsonaro', 'bolton', 'bomb', 'bombed', 'bon', 'bone', 'bong', 'bonhomme', 'bonus', 'book', 'booking', 'bookmark', 'boom', 'boone', 'boost', 'boosted', 'booster', 'bootsontheground', 'border', 'boris', 'born', 'borne', 'borno', 'borno1', 'borno11', 'borno12', 'borno13', 'borno14', 'borno17', 'borno19', 'borno2', 'borno21', 'borno26', 'borno30', 'borno4', 'borno5', 'borno6', 'borno7', 'borno8', 'borno9', 'borrowed', 'bos', 'bossle', 'boston', 'bosé', 'botafogos', 'botch', 'both', 'bother', 'both—so', 'bottle', 'bottled', 'bottleneck', 'bottom', 'bottomed', 'boucher', 'bought', 'bounce', 'bound', 'boundary', 'bowl', 'box', 'boy', 'boyacá', 'bo…', 'brace', 'braced', 'brad', 'brahman', 'brahmin', 'brain', 'branch', 'brand', 'brandnew', 'brandolino', 'brave', 'brazailian', 'brazil', 'brazil!!now', 'brazilian', 'breached', 'bread', 'break', 'breakdown', 'breaker', 'breakfast', 'breaking', 'breakthroug', 'breakthrough', 'breast', 'breastfeed', 'breastfeed@drtedros', 'breastfeeding', 'breath', 'breath)', 'breathe', 'breathing', 'breathlessness', 'breed', 'brewed', 'brexit', 'brian', 'bribe', 'bribed', 'brick', 'bridge', 'briefed', 'briefing', 'bright', 'brighten', 'brilliant', 'bring', 'bring.', 'bringing', 'brings', 'brink', 'briones', 'brisbane', 'brit', 'britain', 'british', 'briton', 'brl', 'broad', 'broadcast', 'broaden', 'broader', 'broadest', 'broadly', 'broadscale', 'broad—10', 'broiler', 'broke', 'broken', 'broking', 'bronx', 'brooklyn', 'brother', 'brought', 'brownsville', 'bruno', 'brush', 'brute', 'btk', 'bu', 'bubble', 'bubble??�', 'bubonic', 'bucaramanga', 'buck', 'buddhist', 'budget', 'budget....', 'budget�', 'buenaventura', 'buenos', 'buffet', 'bug', 'buhari', 'build', 'building', 'built', 'bulgaria', 'bulk', 'bull', 'bullet', 'bullet.', 'bulletin', 'bullfight', 'bullfighter', 'bullshit', 'bump', 'bumper', 'bunch', 'bundle', 'bunker', 'bunkum', 'burden', 'bureau', 'burecrat', 'burger', 'burglar', 'burial', 'buried', 'burka', 'burn', 'burned', 'burnham', 'burning', 'burning)', 'burr', 'bury', 'burying', 'bus', 'busey', 'business', 'businessman', 'business…', 'buster', 'busy', 'busy😖', 'but', 'butand', 'buttar', 'but—because', 'buy', 'buyer', 'buying', 'buyutikum', 'bu�', 'by', 'byer', 'byoblu', 'bypass', 'bypassed', 'byrti', 'c', 'c.�', 'c19', 'ca', 'caba', 'caballero', 'cabbage', 'cabellos', 'cabinet', 'cable', 'cached', 'cadila', 'caesarean', 'cahill', 'cain', 'cake', 'calahorra', 'calculate', 'calculating', 'calendar', 'cali', 'calibrated', 'calif.', 'california', 'california..virginia', 'california’s', 'call', 'called', 'caller', 'calling', 'calm', 'calmly', 'cambridge', 'came', 'camel', 'camila', 'camilla', 'camp', 'campaign', 'camper', 'campos', 'camps.�', 'campus', 'can', 'can.', 'canada', 'canadian', 'canal', 'cancel', 'canceled', 'cancellation', 'cancelled', 'cancer', 'candidate', 'candidates@drtedros', 'candle', 'cane', 'canedsupport', 'canine', 'cannon', 'cannot', 'cansinos', 'cant', 'capacity', 'capacity\"', 'capital', 'capitalism', 'capsule', 'captain', 'caption', 'captivity', 'capture', 'captured', 'capturing', 'caput', 'car', 'carabinieri', 'carbon', 'card', 'cardboard', 'cardiac', 'cardio', 'cardiology', 'cardiovascular', 'care', 'care)', 'career', 'careful', 'carefully', 'caregiver', 'careless', 'caretaker', 'cargo', 'caring', 'carl', 'carlos', 'carlson', 'carlsons', 'carolina', 'carona', 'carpet', 'carping', 'carrefour', 'carried', 'carrier', 'carry', 'carrying', 'cart', 'cartagena', 'cartel', 'casaulty', 'case', 'case.', 'casebycase', 'casefatality', 'caseload', 'casemanagement', \"cases'\", 'cases)', 'cases+cureddischargedmigrated+deaths', 'cases+deaths', 'cases.', 'cases19', 'casesstill', 'casestill', 'cases\\u2063', 'case\\u2063', 'cash', 'cashew', 'cast', 'caste', 'casteism', 'casting', 'casual', 'casualty', 'cat', 'catalyst', 'catastrophe', 'catch', 'catching', 'catc�', 'categorically', 'category', 'catfish', 'cattle', 'cauca', 'caught', 'cause', 'caused', 'causing', 'caution', 'cautioning', 'cautious', 'cautious\".', 'cautious@drtedros', 'caveat', 'caveated', 'caveats)', 'cavity', 'ca…', 'cbc', 'cbse', 'cc', 'ccp', 'ccp&amp', 'ccps', 'cctv', 'cdc', 'cdc.', 'cdcapproved', 'cdu', 'ce', 'ceará', 'cease', 'cede', 'ceiling', 'celaá', 'celcius', 'celebrate', 'celebrated', 'celebrating', 'celebration', 'celebratory', 'celebrity', 'cell', 'cemetery', 'censor', 'censored', 'census', 'cent', 'center', 'centerstage', 'central', 'centre', 'centreled', 'centre😱', 'century', 'ceo', 'cerebral', 'ceremonial', 'ceremony', 'certain', 'certainly', 'certificate', 'certified', 'cessation', 'cfr', 'cghs', 'chaand', 'chain', 'chair', 'chairman', 'chairmant', 'chalisa', 'challenge', 'challenge—', 'challenging', 'chamber', 'championing', 'chan', 'chanakya', 'chance', 'chance.', 'chancellor', 'chandigarh', 'chandrabhaga', 'chang', 'change', 'changed', 'changeover', 'changer', 'changing', 'channel', 'channelled', 'chant', 'chaos', 'chaotic', 'character', 'characterised', 'characteristic', 'charge', 'charged', 'charging', 'charity', 'charles', 'charm', 'chart', 'charter', 'chase', 'chat', 'chatbot', 'chatbots', 'cheap', 'cheaper', 'cheat', 'cheated', 'cheb', 'check', 'checked', 'checken', 'checker', 'checking', 'checkout', 'checks.�', 'checkup', 'cheek', 'cheer', 'cheering', 'cheesburger', 'chemical', 'chemicalwarfare', 'chemist', 'chemistry', 'chemo', 'chemotherapy', 'chen', 'cheque', 'cherrypicked', 'cherrypicks', 'chest', 'chhattisgarh', 'chicago', 'chicken', 'chicken.', 'chicomvirus', 'chidambaram', 'chief', 'child', \"child'shealth\", 'childcare', 'childhood', 'childrens', 'chile', 'chill', 'chin', 'china', 'china.', 'chinatown', 'chinda', 'chinese', 'chip', 'chiquitos', 'chirayu', 'chlorhexidine', 'chloride', 'chlorine', 'chlorite', 'chloroquine', 'chloroquinehydroxychloroquine', 'chloroxylenol', 'chmp', 'choice', 'choke', 'cholera', 'choose', 'choosing', 'chopped', 'chorley', 'chose', 'chosen', 'chouhan', 'chow', 'chris', 'christ', 'christchurch', 'christian', 'christine', 'christopher', 'chromolaena', 'chronic', 'chuck', 'chunk', 'chupacabra', 'church', 'chyna', 'cientists', 'cigar', 'cigarette', 'cinema', 'circle', 'circuit', 'circulate', 'circulated', 'circulates', 'circulating', 'circulation', 'circumstance', 'circus', 'cite', 'cited', 'citing', 'citizen', 'citrus', 'city', 'city.', 'citylevel', 'citywide', 'civil', 'civilization', 'ciyal', 'clad', 'claim', 'claimed', 'claiming', 'claire', 'clara', 'clarification', 'clarified', 'clarifies', 'clarify', 'clarity', 'clashed', 'class', 'classic', 'classified', 'classroom', 'clause', 'clean', 'cleaner', 'cleanest', 'cleaning', 'clear', 'clear.', 'clearance', 'cleared', 'clearly', 'clemson', 'clever', 'click', 'clicking', 'client', 'climate', 'climb', 'climbing', 'clinic', 'clinical', 'clinically', 'clinician', 'clinton', 'clip', 'clipon', 'clique', 'clive', 'clo2', 'clock', 'clooney', 'clorox', 'close', 'closed', 'closed\\u2063', 'closely', 'closer', 'closest', 'closing', 'closure', 'clot', 'cloth', 'clothes', 'clothesline', 'club', 'clue.', 'cluster', 'clusters\\u2063', 'clusters\\u2063\\u2063\\u2063\\u2063', 'cluster\\u2063', 'clutching', 'clínicas', 'cm', 'cn', 'cnbc', 'cnn', 'cnns', 'cns', 'cnt', 'co', 'co-worker', 'coa', 'coach', 'coaching', 'coagulopathy', 'coast', 'coat', 'coauthor', 'cobas', 'cobbled', 'cobey', 'cobr', 'cobra', 'coca', 'cocaine', 'code', 'codechecking', 'coded', 'codelevel', 'coffee', 'coffin', 'cohen', 'cohort', 'coin', 'coincidence', 'cold', 'colfax', 'collaboration', 'collaborative', 'collapse', 'collapsing', 'collates', 'colleague', 'collection', 'collective', 'college', 'colloidal', 'colombia', 'color', 'colorado', 'colour', 'columbia', 'column', 'combat', 'combating', 'combination', 'combined', 'combo', 'come', 'coming', 'commemorative', 'commercial', 'commission', 'commit', 'commitment', 'commits', 'committed', 'committee', 'commodity', 'common', 'commonly', 'communal', 'communicate', 'communicated', 'communicating', 'communication', 'communist', 'community', 'communitybased', 'comorbidities', 'company', 'comparable', 'compare', 'compared', 'comparing', 'comparison', 'compassionate', 'complaint', 'complete', 'completed', 'completely', 'completes', 'completing', 'completion', 'complex', 'complexity', 'compliance', 'complicated', 'complication', 'complicit', 'component', 'compound', 'comprehensive', 'comprehensively', 'comprising', 'compulsory', 'computer', 'concentrated', 'concentration', 'concern', 'concerned', 'concerning', 'concluded', 'conclusion', 'conclusive', 'condemned', 'condition', 'conduct', 'conducted', 'conducting', 'conference', 'confidence', 'confident', 'confirm', 'confirmation', 'confirmed', 'confirming', 'confirms', 'confuse', 'confused', 'confusing', 'congregation', 'congress', 'connect', 'connected', 'connecticut', 'connecting', 'connection', 'consecutive', 'consent', 'consequence', 'consider', 'considerable', 'consideration', 'considered', 'considering', 'consistent', 'consistently', 'conspiracy', 'constant', 'constantly', 'constituent', 'constrained', 'constructed', 'consult', 'consultation', 'consume', 'consuming', 'consumption', 'contact', 'contacted', 'contacted\\u2063', 'contacting', 'contagion', 'contain', 'containing', 'containment', 'contains', 'contaminated', 'content', 'context', 'continent', 'continue', 'continued', 'continues', 'continuing', 'continuous', 'continuously', 'contract', 'contracted', 'contracting', 'contrary', 'contribute', 'contributed', 'contributing', 'contribution', 'control', 'controlled', 'controller', 'controlling', 'controversial', 'controversy', 'convalescent', 'convened', 'convention', 'conversation', 'conversion', 'convert', 'converted', 'converting', 'cool', 'coordinate', 'coordinated', 'coordination', 'cop', 'cope', 'copied', 'coping', 'core', 'corona', 'coronacheck', 'coronavac', 'coronavirus', 'coronavirus.', 'coronavirus.�', 'coronaviruses', 'coronavirusthemed', 'coronil', 'corporation', 'corps', 'corpse', 'correct', 'corrected', 'correction', 'correctly', 'correctness', 'correlation', 'corridor', 'corrientes', 'corticosteroid', 'cost', 'costco', 'cough', 'coughing', 'could', 'couldnt', 'council', 'count', 'counted', 'counter', 'counterpart', 'counting', 'countries@drtedros', 'country', 'county', 'couple', 'coupled', 'course', 'court', 'cov2', 'covax', 'covaxin', 'cover', 'coverage', 'covered', 'covering', 'covid', 'covid-19', 'covid-19.', 'covid-19.�', 'covid-19s', 'covid-19\\u200b', 'covid-19\\u2063', 'covid1', 'covid19', 'covid19nigeria', 'covid19related', 'covidiots', 'covidnet', 'covidrelated', 'covidsafe', 'cow', 'cr', 'crazy', 'cream', 'create', 'created', 'creating', 'credit', 'creeping', 'crematorium', 'creted', 'crew', 'cricket', 'crime', 'criminal', 'criminalized', 'crisis', 'cristiano', 'criterion', 'critical', 'critically', 'crore', 'cross', 'crossed', 'crossing', 'crowd', 'crowded', 'crown', 'crucial', 'cruise', 'cry', 'ct', 'cuba', 'cultural', 'cummings', 'cumulative', 'cumulatively', 'cunial', 'cuomo', 'cup', 'cupboard', 'curbside', 'cure', 'cured', 'cureddischargedmigrated', 'cureddischargedmigrated+active', 'curedrecovered', 'curfew', 'currency', 'current', 'currently', 'curve', 'customer', 'cut', 'cutting', 'cv', 'cv19', 'c…', 'd', 'da', 'dad', 'dadar', 'daily', 'dakota', 'dallas', 'damage', 'dana', 'dancing', 'danger', 'dangerous', 'daniel', 'dark', 'dashboard', 'data', 'dataset', 'date', 'date…', 'dating', 'daughter', 'david', 'dawood', 'dawson', 'day', 'dc', 'dcgi', 'de', 'dead', 'deadline', 'deadly', 'deal', 'dear', 'death', 'deathsmillion', 'debate', 'debt', 'debunk', 'debunked', 'debunking', 'decade', 'deceased', 'december', 'decent', 'decide', 'decided', 'deciding', 'decision', 'decisive', 'decisively', 'deck', 'declaration', 'declared', 'declares', 'decline', 'declined', 'declining', 'decontamination', 'decrease', 'decreased', 'decreasing', 'dedicated', 'deep', 'deeper', 'defeat', 'defeated', 'defeating', 'defence', 'defend', 'defense', 'defer', 'deficiency', 'definitely', 'definition', 'degree', 'dehradun', 'del', 'delaware', 'delay', 'delayed', 'deleted', 'delhi', 'deliver', 'delivered', 'delivering', 'delivery', 'delta', 'delta10', 'delta12', 'delta13', 'delta16', 'delta18', 'delta25', 'delta3', 'delta37', 'delta5', 'delta6', 'delta7', 'demand', 'demanding', 'democrat', 'democratic', 'demographic', 'demonstrated', 'demonstrating', 'demonstration', 'denial', 'denied', 'denies', 'denmark', 'densely', 'density', 'departing', 'department', 'departure', 'depend', 'depending', 'depends', 'deploy', 'deployed', 'depopulate', 'depressing', 'depression', 'depth', 'deputy', 'derived', 'dermatology', 'desai', 'desantis', 'describes', 'describing', 'description', 'deserves', 'design', 'designed', 'desired', 'despite', 'destination', 'destroy', 'destroyed', 'destroying', 'destroys', 'detail', 'detailed', 'detain', 'detect', 'detected', 'detection', 'determine', 'determined', 'detroit', 'dettol', 'devastated', 'devastating', 'develop', 'developed', 'developed.', 'developer', 'developing', 'development', 'develops', 'devi', 'dewine', 'dexamethasone', 'dexamethsaone', 'dg', 'dhb', 'diabetes', 'diagnose', 'diagnosed', 'diagnosis', 'diagnostic', 'diagnostics', 'diamond', 'did', 'didnt', 'dido', 'die', 'died', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'diffies', 'digital', 'dilution', 'dioxide', 'dip', 'direct', 'directed', 'direction', 'directive', 'directly', 'director', 'directorgeneral', 'directs', 'dirty', 'disappear', 'disaster', 'discharge', 'discharged', 'discipline', 'discontinued', 'discover', 'discovered', 'discovers', 'discovery', 'discrepancy', 'discus', 'discussion', 'disease', 'disheveled', 'disinfect', 'disinfectant', 'disinfected', 'disinfecting', 'disinfection', 'disorder', 'disparity', 'disposable', 'disproportionately', 'disrupted', 'disruption', 'distance', 'distancing', 'distant', 'distraction', 'distribute', 'distributed', 'distributing', 'distribution', 'district', 'dive', 'diverse', 'diy', 'dma', 'dna', 'dnc', 'do', 'doc', 'doctor', 'doctored', 'document', 'documentary', 'documentation', 'doe', 'doesnt', 'dog', 'doha', 'dollar', 'domestic', 'dominic', 'donald', 'donate', 'donated', 'donates', 'donation', 'done', 'donor', 'dont', 'don´t', 'doomed', 'doomsday', 'door', 'doria', 'dos', 'dose', 'double', 'doubled', 'doubled@drtedros', 'doubling', 'doubt', 'doug', 'doused', 'down', 'download', 'downplayed', 'downward', 'downwards', 'dozen', 'dph', 'dr', 'drastically', 'draw', 'dressed', 'drew', 'drifting', 'drink', 'drinking', 'drive', 'driven', 'driver', 'driving', 'drone', 'drop', 'droplet', 'dropped', 'dropping', 'drove', 'drug', 'drunk', 'dry', 'dubai', 'dublin', 'duck', 'due', 'dump', 'dumped', 'dundee', 'duration', 'durham', 'during', 'dutch', 'duterte', 'duty', 'dy', 'dying', 'dyk', 'dynamic', 'each', 'eager', 'ear', 'earlier', 'early', 'earn', 'earth', 'ease', 'eased', 'easier', 'easily', 'easing', 'east', 'eastern', 'easy', 'eat', 'eating', 'ebola', 'ebonyi11', 'ebonyi17', 'ebonyi19', 'ebonyi3', 'ebonyi4', 'ebonyi9', 'ecmo', 'economic', 'economy', 'ecuador', 'ecuadorian', 'ed', 'editor', 'edo', 'edo1', 'edo13', 'edo17', 'edo19', 'edo2', 'edo22', 'edo23', 'edo3', 'edo6', 'edo7', 'edo8', 'educate', 'education', 'educational', 'edward', 'effect', 'effective', 'effectively', 'effectiveness', 'efficacious', 'efficacy', 'efficiency', 'efficient', 'efficiently', 'effort', 'eg', 'egyptian', 'eight', 'either', 'ekiti', 'ekiti1', 'ekiti2', 'ekiti3', 'ekiti4', 'ekiti6', 'ekiti8', 'ekiti9', 'el', 'elbow', 'elderly', 'elected', 'election', 'elective', 'electoral', 'electromagnetic', 'elevated', 'eligible', 'eliminate', 'eliminates', 'elimination', 'elizabeth', 'else', 'elsewhere', 'email', 'embrace', 'embracing', 'emerged', 'emergency', 'emerges', 'emerging', 'emirate', 'emission', 'emotionally', 'emphasis', 'emphasize', 'employed', 'employee', 'employment', 'empty', 'enable', 'enabled', 'enables', 'encourage', 'encouraged', 'encourages', 'encouraging', 'end', 'ended', 'ending', 'endorses', 'enema', 'enemy', 'enforce', 'enforced', 'enforcement', 'engage', 'engagement', 'engaging', 'engineered', 'engineering', 'england', 'english', 'enhanced', 'enjoy', 'enjoyed', 'enough', 'enrolled', 'enrollment', 'ensure', 'ensured', 'ensuring', 'enter', 'entered', 'entering', 'entire', 'entirely', 'entitled', 'entity', 'entrance', 'entry', 'enugu', 'enugu14', 'enugu15', 'enugu2', 'enugu25', 'enugu6', 'enugu7', 'enugu9', 'environmental', 'envoy', 'epidemic', 'epidemiological', 'epidemiologist', 'equipment', 'equitable', 'equity', 'equivalent', 'er', 'eradicate', 'erratic', 'erroneously', 'error', 'especially', 'essential', 'established', 'establishes', 'estimate', 'estimated', 'et', 'etc', 'ethiopian', 'ethnic', 'ethnicity', 'eu', 'eucalyptus', 'euro', 'europe', 'european', 'evaluate', 'evaluation', 'evangelical', 'evangelicals', 'even', 'evening', 'event', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everyones', 'everything', 'everywhere', 'eviction', 'evidence', 'evil', 'evolution', 'evolves', 'exact', 'exactly', 'exaggerated', 'exam', 'examination', 'examines', 'example', 'exceed', 'exceeded', 'exceeds', 'excellent', 'except', 'exception', 'exceptional', 'excerpt', 'excess', 'excessive', 'excited', 'exclusive', 'excuse', 'executive', 'exempt', 'exemption', 'exercise', 'exhausted', 'exist', 'existed', 'existing', 'exists', 'exosome', 'exotic', 'expand', 'expanded', 'expanding', 'expansion', 'expect', 'expected', 'expecting', 'expel', 'expelled', 'expensive', 'experience', 'experienced', 'experiencing', 'expert', 'explain', 'explained', 'explainer', 'explaining', 'explains', 'explanation', 'explosion', 'exponential', 'exponentially', 'export', 'exporting', 'exposed', 'exposure', 'expresident', 'expression', 'expressly', 'extend', 'extended', 'extending', 'extends', 'extension', 'extensive', 'extent', 'extra', 'extreme', 'extremely', 'extremist', 'eye', 'fabiflu', 'face', 'facebook', 'facemask', 'facilitate', 'facilitating', 'facilitation', 'facilities\\u200b\\u2063', 'facility', 'facing', 'fact', 'fact-check', 'factchecked', 'factchecking', 'factchecks', 'factor', 'factory', 'fad', 'fade', 'fail', 'failed', 'failing', 'fails', 'failure', 'fair', 'faith', 'fake', 'fall', 'fallen', 'falling', 'false', 'falsehood', 'family', 'famous', 'fan', 'faq', 'far', 'farmer', 'fascinating', 'fascist', 'fashion', 'fast', 'faster', 'fastest', 'fatal', 'fatality', 'father', 'fatigue', 'fauccis', 'fauci', 'faucian', 'faucis', 'favipiravir', 'favor', 'fbi', 'fct', 'fct138', 'fct14', 'fct25', 'fct26', 'fct29', 'fct34', 'fct35', 'fct38', 'fct52', 'fct60', 'fda', 'fear', 'feature', 'feb', 'february', 'federal', 'feedback', 'feel', 'feeling', 'fell', 'fellowship', 'felt', 'fema', 'female', 'fennel', 'ferguson', 'fernández', 'fever', 'fewer', 'fewest', 'fibrosis', 'fiction', 'field', 'fifth', 'fight', 'fighting', 'figure', 'figuring', 'file', 'filed', 'filipino', 'filled', 'film', 'filmed', 'filming', 'final', 'finalising', 'finally', 'finance', 'financial', 'financially', 'find', 'finding', 'fine', 'fined', 'finished', 'fire', 'firearm', 'fired', 'firing', 'first', 'fiscal', 'fish', 'fit', 'fitness', 'five', 'fix', 'fixed', 'fixing', 'fl', 'flag', 'flattened', 'flawed', 'flew', 'flight', 'floor', 'florida', 'flour', 'flouting', 'flu', 'flulike', 'fly', 'flying', 'focus', 'focused', 'focusing', 'focussed', 'folk', 'follow', 'followed', 'follower', 'following', 'follows', 'followup', 'food', 'foot', 'footage', 'football,', 'for', 'forbade', 'force', 'forced', 'ford', 'forecast', 'foreign', 'foreigner', 'foreseeable', 'forever', 'forged', 'forget', 'forgotten', 'form', 'former', 'fortaleza', 'forward', 'fought', 'found', 'foundation', 'founder', 'four', 'fourmonth', 'fourteen', 'fourth', 'fox', 'fraction', 'framework', 'france', 'francis', 'fraud', 'free', 'freedom', 'freely', 'freeview', 'freezing', 'french', 'frequency', 'frequently', 'fresh', 'freshly', 'friday', 'friend', 'frm', 'from', 'front', 'frontline', 'frozen', 'fruit', 'frustration', 'ft', 'fuck', 'fuel', 'full', 'fully', 'function', 'functional', 'fund', 'fundamental', 'fundamentally', 'funded', 'funding', 'funeral', 'fungal', 'funneled', 'funny', 'furlough', 'future', 'ga', 'gain', 'galicia', 'game', 'gandhi', 'ganga', 'gap', 'gargle', 'gargling', 'garib', 'garlic', 'gate', 'gather', 'gathered', 'gathering', 'gave', 'gay', 'gear', 'gender', 'general', 'generally', 'generate', 'generated', 'generation', 'genetic', 'genexpert', 'genius', 'genocide', 'genomic', 'gentleman', 'genuine', 'geographical', 'george', 'georgia', 'gerais', 'germ', 'german', 'germany', 'get', 'getting', 'ghana', 'ghislaine', 'gift', 'gifted', 'gilead', 'ginger', 'girl', 'give', 'given', 'giving', 'glad', 'global', 'globally', 'globe', 'glove', 'go', 'goal', 'god', 'goi', 'going', 'gold', 'gombe', 'gombe1', 'gombe2', 'gombe21', 'gombe3', 'gombe30', 'gombe4', 'gombe5', 'gombe6', 'gone', 'gonna', 'good', 'goodbye', 'goodwill', 'google', 'gop', 'got', 'gotten', 'gourd', 'gov', 'gove', 'government', 'governor', 'govt', 'gowdy', 'gown', 'gp', 'gps', 'grade', 'graded', 'graduate', 'graf', 'grand', 'grandparent', 'grant', 'granted', 'graph', 'graphic', 'grateful', 'gratitude', 'grave', 'graveyard', 'great', 'greater', 'greatest', 'greatly', 'greece', 'green', 'grenons', 'gretchen', 'grieve', 'grim', 'grime', 'grocery', 'ground', 'groundbreaking', 'group', 'grow', 'growing', 'grown', 'growth', 'guarantee', 'guatemalan', 'guess', 'guest', 'guidance', 'guide', 'guideline', 'guidelinesnotifications', 'guinean', 'gujarat', 'gun', 'guy', 'gym', 'h1n1', 'ha', 'habit', 'hack', 'had', 'hadio', 'hadnt', 'hail', 'hair', 'hairdresser', 'haji', 'hajipur', 'half', 'hall', 'halt', 'hamster', 'hancock', 'hand', 'handed', 'handing', 'handle', 'handling', 'hangover', 'hank', 'hantavirus', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'harder', 'hardest', 'harding', 'hardship', 'hare', 'haripriya', 'harm', 'harmful', 'harmless', 'harmless.', 'harris', 'harry', 'harvard', 'haryana', 'hasnt', 'hat', 'hate', 'have', 'havent', 'having', 'hav…', 'hcq', 'he', 'head', 'headache', 'heading', 'headline', 'headquarters', 'headroom', 'headteacher', 'heal', 'health', 'healthcare', 'healthline', 'healthy', 'health\\u2063', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heath', 'heavily', 'heavy', 'height', 'held', 'heleno', 'hell', 'hello', 'help', 'helped', 'helping', 'helpline', 'hence', 'her', 'herbal', 'herd', 'here', 'herman', 'hero', 'hhs', 'hi', 'hidden', 'hiding', 'high', 'higher', 'highest', 'highincome', 'highlight', 'highlighting', 'highly', 'highrisk', 'hill', 'hillary', 'hindu', 'hinted', 'his', 'hispanic', 'historic', 'historical', 'history', 'hit', 'hitting', 'hiv', 'hivaids', 'hmh', 'hoax', 'hold', 'holding', 'holiday', 'home', 'homeless', 'homemade', 'homeopathic', 'homeopathy', 'homeschooling', 'hon', 'honey', 'hong', 'honjo', 'honourable', 'honoured', 'hope', 'hopefully', 'hoping', 'hopkins', 'horizon', 'horny', 'horse', 'hosp', 'hospital', 'hospitalists', 'hospitality', 'hospitalization', 'hospitalizationsicu', 'hospitalized', 'hospitallevel', 'host', 'hosting', 'hot', 'hotel', 'hotline', 'hotspot', 'hour', 'hours.', 'house', 'household', 'housing', 'how', 'however', 'hr', 'https://t.co/03hguvcatu', 'https://t.co/1ato9qo0he', 'https://t.co/25nxirzawb.', 'https://t.co/2caogenfur', 'https://t.co/2l2qxh0m45', 'https://t.co/2rvg3dwbkt.', 'https://t.co/2xlf9mccft.', 'https://t.co/3lb8xsviva', 'https://t.co/4ku7nklzcq', 'https://t.co/4yblkisg6u', 'https://t.co/5l9jptglai', 'https://t.co/5rbbdr4r0u', 'https://t.co/6kydz6twwe', 'https://t.co/7c8w5pwnmp', 'https://t.co/98jmut3igq.', 'https://t.co/9jgwi7gszz', 'https://t.co/9zn2zytaud.', 'https://t.co/a36kao2nwa', 'https://t.co/adsrezpsfh', 'https://t.co/aiyoynmcus', 'https://t.co/apqxpndtq2', 'https://t.co/apswxjcfgw', 'https://t.co/b3qfvqwv7u', 'https://t.co/bzvndgpell', 'https://t.co/c0tikpeaju', 'https://t.co/c2ytwok7it', 'https://t.co/cs7uxqrrmn', 'https://t.co/d70c7hfahc', 'https://t.co/dmfpoapmjw.', 'https://t.co/dmfpob7nbu.', 'https://t.co/dyojlfjhyd', 'https://t.co/e9cshsdhgy', 'https://t.co/ebclrcf6q3', 'https://t.co/eckw6gemjf', 'https://t.co/ewhzrrykvo', 'https://t.co/fegmdobt0q.', 'https://t.co/fqhg5m5xrn', 'https://t.co/ft6cgmampx', 'https://t.co/ft6cgmampx.', 'https://t.co/ftca9h75oa', 'https://t.co/g8duiqxiwr.', 'https://t.co/gdfjrxl032', 'https://t.co/gialss3xd7', 'https://t.co/gpqyw8gnx3', 'https://t.co/gudbpy0x9d.', 'https://t.co/i0ya5yftvz', 'https://t.co/igh6ua8oha.', 'https://t.co/ihbwco8lbl', 'https://t.co/ioqv5omdka.', 'https://t.co/ip0gahip7q.', 'https://t.co/isbyfxnv5a.', 'https://t.co/jkwwztfwss.', 'https://t.co/jkwwztxyhs.', 'https://t.co/jw9vsogjgo', 'https://t.co/jy6ojd1g7y', 'https://t.co/ktyazabu4m', 'https://t.co/kulxwpdc15.', 'https://t.co/kzncyfx70q', 'https://t.co/lcfch0fxct', 'https://t.co/lmiaablmji', 'https://t.co/lmr9xro4wi', 'https://t.co/lqlfumwmvu', 'https://t.co/lqlfunenns', 'https://t.co/lvzejloxmh.', 'https://t.co/lxwme4nubd.', 'https://t.co/mcp09udspe', 'https://t.co/mlj56qcw37.', 'https://t.co/mp3spdaktl', 'https://t.co/mpuji2yq0v', 'https://t.co/n4zdlimwkk', 'https://t.co/n6iwcmznbk', 'https://t.co/n8oor2o8ep', 'https://t.co/nyzlpjyfxm', 'https://t.co/opc8z4tnib', 'https://t.co/oz9kcdajij', 'https://t.co/pagzfxjnbi', 'https://t.co/pgxjssssu9', 'https://t.co/pqd1i8xgam', 'https://t.co/pzrmh3tkeq', 'https://t.co/pzrmh4bl5y', 'https://t.co/q1dtcxukin.', 'https://t.co/qshrwi4wl6', 'https://t.co/qudkgltmpz', 'https://t.co/qut7jutqe9', 'https://t.co/qv6qlvjhcg.', 'https://t.co/qvdcousvh0', 'https://t.co/qveevtktxp', 'https://t.co/qvg0q767nv', 'https://t.co/qwap6bq9zz', 'https://t.co/qwbw7lshmz', 'https://t.co/qwuqdjft1o', 'https://t.co/qwwazudzn7', 'https://t.co/qxmtdm9wiq', 'https://t.co/qxnveiqta1', 'https://t.co/qxrl0im4hj', 'https://t.co/qxwesswg4y', 'https://t.co/qya6tbtxeb', 'https://t.co/qya6tcby5j', 'https://t.co/qyjpwo3soz', 'https://t.co/qymgi29huz', 'https://t.co/qymhxyiqwx', 'https://t.co/qyrdw8nxqy', 'https://t.co/qzdr78e8xv', 'https://t.co/qztitzzvii', 'https://t.co/r02vbcsl2r', 'https://t.co/r0jh79y09e', 'https://t.co/r1kuh5ikon', 'https://t.co/r2m7ybdelj', 'https://t.co/r2ok4f9icn', 'https://t.co/r2z1e6agnj', 'https://t.co/r3s66hbfoh', 'https://t.co/r4hntneewd', 'https://t.co/r4qfhizdw5', 'https://t.co/r5eohsbycl', 'https://t.co/r5n1mhnung', 'https://t.co/r5ssfz6cdl', 'https://t.co/r7j5b1dxzu', 'https://t.co/r8ecxmfk32', 'https://t.co/r8tbtbrnhr', 'https://t.co/r94cjvfpv5', 'https://t.co/raipikpyrr', 'https://t.co/ravbt5tbqs', 'https://t.co/rayx3k0iiv', 'https://t.co/rbk1lnhhd9', 'https://t.co/rbrefuf3ng', 'https://t.co/rbtbbm5yrv', 'https://t.co/rc0t2zbtep', 'https://t.co/rd21gako6c', 'https://t.co/rd3jlyx3rr', 'https://t.co/rdh7cebcn6', 'https://t.co/rdkcvfbhus', 'https://t.co/re9k3kzmyr', 'https://t.co/recbkf4y1y', 'https://t.co/rf3kkuan5n', 'https://t.co/rfetmavs0n', 'https://t.co/rfior52i7c', 'https://t.co/rggosydyuy.', 'https://t.co/rggosymo30.', 'https://t.co/rgizhubt4m', 'https://t.co/rgjphg6lbv', 'https://t.co/rgjwhgpzxs', 'https://t.co/rgmowepkfe', 'https://t.co/rgrlm6uehn', 'https://t.co/rgsdd4sqji', 'https://t.co/rh0zzush1m', 'https://t.co/rh3k6hgxdi', 'https://t.co/rhyppzupsh', 'https://t.co/rihwnivq0v', 'https://t.co/rilqzu8wpe', 'https://t.co/riovdcjwjg', 'https://t.co/ripnkfiznh', 'https://t.co/rispgs7a2r', 'https://t.co/riwhg0ymbh', 'https://t.co/rixdibyger', 'https://t.co/rixuqqg0rw', 'https://t.co/rizerlnu0u', 'https://t.co/rjbavzcemu', 'https://t.co/rjdmlwsjes', 'https://t.co/rjiyanq1ls', 'https://t.co/rjmj4bbz5d', 'https://t.co/rjsbiy44zb', 'https://t.co/rjtssqlcwx', 'https://t.co/rkabyoe1ff', 'https://t.co/rkgcgfvqdo', 'https://t.co/rkph74hz3w', 'https://t.co/rkvudprnti', 'https://t.co/rkz60kruul', 'https://t.co/rl7gy6cduh', 'https://t.co/rlctuiciho', 'https://t.co/rlqnpjofj4', 'https://t.co/rmiw5kyivn', 'https://t.co/rmkexd7kbt', 'https://t.co/rmmtlauelo', 'https://t.co/rmwxxasf45', 'https://t.co/rn2iprohku', 'https://t.co/rnikdmjcgc', 'https://t.co/rnqvxpezex', 'https://t.co/rntngmikwd', 'https://t.co/roajwp9l5w', 'https://t.co/rohnmsghns', 'https://t.co/rohnxgct82', 'https://t.co/rpasvlstep', 'https://t.co/rpyxgp7f9u', 'https://t.co/rq2kx3g7va', 'https://t.co/rqhju0iw6a', 'https://t.co/rqk0amgomq', 'https://t.co/rqqovrljmp', 'https://t.co/rquofdxfve', 'https://t.co/rr0n19uyn3', 'https://t.co/rrc3okdf7j', 'https://t.co/rrj2fd2tgd', 'https://t.co/rrsgnu3roc', 'https://t.co/rs0b0v3doz', 'https://t.co/rsn6wibvue', 'https://t.co/rsrsv8ev2p', 'https://t.co/rt0zh41hpj', 'https://t.co/rt5rd9woga', 'https://t.co/rtcdrvolsy', 'https://t.co/ruh4gdrznb', 'https://t.co/runa9fdqc4', 'https://t.co/rv9clsg0ck', 'https://t.co/rvdweld9tk', 'https://t.co/rvxtbaihzg', 'https://t.co/rwfmgknu3h', 'https://t.co/rwfucymibx', 'https://t.co/rwiv73jrfz', 'https://t.co/rwnlwku0ls', 'https://t.co/rwqg9axeh6', 'https://t.co/rwqpwvfvty', 'https://t.co/rwsnz0ceu3', 'https://t.co/rxbvl9gep3', 'https://t.co/rxdfhltlq6', 'https://t.co/rxrifaemq6', 'https://t.co/ryivuowcui', 'https://t.co/ryivupdnss', 'https://t.co/rymzjhe70r', 'https://t.co/ryrgog5sxw', 'https://t.co/rzatsh87r4', 'https://t.co/rzctmeowo4', 'https://t.co/rzfiemnbix', 'https://t.co/rzpojp6od6', 'https://t.co/rzrktinhss', 'https://t.co/rzrterpjbt', 'https://t.co/rzwlycguud', 'https://t.co/rzxesqw0i7', 'https://t.co/s2byklkq0a', 'https://t.co/s2im77po4b', 'https://t.co/s2sgjeexfu', 'https://t.co/s313vrtmbv', 'https://t.co/s4dscsm7xx', 'https://t.co/s5aicxapng', 'https://t.co/s5kmrevxcm.', 'https://t.co/s6le1tsaoe', 'https://t.co/s6qw3y02f5', 'https://t.co/s7xzswtkib', 'https://t.co/s8keeonooj', 'https://t.co/s8keeovnxb.', 'https://t.co/s8lyn4fdlk', 'https://t.co/s95tioecwn', 'https://t.co/s9pxvfy9go', 'https://t.co/sabwfrccgb', 'https://t.co/sahjge3d51', 'https://t.co/sajutqcaew', 'https://t.co/saohve4eai', 'https://t.co/sap7crrcjg', 'https://t.co/sb0khellua.', 'https://t.co/sb5iq8s5tg', 'https://t.co/sb9hzyg2mk', 'https://t.co/sbhstsr1mh', 'https://t.co/sbhx4p907f', 'https://t.co/sbpcmusfzj', 'https://t.co/sbuxc4qtyx', 'https://t.co/sc39tje5xr', 'https://t.co/scq1bqpbxd', 'https://t.co/scyn5aasmv', 'https://t.co/sd4ct5z2ck', 'https://t.co/sd5peyonoo', 'https://t.co/sdaowt6qyg', 'https://t.co/sdmncvngfg', 'https://t.co/sdypxhrhrr', 'https://t.co/se9pmceckl.', 'https://t.co/sem7etf6qu', 'https://t.co/sf29fzoju8', 'https://t.co/sfmhzssd9e', 'https://t.co/sfwkersivu', 'https://t.co/sgncd2vawf', 'https://t.co/sgrrnbvcg7', 'https://t.co/sgwr7ghxjz', 'https://t.co/sgz6htnfqv', 'https://t.co/sh4hj0xusx', 'https://t.co/shg6q7lh91', 'https://t.co/shrvs5mmpu', 'https://t.co/shydnnkf82', 'https://t.co/sijdfztph0', 'https://t.co/sj1i95brwd', 'https://t.co/sjeh3nluef', 'https://t.co/sjf1as4zbg', 'https://t.co/sjk0rzmwwu', 'https://t.co/sjolikrsje', 'https://t.co/skd06he2ub', 'https://t.co/ske1qmbbfe', 'https://t.co/skrj6gnvkv', 'https://t.co/sl8ifp4ygb', 'https://t.co/sla5uwxncg', 'https://t.co/sldrvxxfcz', 'https://t.co/sldrvxxfcz.', 'https://t.co/sllc52m2mx', 'https://t.co/sllwxhk1ip', 'https://t.co/slpaevaopw', 'https://t.co/slxklkqg2g', 'https://t.co/sm3fmh0vok', 'https://t.co/smdujaa8i0', 'https://t.co/smqhswqt56', 'https://t.co/smrasvtxko', 'https://t.co/smxkjvutjw', 'https://t.co/sn2xynx6gp', 'https://t.co/snixym9wmm', 'https://t.co/snnjpdydwv', 'https://t.co/snxt5hrhqt', 'https://t.co/so8yfe2ael', 'https://t.co/sokmkzyezq.', 'https://t.co/sotvviqc40', 'https://t.co/soxssgdj4d', 'https://t.co/sp1mxkdnv6', 'https://t.co/sp9bq8ng6j', 'https://t.co/sqd1vmszly', 'https://t.co/sqxosteghu', 'https://t.co/sr3d9jcdib', 'https://t.co/sr8cu7in29', 'https://t.co/srruh7l26k', 'https://t.co/sslspaqfv8', 'https://t.co/ssvpzecxho', 'https://t.co/stby9wcp2i', 'https://t.co/stqzuvqsxg', 'https://t.co/sufmkbqvrw', 'https://t.co/sulditahvv', 'https://t.co/suxeenrkrp', 'https://t.co/sv9pldszyw', 'https://t.co/svjhdhhhss', 'https://t.co/svoidrif72', 'https://t.co/svre0kmf4w', 'https://t.co/sw0jhaq7ac', 'https://t.co/sw0jhb7i1k', 'https://t.co/swcqc3xlyj', 'https://t.co/swdxhngajn', 'https://t.co/swjnxtd1zg', 'https://t.co/swyqfbogvk', 'https://t.co/sxszcxq62l', 'https://t.co/sy3gn5dyr6', 'https://t.co/symuaghq8v', 'https://t.co/sysilcsith', 'https://t.co/sywstohk7b', 'https://t.co/sz3kyu7kvz', 'https://t.co/szddkye7rb', 'https://t.co/szdlv1kob6', 'https://t.co/szikq4myuq', 'https://t.co/szmvfrdl1x', 'https://t.co/szthiee6c4', 'https://t.co/szunxu6jg6', 'https://t.co/szuqqp7fqu', 'https://t.co/t1g5edrfkk', 'https://t.co/t2a0ysrsmf', 'https://t.co/t2ln4yooyn', 'https://t.co/t3hxfvgxgj', 'https://t.co/t3p9eyyjfd', 'https://t.co/t46mnkxe9c', 'https://t.co/t4cxmt3pck', 'https://t.co/t4nnvivhwh', 'https://t.co/t4rmicjmxk', 'https://t.co/t52mynzwpk', 'https://t.co/t5zpt6qcol', 'https://t.co/t6i4i8jzhg', 'https://t.co/t6s1hdb0mh', 'https://t.co/t74vftkofb', 'https://t.co/t7ik1906hv', 'https://t.co/t7v5vnff0j', 'https://t.co/tabjmco5ez', 'https://t.co/tanov2xuss', 'https://t.co/tatgqdl6l3', 'https://t.co/taxi37nzjw', 'https://t.co/tb1g42wghw', 'https://t.co/tbnxig7mey', 'https://t.co/tbpyuakvql', 'https://t.co/tc2nwx0hth', 'https://t.co/tcc2qbejky', 'https://t.co/tcm38i6wpe', 'https://t.co/tco1enk5jk', 'https://t.co/tcpn0k7kot.', 'https://t.co/tctgzmlywb', 'https://t.co/tcymomcqul', 'https://t.co/tdh87rbm3b', 'https://t.co/tdlmlbdlvk.', 'https://t.co/tdmqa6t2mn', 'https://t.co/tdyve0wdmn', 'https://t.co/tdztpcsq8y', 'https://t.co/teff0fi7ys', 'https://t.co/tefri8igot', 'https://t.co/tehuasgk0l', 'https://t.co/teq1p4cvp4', 'https://t.co/tf2fd4yskf', 'https://t.co/tfhpdvjsa9', 'https://t.co/tfsckou50j', 'https://t.co/tfummxsmzy', 'https://t.co/tfy9s186zr', 'https://t.co/tfzpdffyrc', 'https://t.co/tg1rvoezxs', 'https://t.co/tg2cktjskp', 'https://t.co/tg37vakede', 'https://t.co/tga4g4fzbf', 'https://t.co/tguw34cdjy', 'https://t.co/tgwbluv3lg', 'https://t.co/tgwcxm9uyy', 'https://t.co/tgys6ioryv', 'https://t.co/thb4fwhd0m', 'https://t.co/thlnxo4yfc', 'https://t.co/thnlkqvgop', 'https://t.co/thq8ms7ilt', 'https://t.co/tidupq6mbo', 'https://t.co/tijv32eltv', 'https://t.co/tinvxiehvx', 'https://t.co/tirm5nkalb', 'https://t.co/tizw3jwdbf', 'https://t.co/tjo9w5rre6', 'https://t.co/tjsinzqc9u', 'https://t.co/tjuqb7kmph', 'https://t.co/tkinu8jvyf', 'https://t.co/tkiuemc1ax', 'https://t.co/tklylbwhc5', 'https://t.co/tkm1v6act2', 'https://t.co/tkno3wmtxl', 'https://t.co/tkurp8lz0h', 'https://t.co/tkyxqyrnok', 'https://t.co/tl59tjvqj9', 'https://t.co/tlilhg9ogs.', 'https://t.co/tlua5u9q69', 'https://t.co/tlw5gup7hr', 'https://t.co/tme4omkrvt', 'https://t.co/tmmvou4rzd', 'https://t.co/tmtmc5cbia', 'https://t.co/tmxhftkhjn', 'https://t.co/tnpx5fnvg6.', 'https://t.co/tobfphyfmk', 'https://t.co/torjeoohnv', 'https://t.co/tpbnintiwc', 'https://t.co/tpd86dle42', 'https://t.co/tpuhogpvwt', 'https://t.co/tqpawlwjdz', 'https://t.co/tqtady78dh', 'https://t.co/tqufhmybf1', 'https://t.co/trc6wahohh', 'https://t.co/trjb0e9xpq', 'https://t.co/trkrj6xdbt', 'https://t.co/trrpktmquj', 'https://t.co/trtpbmu5ob', 'https://t.co/trvo4ypkgf', 'https://t.co/tsbomm9qff', 'https://t.co/tsmpzvb7gs', 'https://t.co/tst030hhbn', 'https://t.co/tsvd8mfsm7', 'https://t.co/tt49zoec8n.', 'https://t.co/tt49zon1hf', 'https://t.co/tt49zon1hf.', 'https://t.co/ttauadehwy', 'https://t.co/ttbxqwqjhz', 'https://t.co/ttcquwqgle', 'https://t.co/ttn6qas7am', 'https://t.co/ttocbbwtmp', 'https://t.co/tud4upsdio', 'https://t.co/tuohxwun8u', 'https://t.co/tuva8tb4tf', 'https://t.co/tv9jete0oi.', 'https://t.co/tvucp7j2dn', 'https://t.co/tvwemzzpdh', 'https://t.co/tvzp0zisnh', 'https://t.co/twef6e8r6k', 'https://t.co/twmhy2t93d', 'https://t.co/twoavdze1x', 'https://t.co/twoavdze1x.', 'https://t.co/twuuxl0yzn', 'https://t.co/txck6m8hvp', 'https://t.co/tytmwexio8', 'https://t.co/tyuuuvlaoe', 'https://t.co/tywaicolri', 'https://t.co/tzb9fzm6fp', 'https://t.co/tzchlfbxtg', 'https://t.co/tzot2qazp8', 'https://t.co/u0ls18ioyf', 'https://t.co/u0t1njmssx', 'https://t.co/u1knxcxskc', 'https://t.co/u2b9dwtqxa', 'https://t.co/u2ursbopdj', 'https://t.co/u39bedxiv8', 'https://t.co/u41s8bvyxk', 'https://t.co/u438lvkslg', 'https://t.co/u4o1ja30d1', 'https://t.co/u5jh1xw8nw', 'https://t.co/u5ttl3m572', 'https://t.co/u6c7g0zuh0', 'https://t.co/u8s6artvh3', 'https://t.co/u942yvfskt', 'https://t.co/uaays6uhsg', 'https://t.co/uac45bd9xc', 'https://t.co/uackidmrq2', 'https://t.co/uaj29xa1y5', 'https://t.co/uamd2xavpm', 'https://t.co/uao00rybys', 'https://t.co/uaoxltrfdt', 'https://t.co/uargztrh5l', 'https://t.co/uargztrh5l.', 'https://t.co/uasjdxdagq', 'https://t.co/uaws1omper', 'https://t.co/ub8hzyzezf', 'https://t.co/ubbdeu1ebm', 'https://t.co/ubesb5qz3p', 'https://t.co/ubfeluso6m', 'https://t.co/ubpqaxk9xr', 'https://t.co/ucfnxpdbs4', 'https://t.co/uclvtdlajm', 'https://t.co/ucsdnisy9z', 'https://t.co/ucsj8aicqd', 'https://t.co/ucxdklszfn', 'https://t.co/ucxpytypit', 'https://t.co/ucyaqrrq2m', 'https://t.co/ud0xxee4pr', 'https://t.co/udektqciat', 'https://t.co/udfsmrdu60', 'https://t.co/udnd89r1zl', 'https://t.co/udyrs1iniw', 'https://t.co/ue2sqymwvu', 'https://t.co/uebsnldirr.', 'https://t.co/uefaj1ydtj', 'https://t.co/uegozko37r', 'https://t.co/uep3rg36yq', 'https://t.co/uepnhl9znm', 'https://t.co/ufaofpw0yl', 'https://t.co/ufdtothh6x', 'https://t.co/uft4ztnye3', 'https://t.co/uftuh1rbij', 'https://t.co/ug3inz7aii', 'https://t.co/ugbqocxbvo', 'https://t.co/ugebo1su2o', 'https://t.co/ugfqgwe9sx', 'https://t.co/ugmnn0vvle', 'https://t.co/ugmspu4mmh', 'https://t.co/ugon41cy2h', 'https://t.co/uhd6ifv8ot', 'https://t.co/uherg8edun', 'https://t.co/uhhmcaydla', 'https://t.co/uhkzfghgtd', 'https://t.co/uhtoqf8cp7', 'https://t.co/uip0zhqeee', 'https://t.co/uisf61j5iy', 'https://t.co/uixua7tjub', 'https://t.co/uiz1vjshp1', 'https://t.co/ujfumcrise', 'https://t.co/ujguetzyda', 'https://t.co/ujhegnjq0x', 'https://t.co/ujsose2syr', 'https://t.co/ujwxfyx2tv', 'https://t.co/ujyvdpks5m', 'https://t.co/uk28svfvxo', 'https://t.co/uk8iwzqkm3', 'https://t.co/ukf3jezpos', 'https://t.co/ulbshv89ol.', 'https://t.co/ulsgqzjs2c', 'https://t.co/ulxqbygt4j', 'https://t.co/umfipq69nz', 'https://t.co/umg2y6af0k', 'https://t.co/umxqbsb39f', 'https://t.co/unbw0ptj2h', 'https://t.co/unj31uemeh', 'https://t.co/unlkvon7ji', 'https://t.co/unlobdneo0', 'https://t.co/unlve1kcgw', 'https://t.co/unpwzlb7xu.', 'https://t.co/untrjwwxkg', 'https://t.co/uocg7nqi4a', 'https://t.co/uogq5aaurl', 'https://t.co/uoipnkhcnr', 'https://t.co/uou8p925u9', 'https://t.co/uovxykhryz', 'https://t.co/upgh9m7cg8', 'https://t.co/upqwmtfn37', 'https://t.co/upt9mzmcs8', 'https://t.co/uqhmmoq9zn', 'https://t.co/uqptqsetk5', 'https://t.co/uqrbeifm0f', 'https://t.co/uqvydke9xk', 'https://t.co/ur6jplo3wh', 'https://t.co/urampqrd4o', 'https://t.co/urrkc0kxpq', 'https://t.co/urssms60ac', 'https://t.co/urwh11lamf', 'https://t.co/urwsemvsa5', 'https://t.co/usgkdfoe9g', 'https://t.co/usk6kokgoy', 'https://t.co/usvoiwwr3r', 'https://t.co/utddi7matk', 'https://t.co/uu1k74ihik', 'https://t.co/uuevh9u9ts', 'https://t.co/uuevhabks2', 'https://t.co/uuttdake7b', 'https://t.co/uuvvd0x5j9', 'https://t.co/uvfbawrbhb', 'https://t.co/uvzipzei1n', 'https://t.co/uw9eaqtaf7', 'https://t.co/uwa2pclngr', 'https://t.co/uwepwev9ho', 'https://t.co/uwscnvzq9m', 'https://t.co/uwy8mjbxgb', 'https://t.co/ux4enfmay1', 'https://t.co/uxcev1vnbb', 'https://t.co/uxegrj7umj', 'https://t.co/uxltgmkjip', 'https://t.co/uxsodlhrj8', 'https://t.co/uybfzuwvue.', 'https://t.co/uyn7a6uegl', 'https://t.co/uz6d2aq9lu', 'https://t.co/uzvo7z9kxc\"', 'https://t.co/v0f20rq57g', 'https://t.co/v0kzn4n14b', 'https://t.co/v0olb32gkv.', 'https://t.co/v0ya3pm0i9', 'https://t.co/v1do6ds7op', 'https://t.co/v1ggyg5m6y', 'https://t.co/v1sem2fqeq', 'https://t.co/v2m7kb50sv', 'https://t.co/v38beoju1v', 'https://t.co/v4aownphun', 'https://t.co/v4sa2umgm7', 'https://t.co/v68of6irif', 'https://t.co/v6enpsxuh3', 'https://t.co/v6nutftfrf', 'https://t.co/v6ygzvswko', 'https://t.co/v7a0nzehuv', 'https://t.co/v7yic1d8my', 'https://t.co/v7zfbr9ud4', 'https://t.co/v9lwasrwxs', 'https://t.co/v9wvbfwav2', 'https://t.co/va6ptunrcl', 'https://t.co/vaembn2qo0', 'https://t.co/vaextxps8s.', 'https://t.co/vb1dqhrw7b', 'https://t.co/vb8i70nafm', 'https://t.co/vbfas6yqyj', 'https://t.co/vbr8fuykm6', 'https://t.co/vc2dl9vmok', 'https://t.co/vcly7usizr', 'https://t.co/vdj1yhqiqw', 'https://t.co/vdqsv7xvub', 'https://t.co/vdzvj4dcea', 'https://t.co/ve0dngntdm', 'https://t.co/veaukpkaqx', 'https://t.co/veske4kcvi', 'https://t.co/vet04orsdi', 'https://t.co/vf5mtmb27i', 'https://t.co/vfub3eoirm', 'https://t.co/vgflhn5bjl', 'https://t.co/vgqida4pwv', 'https://t.co/vgzrm6uwgw', 'https://t.co/vhejvx06cx', 'https://t.co/vhhgwmemhq', 'https://t.co/vhn6z512du', 'https://t.co/vhtmlqfeg7', 'https://t.co/vih89d6gzj', 'https://t.co/vipc38rewz', 'https://t.co/viseqj4qy4', 'https://t.co/vj6ddnlasm.', 'https://t.co/vjjbb3mmrl', 'https://t.co/vjobnbpyaw', 'https://t.co/vkk6hhxrqd', 'https://t.co/vkmfpxxryu', 'https://t.co/vkvkvfc8tf', 'https://t.co/vkxevcr1m4', 'https://t.co/vldiswteyn', 'https://t.co/vldzfrneaj', 'https://t.co/vlncib4q18', 'https://t.co/vm8npwhuks', 'https://t.co/vm9kdihvwk', 'https://t.co/vmep0hhnbc', 'https://t.co/vmp48pegcq', 'https://t.co/vn2lxxewpr', 'https://t.co/vn4d8m6hch', 'https://t.co/vn96i8m5yd', 'https://t.co/vnnly5tiao.', 'https://t.co/vnqjvd9ksn', 'https://t.co/vnqr3kxq46', 'https://t.co/vnx5qxmqjw', 'https://t.co/vokbzil9ob.', 'https://t.co/voxzq4dqth', 'https://t.co/vpb4okrdep', 'https://t.co/vpe5dcsyzz', 'https://t.co/vpiyadvew1', 'https://t.co/vpmi4nsmyv', 'https://t.co/vpqa62ggqr', 'https://t.co/vpurrkopvs', 'https://t.co/vpxfqy6rpi', 'https://t.co/vqg3ezgnos', 'https://t.co/vrey6mxggi', 'https://t.co/vrhtgjirmq', 'https://t.co/vrwwuihowq', 'https://t.co/vs0necud4i', 'https://t.co/vsfm1536o7', 'https://t.co/vsihwf4d68', 'https://t.co/vsjjthqrvv', 'https://t.co/vst2mpeluq', 'https://t.co/vt1gpunx5b', 'https://t.co/vt8hikfygy', 'https://t.co/vt9bp9m1wd', 'https://t.co/vtachszvuz', 'https://t.co/vtjgcsornu', 'https://t.co/vu2xspc5pf', 'https://t.co/vubukvzytn', 'https://t.co/vufkbb9bma', 'https://t.co/vul1m40jlh', 'https://t.co/vuyx19nzpe.', 'https://t.co/vuyx19woy6.', 'https://t.co/vv3l3rcgvj', 'https://t.co/vvizx7o3mm', 'https://t.co/vvtjcr9fvs', 'https://t.co/vw8zvcetus', 'https://t.co/vwikukok0y', 'https://t.co/vwvkebacnf.', 'https://t.co/vx8ocpgnwx', 'https://t.co/vxjuvzv4bb', 'https://t.co/vxyfhndouo', 'https://t.co/vxzjcd14ob', 'https://t.co/vymec4om3f', 'https://t.co/vz9zhjcuho', 'https://t.co/vzc11bvo8k', 'https://t.co/vzfkxfkisr', 'https://t.co/vznix69svh', 'https://t.co/vzvlv3tgn4', 'https://t.co/vzz8uppyqm', 'https://t.co/w0a8m6yewl', 'https://t.co/w0dy2r6mfz', 'https://t.co/w0jbm4rkh1', 'https://t.co/w0jguvacjt', 'https://t.co/w0rtlokopb', 'https://t.co/w0uidqtc4b', 'https://t.co/w1mpunitvh', 'https://t.co/w2q4cgocju', 'https://t.co/w2yzwmja5f', 'https://t.co/w3u2szgqel.', 'https://t.co/w4477louqz', 'https://t.co/w4guuofsrh', 'https://t.co/w4nztxknzz', 'https://t.co/w5eznwgryj', 'https://t.co/w5firththp', 'https://t.co/w602glalxh', 'https://t.co/w6sejjhbi6', 'https://t.co/w6uoyrxq3q', 'https://t.co/w72p7hhyfb', 'https://t.co/w87gozl9qh', 'https://t.co/w8mrzqvinz', 'https://t.co/w8uwi3ojhm', 'https://t.co/w9745xxurs', 'https://t.co/w9gkunudv6', 'https://t.co/w9jlzbohss', 'https://t.co/waqehbttey', 'https://t.co/waqgluhb3s', 'https://t.co/wb3rfvporr', 'https://t.co/wban7thfm2', 'https://t.co/wbbgigmr52', 'https://t.co/wbdyipiucc', 'https://t.co/wbmftqle9k', 'https://t.co/wbqwntjfjv', 'https://t.co/wbvgig9yc0.', 'https://t.co/wcflv3xb8h', 'https://t.co/wcs5atlthx', 'https://t.co/wda1fy8jaz', 'https://t.co/wdfel3b5aq', 'https://t.co/wdooccixfu', 'https://t.co/wef6x3ecbb', 'https://t.co/wet4nuijhy', 'https://t.co/wezxq6kbdc', 'https://t.co/wf1up6kz5k', 'https://t.co/wfp3li5vrp', 'https://t.co/wfwxug5bui', 'https://t.co/wfzsxx3bjk', 'https://t.co/wgfumgxjrp', 'https://t.co/wgijthaagp', 'https://t.co/wgrconvd9t.', 'https://t.co/wgrtt48jue', 'https://t.co/wguulcbijl', 'https://t.co/wh5gkjf3kh', 'https://t.co/whkdgwwaw8', 'https://t.co/wi9ubqmii3', 'https://t.co/wiufbkr3uh', 'https://t.co/wivmo3xbfv', 'https://t.co/wivuvvfmu5', 'https://t.co/wiwgobylxf', 'https://t.co/wiybsfnetx', 'https://t.co/wjinjkyi4a', 'https://t.co/wjpigeupae', 'https://t.co/wjw9od8kaz', 'https://t.co/wk2jjialj7', 'https://t.co/wka1rxjy2o', 'https://t.co/wkgjiymu1b', 'https://t.co/wkn4aqcigt', 'https://t.co/wkq4w9dchb', 'https://t.co/wkrwbgruwd', 'https://t.co/wksnmc7pi3', 'https://t.co/wktyjp5gpc', 'https://t.co/wlbfspafzw', 'https://t.co/wlo15zhmwf', 'https://t.co/wlp3gx6f5t', 'https://t.co/wlpldjfzem', 'https://t.co/wlq0tssx59', 'https://t.co/wlz02vgysm', 'https://t.co/wm8kyp2vaf', 'https://t.co/wmhgseg08c', 'https://t.co/wmtcqqycna', 'https://t.co/wmy7wjlb2k', 'https://t.co/wmznwl2uya', 'https://t.co/wnadxwp1oc', 'https://t.co/wnghinbqdr', 'https://t.co/wnj8iqlrf5', 'https://t.co/wnkbxrc4tl', 'https://t.co/wnyi0b4fcg', 'https://t.co/wo0styf91e', 'https://t.co/wo8ngyxdle', 'https://t.co/wodw3xeccn', 'https://t.co/wollj4pglc', 'https://t.co/wontgfuuxn', 'https://t.co/woolrigvku', 'https://t.co/woplkz1bzc', 'https://t.co/worpvv8if2', 'https://t.co/wotsjkcv4d', 'https://t.co/wou7q1pfio', 'https://t.co/wpokewonej', 'https://t.co/wq0ufoupqh.', 'https://t.co/wq30d52izq', 'https://t.co/wqfekc8jqa', 'https://t.co/wqjjdbl870', 'https://t.co/wrhckyi1fu', 'https://t.co/wrzffjjbtl', 'https://t.co/ws0bqdlc1y', 'https://t.co/ws1lw6rhas', 'https://t.co/wscckxnyeb', 'https://t.co/wsevdvm0tp', 'https://t.co/wsex2fpcu3', 'https://t.co/wsn2ghkzrp', 'https://t.co/wsn4mvdikk.', 'https://t.co/wsnm1myoc2', 'https://t.co/wsny2oyymd', 'https://t.co/wt3fblz2cl', 'https://t.co/wtdfqgnqz4', 'https://t.co/wtrijwju9t', 'https://t.co/wtvned5fut', 'https://t.co/wuddteyxxd', 'https://t.co/wukazk9ale', 'https://t.co/wvajisgysw', 'https://t.co/wvio4b4eff', 'https://t.co/wvyok4lfzn', 'https://t.co/wwaghilpso', 'https://t.co/wwdyvm3nnl', 'https://t.co/wwjpru2vbp', 'https://t.co/wx85tr8wce', 'https://t.co/wx9pvlfnav', 'https://t.co/wxtukphynb', 'https://t.co/wy9mzx1lsr', 'https://t.co/wytp7o8wgx.', 'https://t.co/wywrhs5brr', 'https://t.co/wyxdaw6flw', 'https://t.co/wyzbdvrqsh', 'https://t.co/wzmvu3e3p7', 'https://t.co/wzoqiacuyu', 'https://t.co/wzq5ma5edn', 'https://t.co/wzqvk0iu9f', 'https://t.co/x0vknyj84j', 'https://t.co/x1qmkvwvj9', 'https://t.co/x2hcebjmel', 'https://t.co/x2nqnlbov9', 'https://t.co/x37sezyao1', 'https://t.co/x3oe2rwa1k', 'https://t.co/x4bjbpsaom', 'https://t.co/x4fmtcabcc', 'https://t.co/x4vbhjjben', 'https://t.co/x5mnhg0lyt', 'https://t.co/x5zn4uikhy', 'https://t.co/x6fu7pk4ob', 'https://t.co/x6h7imowcg', 'https://t.co/x73jpbq18i', 'https://t.co/x7dxuhrucd', 'https://t.co/x8jcqo7lfd', 'https://t.co/x8ntbcvlfu', 'https://t.co/x9evi84zmk', 'https://t.co/x9hmgolxmz', 'https://t.co/xa1qkwzjho', 'https://t.co/xa1qkwzjho.', 'https://t.co/xa7oumrlcc', 'https://t.co/xaayqnvxbd', 'https://t.co/xab9s6yymg', 'https://t.co/xaqbij966c', 'https://t.co/xavngvjvgx', 'https://t.co/xawbq9iqrh', 'https://t.co/xb8sk1bonk', 'https://t.co/xbbsutslkv', 'https://t.co/xbfflajw0g', 'https://t.co/xbggps0npg', 'https://t.co/xby3er8k0p', 'https://t.co/xc1nqnlw8c', 'https://t.co/xcgcecp31w', 'https://t.co/xciqed7qbd', 'https://t.co/xd7gyk6dn7', 'https://t.co/xdfm4f80bx', 'https://t.co/xdppqnzbzp', 'https://t.co/xe13ljlv44', 'https://t.co/xf3wah2g31', 'https://t.co/xfbs5icjn3', 'https://t.co/xfeqz7sbff', 'https://t.co/xfh2bpcour', 'https://t.co/xfjzpekawz', 'https://t.co/xfpmdthkxx', 'https://t.co/xg4ntcwml9', 'https://t.co/xgpkpdvn0r', 'https://t.co/xgtpnfcpij', 'https://t.co/xhphxurnvy', 'https://t.co/xht7gsfsgy', 'https://t.co/xi1zl0u7zh', 'https://t.co/xi9sv6fk4z', 'https://t.co/xikkpuivzd', 'https://t.co/xilglumgso', 'https://t.co/xixexdccg5', 'https://t.co/xjadbpoakr', 'https://t.co/xjmclrwz3i', 'https://t.co/xjxsdn2qcd', 'https://t.co/xk6yufw3z2', 'https://t.co/xkegzc7duu', 'https://t.co/xkf5fzyquj', 'https://t.co/xkrpcvqjxc', 'https://t.co/xkxebsubik', 'https://t.co/xkxsnmax7s', 'https://t.co/xl5uqsoubf', 'https://t.co/xl7qefqawq', 'https://t.co/xlcm9ygatj', 'https://t.co/xleld3unjw', 'https://t.co/xlhjdea4g7', 'https://t.co/xlr7cqfcqm', 'https://t.co/xlziji5meo', 'https://t.co/xm04wiasgu', 'https://t.co/xm4beezav1', 'https://t.co/xmwgqqhfg6', 'https://t.co/xn9bk1zzxj', 'https://t.co/xnhsjrblff', 'https://t.co/xnjoy41dbc', 'https://t.co/xnkztzlpqc', 'https://t.co/xnsswth9dc', 'https://t.co/xnupv0o9ed', 'https://t.co/xo1wg4qdyt', 'https://t.co/xof1nbiycy', 'https://t.co/xowibklxsd', 'https://t.co/xoyagagmzs', 'https://t.co/xq3b7o0yib', 'https://t.co/xq91oaysoy', 'https://t.co/xr9uxftx5f', 'https://t.co/xrey2ncs7n', 'https://t.co/xrmru7lx6f', 'https://t.co/xrqbinmqft', 'https://t.co/xsbv8dwgxs', 'https://t.co/xsjoqgm73l', 'https://t.co/xtinb3o8bx', 'https://t.co/xu28jldxvw', 'https://t.co/xu7xyqwemi', 'https://t.co/xubnxlzynm', 'https://t.co/xuevsecilk', 'https://t.co/xukmqn57fu', 'https://t.co/xuo7oqlm50', 'https://t.co/xv0pdukvg2', 'https://t.co/xv52fcvng9', 'https://t.co/xveaaqhrmp', 'https://t.co/xvkan77vcs', 'https://t.co/xvni1ywvfz', 'https://t.co/xw6qcwhafu', 'https://t.co/xwamolbw5k', 'https://t.co/xwfxvoyvd6', 'https://t.co/xwsslvi7zq', 'https://t.co/xxbp6lx2ms', 'https://t.co/xxbvywtarw', 'https://t.co/xxpdhfg0hg', 'https://t.co/xyeiwdbwqc', 'https://t.co/xyt8thglfe', 'https://t.co/xz1xx9oynt', 'https://t.co/xzounruoi7', 'https://t.co/y0pvkpujzr', 'https://t.co/y0sywh3b68', 'https://t.co/y1gqugsmwi', 'https://t.co/y1ldnwnywg', 'https://t.co/y2gnsinw7j', 'https://t.co/y31nn33zho', 'https://t.co/y3ezywpjld', 'https://t.co/y3qswuj23i', 'https://t.co/y3voxfzlii', 'https://t.co/y49ykd5os2', 'https://t.co/y6xg8ny2fq', 'https://t.co/y7lyfceln2', 'https://t.co/y7vvpuhurh', 'https://t.co/y8erhlprgr', 'https://t.co/y8tdrudpt2', 'https://t.co/y8ynpil6q2', 'https://t.co/y97tugzlxy', 'https://t.co/y9nizlnbcu', 'https://t.co/yadnqbx2xj', 'https://t.co/yapqkvdncj', 'https://t.co/yaqbeg5anv', 'https://t.co/yar4oabpbo', 'https://t.co/yasgrtt4ux', 'https://t.co/yb16z6yybd', 'https://t.co/yb3tgyya4c', 'https://t.co/ybmnw35za5', 'https://t.co/ybth4sobzt', 'https://t.co/yccw7laqeo', 'https://t.co/ycffydxbeh', 'https://t.co/ycfr61hm4c', 'https://t.co/ycgqly8le3', 'https://t.co/yd5y23vs6b', 'https://t.co/yd7ve5m4ru', 'https://t.co/ydayzhexwl', 'https://t.co/ydhvl06n4m.', 'https://t.co/ydtiiip02r', 'https://t.co/ydtvnjlm6m', 'https://t.co/ydyueofir4', 'https://t.co/ye55etgpxz', 'https://t.co/yeovbpqzju', 'https://t.co/yf7zktbfbw', 'https://t.co/yf8dirnav4', 'https://t.co/yfmhi9xfyl', 'https://t.co/yfozahlnrl', 'https://t.co/ygjbmvfu9y', 'https://t.co/ygpa8asse6', 'https://t.co/ygwd8qihpx', 'https://t.co/yh3zxknnhz', 'https://t.co/yhiwepz8ik', 'https://t.co/yhklh8e8ue', 'https://t.co/yhpeb4e0ax', 'https://t.co/yi9tchehsa', 'https://t.co/yihkwugyj9', 'https://t.co/yistqpnlny', 'https://t.co/yivn71b47z', 'https://t.co/yjldxlpwqe', 'https://t.co/ykgdf9qbuk', 'https://t.co/ykoix7ama5', 'https://t.co/ylcvlzbxsv', 'https://t.co/ylisgyntqv', 'https://t.co/ymehxx5dxc', 'https://t.co/ymlowpxoxo', 'https://t.co/ymyl1de2xu', 'https://t.co/ynjwpobndu', 'https://t.co/yo8y2sfjym', 'https://t.co/yoklhxoxhq', 'https://t.co/yookabsidq', 'https://t.co/yorxfuygac', 'https://t.co/yoycpflaag', 'https://t.co/ypfgilt3kz', 'https://t.co/ypks7r77vs', 'https://t.co/yqhhsalzi3', 'https://t.co/yqi8i0nahk', 'https://t.co/yqlzdmkxjf', 'https://t.co/yqvuorbmrk', 'https://t.co/yrcndtilfs', 'https://t.co/yrl6wqayvm', 'https://t.co/yrnbulrjrt', 'https://t.co/yrryn9jkkd', 'https://t.co/yrwnhf6ezc', 'https://t.co/yrxdc9ga2f', 'https://t.co/ysahnzwnnu', 'https://t.co/ysudbuni8y', 'https://t.co/ysuwn4vir0', 'https://t.co/ytiysuztux', 'https://t.co/yuevwdzkma', 'https://t.co/yvbkdtnzeu', 'https://t.co/yvex3d7ien', 'https://t.co/yvw3ojqaom', 'https://t.co/yw1nor2h1v', 'https://t.co/ywj4kzjget', 'https://t.co/ywoxx6vjhk.', 'https://t.co/ywqomuphbp', 'https://t.co/yxn76gqa9c', 'https://t.co/yyfyuziehn', 'https://t.co/yyihrou7ep', 'https://t.co/yykj2m5ozj', 'https://t.co/yypvdowjh3', 'https://t.co/yytvzdpywy', 'https://t.co/yywv4kzoil', 'https://t.co/yzbullncvw', 'https://t.co/yzmpm1zmvw', 'https://t.co/yzoyrskdrh', 'https://t.co/z0s52mtwev', 'https://t.co/z1xzotqznt', 'https://t.co/z39q1vj6b0', 'https://t.co/z4nt1ej6u3', 'https://t.co/z52upszwri', 'https://t.co/z59w7ahy6c', 'https://t.co/z5aeal3fba', 'https://t.co/z5x7ufxpxd', 'https://t.co/z6nswrbn64', 'https://t.co/z6qkzptwxs', 'https://t.co/z7hf0aim8t', 'https://t.co/z7vjvdglhw', 'https://t.co/z87x8y6eza', 'https://t.co/z8o6cmc1na', 'https://t.co/z9k0shxj1g.', 'https://t.co/z9qn80epex', 'https://t.co/za3rso8wtu', 'https://t.co/za5195kas3.', 'https://t.co/zaakfiy8of', 'https://t.co/zajfhkenkm', 'https://t.co/zao8myr3jf', 'https://t.co/zaqeuzpywk', 'https://t.co/zaqzsp6y0u', 'https://t.co/zar9ysqpg7', 'https://t.co/zaw7cux9gp', 'https://t.co/zb3edu6g6d', 'https://t.co/zbaodgpuw5', 'https://t.co/zbbrtgzufb', 'https://t.co/zbrmt7op33', 'https://t.co/zbroovi5ni', 'https://t.co/zbucb6kdfo', 'https://t.co/zc39azvrge', 'https://t.co/zc9ez90bhe', 'https://t.co/zcl387bzlk', 'https://t.co/zcm7gbuvet', 'https://t.co/zcm7yhdirx', 'https://t.co/zcmozmd0pt', 'https://t.co/zcralvr4ro', 'https://t.co/zdckhk5xop', 'https://t.co/zdp24h1pyy', 'https://t.co/zdp4hkbl1w', 'https://t.co/zfaousoi4t', 'https://t.co/zfgtnxmadb', 'https://t.co/zfuwup75js', 'https://t.co/zfxlgjivjj', 'https://t.co/zghmvmhxyz', 'https://t.co/zgk7dyzkmm', 'https://t.co/zgmzaouc69', 'https://t.co/zgrvmqpfpu', 'https://t.co/zhg3llhdlb', 'https://t.co/zhgpeeuzzp', 'https://t.co/zhhrf0r46s', 'https://t.co/zidi8uuzqj', 'https://t.co/ziinu3zea3', 'https://t.co/zin6ib4jdi', 'https://t.co/zisas5igcn', 'https://t.co/zivrwbdkgj', 'https://t.co/zjekiqg5jg.', 'https://t.co/zjekiqous8.', 'https://t.co/zjn60klll9', 'https://t.co/zjx28vbcag', 'https://t.co/zk8fashkim', 'https://t.co/zkbaeyzq6e', 'https://t.co/zkdtwwgpu9', 'https://t.co/zkhw5tnglz', 'https://t.co/zkosxn0qtl', 'https://t.co/zkqm3oexgh', 'https://t.co/zkselwpqfi', 'https://t.co/zkyvo21zp2', 'https://t.co/zlarels1hx', 'https://t.co/zlg47bwerb', 'https://t.co/zltdrn9bj4', 'https://t.co/zm1p5h9cvt', 'https://t.co/zm2lv0hgkz', 'https://t.co/zmcntceqew', 'https://t.co/zndslcc19z', 'https://t.co/zoidyiengk', 'https://t.co/zoyclneupi', 'https://t.co/zp4vylo0pb', 'https://t.co/zp4vylo0pb.', 'https://t.co/zpi5wx1kb2', 'https://t.co/zpl51dmyiy', 'https://t.co/zpnzjt7cps', 'https://t.co/zqrpneofet', 'https://t.co/zrmrylqsww', 'https://t.co/zsemcskgp1', 'https://t.co/zsh1xfze5y', 'https://t.co/zt9ngwzkci', 'https://t.co/ztpck5tnjx', 'https://t.co/ztqnsxeqbk', 'https://t.co/ztr5ssmqli', 'https://t.co/ztram9878j', 'https://t.co/zttbyzpabl', 'https://t.co/ztyhjzn1hv', 'https://t.co/zuflymft2l', 'https://t.co/zukeu7k2d5', 'https://t.co/zutycuzrv1', 'https://t.co/zuxra2sfke', 'https://t.co/zvmaqfs2ba', 'https://t.co/zvs7lklatm', 'https://t.co/zwflrzghxe', 'https://t.co/zwgj41u5go', 'https://t.co/zwpc9qowyu', 'https://t.co/zwtfmuu2xn', 'https://t.co/zwwwp8q6tb', 'https://t.co/zxferiys6i', 'https://t.co/zylmznfoeg', 'https://t.co/zyo7s2bdee', 'https://t.co/zyv5asylqa', 'https://t.co/zyzznbge6m', 'https://t.co/zzetuvlqzv', 'https://t.co/zzmgdntlcg', 'https://t.co/zzmgvtsqgt', 'https://t.co/zztdrenzuf', 'https://t.c…', 'https://www.tatahealth.com/online-doctor-consultation/general-physician', 'https:/…', 'https:…', 'http…', 'huawei', 'hub', 'hubei', 'huckabee', 'huddled', 'huge', 'hugely', 'hugging', 'hugo', 'human', 'human-made', 'humanitarian', 'humanity', 'humanly', 'humanmade', 'humidity', 'humor', 'hundred', 'hunger', 'hungry', 'hunting', 'huoshenshan', 'hurricane', 'hurt', 'husband', 'hussain', 'hussein', 'hut', 'hv', 'hyde', 'hyderabad', 'hyderbad', 'hydrochloroquine', 'hydrogen', 'hydroquinone', 'hydroxichloroquine', 'hydroxy', 'hydroxychloroqen', 'hydroxychloroquin', 'hydroxychloroquine', 'hydroxychloroquineis', 'hydroxydhloroquine', 'hygiene', 'hypercapnia', 'hypermarket', 'hypochlorite', 'hypochondria', 'hypoxia', 'hypoxia\"', 'hysteria', 'hysteria\"', 'hy…', 'h…', 'h😎', 'i', 'i&ampii', 'ia', 'ians', 'ibadan', 'ibd', 'ibom', 'ibom1', 'ibom10', 'ibom11', 'ibom12', 'ibom13', 'ibom17', 'ibom18', 'ibom2', 'ibom22', 'ibom5', 'ibom8', 'ibom9', 'ibrahim', 'ibuprofen', 'icai', 'ice', 'iceberg', 'ickes', 'icmr', 'icu', 'icu…', 'icu\\u2063', 'icu\\u2063\\u2063\\u2063\\u2063', 'icymi', 'id', 'id2020', 'idaho', 'idea', 'identification', 'identified', 'identify', 'identifying', 'identity', 'idh', 'idiocy', 'idlisdosasmeals', 'idol', 'ie', 'iea', 'if', 'iffy', 'iga', 'igg', 'igm…', 'ignorance', 'ignore', 'ignored', 'ignores', 'ignoring', 'ihme', 'ihr', 'ii', 'iii', 'iit', 'il', 'ill', 'illa', 'illegal', 'illegally', 'illinformed', 'illinois', 'illinoisan', 'illness', 'illogical', 'illprepared', 'illustrate', 'illustration', 'ill’', 'im', 'image', 'imagined', 'imam', 'imf', 'imitating', 'immanuel', 'immediate', 'immediately', 'immediately.�', 'immigrant', 'immigration', 'immobilizing', 'immune', 'immunisation', 'immunity', 'immunization', 'immunize', 'immunogenic', 'immunoglobulin', 'immunologist', 'immunoresponse', 'immunosuppression', 'immuntiy', 'imo', 'imo1', 'imo12', 'imo13', 'imo14', 'imo15', 'imo2', 'imo23', 'imo26', 'imo29', 'imo3', 'imo4', 'imo46', 'imo5', 'imo8', 'imo9', 'imp', 'impact', 'impact@drtedros', 'impacted', 'impacting', 'impassioned', 'impeachment', 'imperative', 'imperial', 'implant', 'implanted', 'implanting', 'implement', 'implementation', 'implemented', 'implemention', 'implication', 'implicitly', 'implies', 'imply', 'implying', 'import', 'importance', 'important', 'importantly', 'importanttesting', 'important—and', 'imported', 'imported\\u200b', 'impose', 'imposed', 'impossible', 'imposter', 'impressed', 'impression', 'impressive', 'imprisonment', 'improperly', 'improve', 'improved', 'improvement', 'improves', 'improving', 'impt', 'imran', 'in', 'inability', 'inaccessible', 'inaccurate', 'inactivated', 'inactive', 'inadequate', 'inarguable', 'inaugural', 'inauguration', 'inc', 'incentive', 'inch', 'inching', 'incidence', 'incident', 'incidents👍', 'incinerated', 'incl', 'include', 'included', 'includes', 'including', 'inclusion', 'income', 'incompetence', 'incomplete', 'incorporated', 'incorporates', 'incorrect', 'incorrectly', 'increase', 'increased', 'increase…', 'increasing', \"increasing'\", 'increas…', 'incubation', 'incurred', 'indecipherable', 'indefinite', 'indefinitely', 'independent', 'index', 'india', 'india)', 'india.', 'indiaas', 'indian', 'indiana', 'indiansv', 'indiantelecommunication', 'india”', 'india👇', 'indicate', 'indicated', 'indicates', 'indicating', 'indication', 'indicative', 'indicator', 'indictment', 'indifferent', 'indigenous', 'indigenously', 'indirect', 'indirectly', 'individual', 'individually', 'indoctornation', 'indonesia', 'indonesian', 'indoor', 'indoors', 'indore', 'induced', 'induction', 'indus', 'industrial', 'industrialist', 'industry', 'ineffective', 'ineffective.', 'ineffective.�', 'inefficiency', 'inept', 'inequality', 'inequity', 'inevitable', 'inevitably', 'inexplicable', 'infant', 'infanta', 'infect', 'infected', 'infected(mild)', 'infected…', 'infecting', 'infection', 'infection@drtedros', 'infections—the', 'infectious', 'infectivity', 'infects', 'inference', 'inferring', 'infertility.', 'infinity', 'infirm', 'inflammation', 'inflammatory', 'inflating', 'influence', 'influenced', 'influenza', 'influenzalike', 'info', 'info@covidactnoworg', 'infodemic', 'infographic', 'inform', 'information', 'informed', 'informs', 'infra', 'infrastructure', 'infrequent', 'infusing', 'ingesting', 'inhabitant', 'inhalation', 'inhale', 'inhaler', 'inhaling', 'inherited', 'inhibitor', 'inhibits', 'inhome', 'inhospital', 'initial', 'initiate', 'initiated', 'initiation', 'initiative', 'inject', 'injectable', 'injected', 'injecting', 'injection', 'injured', 'injury', 'ink', 'inkalonji', 'inmate', 'innocence', 'innovation', 'innowner', 'inoculation', 'inperson', 'inquiry', 'inr', 'insecticide', 'inserted', 'insertion', 'inside', 'insider', 'insight', 'insightful', 'insilico', 'insist', 'insisting', 'insists', 'insolvency', 'inspect', 'inspector', 'inspirational', 'inspire', 'instagram', 'install', 'installed', 'installing', 'instalment', 'instance', 'instant', 'instead', 'instead.', 'institute', 'institutelabs', 'instituting', 'institution', 'institutional', 'instructed', 'instructing', 'instruction', 'instructive', 'instructs', 'instrument', 'instruments�', 'instuctions', 'insufficient', 'insurance', 'insurgency', 'intact', 'intake', 'integral', 'integrate', 'integrated', 'integration', 'intel', 'intelligence', 'intelligence.�', 'intelligent', 'intended', 'intense', 'intensified', 'intensify', 'intensity', 'intensive', 'intentional', 'intentionally', 'inter', 'interact', 'interactive', 'interconnectedness', 'interesante', 'interest', 'interested', 'interested.', 'interfere', 'interferon', 'interim', 'interior', 'intermediate', 'intern', 'internal', 'international', 'internet', 'interpret', 'interpretation', 'interrupted', 'interruption', 'interstate', 'interval', 'intervention', 'interview', 'inthe', 'intially', 'into', 'intra', 'intrastate', 'intravenous', 'intriguing', 'introduce', 'introduced', 'introduces', 'introducing', 'introduction', 'introvert', 'intrusion', 'intubated', 'inundated', 'invalid', 'invented', 'inventing', 'invention', 'inventor', 'invest', 'invested', 'invested@drtedros', 'investigate', 'investigated', 'investigates', 'investigating', 'investigation', 'investigator', 'investment', 'investment.@drtedros', 'investor', 'invisible', 'invite', 'invited', 'invoking', 'involve', 'involved', 'involvement', 'involving', 'in…', 'ioannidis', 'iodine', 'iowa', 'ipc', 'iphone', 'iq', 'iran', 'iranian', 'ireland', 'irene', 'irish', 'irrefutable', 'irrefutably', 'irregular', 'irresponsible', 'irritation', 'irs', 'is', 'is.', 'isa', 'isabel', 'ischemic', 'isi', 'islam', 'islamabad', 'islamic', 'islamist', 'island', 'islander', 'isnt', 'isn’t', 'isolate', 'isolated', 'isolating', 'isolation', 'isolation/quarantine', 'isolationhospitalisation', 'isolation\\u200b', 'isolation\\u2063', 'isolation⠀', 'israel', 'israel!', 'israel!�', 'israeli', 'issue', 'issue.�', 'issued', 'issue”', 'issuing', 'istanbul', 'is🔑to', 'it', 'it\"', 'italian', 'itally', 'italy', 'italy�', 'item', 'itly', 'itself.\"', 'iv', 'ive', 'ivermectin', 'i…', 'j&amp;ks', 'j1', 'jacinda', 'jackie', 'jackinthebox', 'jacksonville', 'jacob', 'jagan', 'jail', 'jain', 'jains', 'jaipur', 'jair', 'jam', 'jamaat', 'jamaatis', 'jamal', 'jamat', 'jamati', 'james', 'jammu', 'jan', 'janata', 'janeiro', 'janmabhoomi', 'janta', 'january', 'japan', 'japanese', 'jaroslav', 'jason', 'jazz', 'jb', 'jean', 'jeanine', 'jeanroger', 'jedi', 'jedward', 'jee', 'jeevan', 'jenkinson', 'jennifer', 'jennifersmith', 'jenny', 'jersey', 'jesus', 'jesús', 'jet', 'jetpark', 'jewellry', 'jewish', 'jhalawar', 'jharkhand', 'jhu', 'ji', 'jigawa', 'jigawa1', 'jigawa2', 'jigawa24', 'jigawa26', 'jigawa5', 'jigawa8', 'jihadi', 'jihadis', 'jim', 'jinping', 'jio', 'jitendra', 'jkuat', 'job', 'job.', 'jobless', 'jobwork', 'joe', 'jogger', 'john', 'johnson', 'join', 'joined', 'joining', 'joint', 'joke', 'jokowis', 'jonathan', 'jones', 'jordanian', 'jos', 'jose', 'josé', 'journal', 'journalist', 'journey', 'jovis', 'joyalukkas', 'joão', 'jr', 'juan', 'juba', 'judaism', 'judge', 'judith', 'judy', 'juice', 'julia', 'julius', 'july', 'july,2020', 'july\\u200b', 'jump', 'jumped', 'jumping', 'juna', 'june', 'jurisdiction', 'just', 'justice', 'justify', 'justin', 'just😢i', 'jyoti', 'k', 'k-8.�', 'k12', 'ka', 'kabataan', 'kaczynski', 'kadhas', 'kaduna', 'kaduna10', 'kaduna11', 'kaduna12', 'kaduna13', 'kaduna14', 'kaduna15', 'kaduna16', 'kaduna17', 'kaduna18', 'kaduna19', 'kaduna2', 'kaduna20', 'kaduna21', 'kaduna23', 'kaduna25', 'kaduna26', 'kaduna27', 'kaduna28', 'kaduna3', 'kaduna30', 'kaduna32', 'kaduna4', 'kaduna40', 'kaduna44', 'kaduna49', 'kaduna5', 'kaduna50', 'kaduna52', 'kaduna54', 'kaduna6', 'kaduna63', 'kaduna7', 'kaduna8', 'kaduna9', 'kalka', 'kalma', 'kalonji', 'kalyan', 'kamal', 'kamala', 'kamia', 'kanika', 'kannanthanam', 'kano', 'kano1', 'kano10', 'kano11', 'kano12', 'kano16', 'kano17', 'kano18', 'kano2', 'kano20', 'kano23', 'kano3', 'kano37', 'kano4', 'kano46', 'kano5', 'kano6', 'kano65', 'kano7', 'kano73', 'kano77', 'kano9', 'kanpur', 'kansa', 'kansas—do', 'kapoor', 'karachi', 'karaoke', 'karimganj', 'karl', 'karnataka', 'karol', 'karti', 'kate', 'kathua', 'katsina', 'katsina1', 'katsina10', 'katsina12', 'katsina14', 'katsina17', 'katsina18', 'katsina2', 'katsina21', 'katsina24', 'katsina25', 'katsina27', 'katsina3', 'katsina30', 'katsina4', 'katsina5', 'katsina6', 'katsina7', 'katsina8', 'katsina9', 'kawasakilike', 'kayleigh', 'kaziranga', 'kdu', 'keanu', 'keating', 'kebbi', 'kebbi1', 'kebbi2', 'kebbi3', 'kebbi5', 'kebbi6', 'keeling', 'keenly', 'keep', 'keeping', 'keir', 'kejriwal', 'kem', 'kemp', 'kennedy', 'kent', 'kentucky', 'kenya', 'kenyan', 'kept', 'keqiang', 'kerala', 'keralas', 'ketamine', 'ketchup', 'kettle', 'kevan', 'kevin', 'key', 'keyboard', 'kg', 'khaled', 'khan', 'khargone', 'khashoggi', 'kia', 'kicillof', 'kick', 'kicked', 'kid', 'kidnapped', 'kidney', 'kill', 'killed', 'killer', 'killing', 'kilo', 'kin', 'kind', 'kindly', 'kindness', 'king', 'kingdom', 'kingswood', 'kirtan', 'kiss', 'kissing', 'kissinger', 'kit', 'kitchen', 'kiwi', 'kmag', 'knell', 'knew', 'knock', 'know', 'knowing', 'knowledge', 'known', 'known.', 'knowns', 'know…', 'ko', 'kochi', 'kogi', 'kogi1', 'kolhapur', 'komal', 'konark', 'kong', 'koolaid', 'koolfee', 'korea', 'korea.', 'korean', 'koregaon', 'korona', 'kota', 'kothapet', 'kowheori19', 'kris', 'krishna', 'kroger', 'kudos', 'kumar', 'kung', 'kunj', 'kurnool', 'kushner', 'kuwait', 'kwara', 'kwara1', 'kwara10', 'kwara11', 'kwara13', 'kwara15', 'kwara17', 'kwara19', 'kwara2', 'kwara20', 'kwara23', 'kwara24', 'kwara3', 'kwara33', 'kwara34', 'kwara4', 'kwara5', 'kwara6', 'ky', 'kyi', 'kylie', 'la', 'lab', 'lab.�', 'labconfirmed', 'label', 'labeled', 'labor', 'laboratory', 'laboratorygrade', 'laborer', 'labour', 'labourer', 'labs/hospitals', 'lack', 'lactate', 'lady', 'lag', 'lagarde', 'lager', 'lagging', 'lagos', 'lagos102', 'lagos106', 'lagos107', 'lagos113', 'lagos121', 'lagos123', 'lagos130', 'lagos137', 'lagos142', 'lagos150', 'lagos152', 'lagos153', 'lagos155', 'lagos156', 'lagos157', 'lagos161', 'lagos168', 'lagos169', 'lagos170', 'lagos172', 'lagos188', 'lagos19', 'lagos192', 'lagos193', 'lagos199', 'lagos200', 'lagos207', 'lagos209', 'lagos212', 'lagos230', 'lagos254', 'lagos27', 'lagos280', 'lagos281', 'lagos285', 'lagos288', 'lagos30', 'lagos33', 'lagos34', 'lagos378', 'lagos39', 'lagos42', 'lagos47', 'lagos504', 'lagos53', 'lagos582', 'lagos65', 'lagos657', 'lagos66', 'lagos68', 'lagos689', 'lagos69', 'lagos70', 'lagos76', 'lagos78', 'lagos87', 'lagos88', 'lagos89', 'lagos90', 'lagos98', 'lags—the', 'lahood', 'laid', 'lakh', 'lakh…', 'laminar', 'lamp', 'lampedusa', 'lancashire', 'lancaster', 'land', 'landlord', 'landmark', 'langres', 'language', 'lanka', 'lankan', 'lankas', 'lapse', 'laptop', 'laredo', 'large', 'largely', 'larger', 'largest', 'last', 'lasting', 'lastmile', 'late', 'later', 'latest', 'latex', 'lathi', 'latin', 'latino', 'latitude', 'latter', 'latvia', 'latvian', 'lauded', 'lauds', 'laugh', 'launch', 'launched', 'launching', 'laureate', 'law', 'lawmaker', 'lawn', 'lawsuit', 'lawyer', 'lax', 'lay', 'layer', 'laying', 'layoff', 'layoffed', 'lazy', 'ldf', 'le', 'lead', 'leader', 'leadership', 'leading', 'leaf', 'league', 'leakage', 'leaked', 'leaking', 'leaning', 'leapfrogged', 'learn', 'learned', 'learning', 'learning@drtedros', 'learns', 'learnt', 'learn…', 'least', 'leave', 'leaving', 'lea…', 'lebanon', 'led', 'left', 'leftover', 'leg', 'legal', 'legend', 'legionnaire', 'legislative', 'legislator', 'legislature.', 'legitfundcom', 'legitimate', 'leh', 'leicester', 'lemon', 'length', 'lengthy', 'leni', 'lennon', 'lenox', 'lentil', 'leonardo', 'leonor', 'lesion', 'leslie', 'lesotho', 'lesser', 'lesserknown', 'lesson', 'let', 'lethal', 'letter', 'letting', 'level', 'level3', 'levels.�', 'lewd', 'lewis', 'lg', 'lga', 'lgas', 'lgte', 'li', 'liable', 'liaison', 'libertarian', 'liberty', 'library', 'libs', 'license', 'licensed', 'licking', 'lid', 'lie', 'lieber', 'lied', 'life', 'lifecamp', 'lifesaver', 'lifesaving', 'lifestyle', 'lifethreatening', 'lift', 'lifted', 'light', 'lighting', 'like', 'likely', 'limaye', 'lime', 'limeng', 'limes,', 'limit', 'limitation', 'limited', 'limiting', 'line', 'linger', 'lingering', 'lining', 'link', 'linked', 'linking', 'lion', 'lionel', 'liquefies', 'liquid', 'liquor', 'lisa', 'list', 'list.�', 'listed', 'listen', 'listening', 'listerine', 'listing', 'lit', 'literally', 'litigation', 'little', 'live', 'livelihoods\"', 'liver', 'liverpool', 'lives@drtedros', 'livestream', 'lives…', 'living', 'llano', 'lnjp', 'load', 'loaf', 'lob', 'local', 'localised', 'locality', 'localized', 'locally', 'located', 'locating', 'location', 'lock', 'lockdown', 'lockdown\"', 'lockdown.', 'lockdown2', 'lockdownera', 'lockdownish', 'locked', 'log', 'logged', 'logic', 'logically', 'logistics', 'logo', 'lokckdown', 'lol', 'lombardy', 'london', 'londonbased', 'londoner', 'loneliness', 'long', 'longer', 'longest', 'longfeared', 'longlasting', 'longstanding', 'longterm', 'longtime', 'look', 'lookalike', 'looked', 'looking', 'looting', 'lopez', 'lord', 'lorry', 'los', 'lose', 'loser', 'loses', 'losing', 'loss', 'lost', 'lot', 'lot*)', 'lotus', 'louisiana', 'louisiana—due', 'lovato', 'love', 'loved', 'low', 'low-&amp', 'lowcock', 'lower', 'lowerincome', 'lowering', 'lowest', 'lowincome', 'low—979—as', 'low—about', 'lpc', 'ltc', 'ltd', 'luck', 'lucknow', 'lucky', 'luckyu', 'lucía', 'luigi', 'luke', 'lull', 'lumped', 'lumping', 'lung', 'lungs)', 'lungs.', 'lupus', 'luque', 'luxury', 'lying', 'lyme', 'lymphocyte', 'lymphocytopenia', 'lysol', 'l…', 'm', 'ma', 'ma!—we', 'macarthur', 'macedonia', 'macedonian', 'machine', 'mackinaw', 'macrolide', 'macron', 'madagascan', 'madagascar', 'maddow', 'made', 'madhav', 'madhya', 'madness', 'madrid', 'maduro', 'maduros', 'magazine', 'maggie', 'magic', 'magickly', 'magne', 'magnitude', 'mahal', 'maharashtra', 'maharasthra', 'mahila', 'mahinda', 'maia', 'maiduguri', 'mail', 'main', 'maine', 'mainland', 'mainly', 'maintain', 'maintained', 'maintained@drtedros', 'maintained…', 'maintaining', 'maintains', 'maintenance', 'majid', 'major', 'majority', 'mak', 'makati', 'make', 'maker', 'makeshift', 'makeup', 'making', 'malaga', 'malaria', 'malaria.', 'malarial', 'malaysia', 'malaysian', 'maldives', 'male', 'mali', 'malignancy', 'mall', 'malnourished', 'malunggay', 'mama', 'man', 'manafort', 'manage', 'managed', 'management', 'manager', 'managing', 'manara', 'manatū', 'manaus', 'manchester', 'mandal', 'mandaluyong', 'mandate', 'mandated', 'mandatorily', 'mandatory', 'mandel', 'maneesha', 'manhours', 'manifest', 'manila', 'manipulated', 'manipulated\"', 'manipulating', 'manipulation', 'manipur', 'manir', 'manish', 'manmade', 'mannequin', 'manner', 'manori', 'mantova', 'mantri', 'mantua', 'manual', 'manuel', 'manufacture', 'manufactured', 'manufacturer', 'manufacturing', 'many', 'map', 'mar', 'marapr', 'marañón', 'march', 'march/april', 'marchapril', 'marcos', 'margaret', 'margarets', 'margarita', 'margin', 'marginally', 'marie', 'marijuana', 'marine', 'marist', 'mark', 'marked', 'market', 'marketed', 'marketplace', 'markle', 'marlena', 'marlin', 'marred', 'marriage', 'married', 'marseille', 'martial', 'martin', 'martinelli', 'martín', 'mary', 'maryland', 'mascot', 'mashpee', 'mashrafe', 'masjid', 'mask', 'mask-wearing', 'mask.�', 'mask/facecover', 'masked', 'maskface', 'maskfor', 'masking', 'masks!!', 'masks.�', 'masks😷', 'maskwearing', 'mask😷', 'mass', 'massachusetts', 'massive', 'massproduce', 'mast', 'master', 'masterstroke', 'masturbate', 'mas…', 'matador', 'matamata', 'matarratn', 'match', 'mate', 'matelots', 'material', 'maternity', 'mathematically', 'matt', 'matter', 'matterhorn', 'mat…', 'maulana', 'maximize', 'maximum', 'maxwell', 'may', 'mayan', 'maybe', 'mayor', 'may—and', 'mazowiecki', 'mccarthy', 'mcconnell', 'mcenany', 'mcmichael', 'md', 'me', 'me?', 'mean', 'meaneydelman', 'meaning', 'meaningless.', 'means...', 'meanssilicon', 'meant', 'meantime', 'meanwhile', 'measles', 'measle…', 'measure', 'measurement', 'measuring', 'meat', 'meatpacking', 'mechanical', 'mechanism', 'medcure', 'median', 'medias', 'mediaservices', 'medic', 'medica', 'medicaid', 'medical', 'medically', 'medicare', 'medicate', 'medication', 'medicine', 'medium', 'medscape', 'meerut', 'meet', 'meeting', 'megha', 'meghalaya', 'meghan', 'meharrys', 'mehdipatnam', 'melaninabsorbs', 'melbourne', 'melburnians', 'melinda', 'member', 'membrane', 'meme', 'memo', 'memorial', 'memory', 'men', 'meng', 'mental', 'mentally', 'mention', 'mentioned', 'mercury', 'mercy', 'merit', 'merkel', 'mers', 'mess.', 'message', 'messaging', 'messed', 'messejana', 'messonnier', 'messy', 'met', 'metal', 'metastatic', 'meter', 'metformin', 'method', 'methodological', 'methylxanthine', 'meto', 'metre', 'metric', 'metric.', 'metro', 'mexico', 'mg', 'mi', 'mi6', 'mic', 'michael', 'micheál', 'michigan', 'micro', 'microbiologist', 'microchip', 'microphase', 'microscope', 'microsoft', 'microsofts', 'mid', 'mid-2021', 'mid-april', 'mid-june', 'mid-may', 'mid-october', 'midapril', 'midatlantic', 'midcourse', 'midday', 'middle', 'middleincome', 'middlemore', 'middleton', 'midland', 'midnight', 'midnovember', 'midoctober', 'midst', 'midtolate', 'midwest', 'midwinter', 'might', 'migrant', 'migrating', 'miguel', 'mihigo', 'mikakoss', 'mike', 'mikovits', 'mil', 'milan', 'mild', 'mild/presymptomatic', 'milder', 'mildvery', 'mile', 'milestone', 'military', 'milk', 'milking', 'milkshake', 'millennials', 'millennium', 'million', 'milliondollar', 'milwaukee', 'min', 'mina', 'mind', 'mine', 'mineral', 'mingfang', 'mingling', 'minimise', 'minimum', 'minister', 'ministry', 'minnesota', 'minogue', 'minority', 'minorityowned', 'minster', 'minute', 'miq', 'miracle', 'mis-c', 'misbehaving', 'misbehavior', 'misconstrue', 'misdiagnosed', 'miserably', 'mishra', 'misinfo', 'misinformation', 'misinformation/disinformation', 'misinformation/fearmongering', 'mislabeled', 'misleading', 'mismanagement', 'miss', 'missed', 'missing', 'mission', 'mississippi', 'missouri', 'mistake', 'mistaking', 'mistook', 'mistreating', 'misuse', 'misusing', 'mit', 'mitch', 'mitigate', 'mitigation', 'mix', 'mixed', 'mixing', 'mixture', 'ml', 'mla', 'mm', 'mn', 'mny', 'mo', 'mob', 'mobile', 'mobileand', 'mobility', 'mobilization', 'mobilize', 'mobilized', 'mock', 'mode', 'model', 'modeling', 'modeller', 'modelling', 'moderate', 'moderatehigh', 'moderateish', 'modern', 'moderna', 'modestly', 'modi', 'modifiable', 'modified', 'modify', 'modis', 'modulators', 'moh', 'mohammed', 'mohan', 'mohoddin', 'moinhos', 'moist', 'moisture', 'molecular', 'molecule', 'mombasa', 'moment', 'momentarily', 'mon', 'monday', 'money', 'money.', 'money.�', 'monitor', 'monitoring', 'monkey', 'montanari', 'montero', 'month', 'monthly', 'months\"', 'months”', 'mooted', 'mor', 'morally', 'moratalaz', 'morbidity', 'morbidityas', 'morbidly', 'more', 'more.', 'moreover', 'morgue', 'morguescrematoriums', 'morning', 'moron', 'morrinsville', 'morrison', 'mortality', 'mortaza', 'mortgage', 'mortuary', 'moscow', 'mosh', 'mosinee', 'mosque', 'mosquito', 'most', 'mostaffected', 'mostly', 'mother', 'motherstobe', 'mothertochild', 'motivating', 'motivation', 'motor', 'motorbiked', 'motorway', 'mountain', 'mourn', 'mouse', 'mouth', 'mouthwash', 'move', 'moved', 'movement', 'movie', 'moving', 'mow', 'mp', 'mr', 'mri', 'mrna', 'mrna-1273', 'mrna1273', 'msg', 'msm', 'msnbc', 'mt', 'mt!�', 'muammar', 'much', 'muchpoor', 'much”', 'mucus', 'mud', 'muhamed', 'muhammadu', 'mujahid', 'mukwege', 'multicentric', 'multiple', 'multiplies', 'multisystem', 'multiweek', 'mumbai', 'municipal', 'municipality', 'muradnagar', 'mural', 'murder', 'murdeshwar', 'murs', 'musck', 'muscle', 'musculoskeletal', 'museveni', 'music', 'muslim', 'muslimstyle', 'mussel', 'must', 'mustapha', 'mustard', 'mutate', 'mutated', 'mutation', 'mutiny', 'muy', 'muñíz', 'my', 'myalgic', 'myanmar', 'myelitis', 'myeloma', 'myocarditis', 'myriad', 'mysore', 'mysterious', 'mystery', 'myth', 'n', 'n95', 'n95s', 'na', 'naaaa', 'nabarro', 'nabl', 'nac', 'nadda', 'nadu', 'nadus', 'nagar', 'nagpaul', 'nagpur', 'nagpurs', 'nahar', 'nahi', 'nahuw', 'naik', 'nail', 'nairobi', 'naked', 'namaha', 'naman', 'namaskar', 'namaz', 'name', 'named', 'namo', 'nanavathi', 'nanavati', 'nancy', 'nanopathologist', 'nanshan', 'nap', 'napkin', 'narendra', 'naresh', 'narrative', 'narrow', 'narrowly', 'nasa', 'nasal', 'nasaldrops/gargle', 'nasarawa', 'nasarawa1', 'nasarawa10', 'nasarawa12', 'nasarawa14', 'nasarawa16', 'nasarawa17', 'nasarawa18', 'nasarawa2', 'nasarawa25', 'nasarawa3', 'nasarawa31', 'nasarawa5', 'nasarawa7', 'nasarawa8', 'nasarawa9', 'nascent', 'nashville', 'nasser', 'nasty', 'nation', 'nation.�', 'national', 'nationalism', 'nationalist', 'nationality', 'nationally', 'nationwide', 'native', 'natl', 'natural', 'nature', 'naturopathy', 'navajo', 'navi', 'navigate', 'navigating', 'navsari', 'navy', 'nayak', 'nazi', 'nba', 'nbas', 'nc', 'ncaa', 'ncd', 'ncdc', 'nci', 'ncov', 'nd', 'ne', 'near', 'nearest', 'nearing', 'nearly', 'nearl…', 'nearrecord', 'nears', 'nebraska', 'necessarily', 'necessary', 'necessity', 'need', 'need.', 'needed', 'needed@drtedros', 'needylesson', 'neem', 'neet', 'nefarious', 'negative', 'negatively', 'neglecting', 'negligence', 'negligent', 'negotiating', 'neighbor', 'neighbour', 'neighbourhood', 'neil', 'neilson', 'neither', 'nejm', 'nelson', 'nervous', 'net', 'netflix', 'netherlands', 'netogly', 'network', 'neurological', 'neuroscientist', 'neutralize', 'neutron', 'neutropenic', 'nevada', 'never', 'never�', 'new', 'new.', 'newborn', 'newcase', 'newcastleupontyne', 'newer', 'newest', 'newkirks', 'newly', 'newlyupdated', 'news', 'news#', \"news'\", 'news.', 'newsletter', 'newsom', 'newspaper', 'newsthump', 'newtest', 'new…', 'next', 'nfeltp', 'nfl', 'nh', 'nhk', 'nicaragua', 'nicely', 'nick', 'nickname', 'nicola', 'nicolás', 'nicotine', 'niece', 'nigel', 'nigella', 'niger', 'niger1', 'niger10', 'niger2', 'niger3', 'niger32', 'niger49', 'niger7', 'nigeria', 'nigeria2', 'nigerian', 'nigh', 'night', 'nightclub', 'nightingale', 'nih', 'nine', 'nineteen', 'ninety', 'nipah', 'nirt', 'nites', 'nitish', 'nitp', 'nizamuddin', 'niño', 'nj', 'no', 'no1', 'nobel', 'nobody', 'nod', 'nodal', 'noel', 'noguchi', 'noia', 'nominate', 'non#covid19', 'non-bravery', 'non-established', 'non-smokers', 'nonbinding', 'noncommunicable', 'noncovid', 'noncovid19', 'nondominant', 'none', 'nonessential', 'nonexistent', 'nonfatal', 'nonhispanic', 'noninvasive', 'nonmedical', 'nonmuslims', 'nonnas', 'nonnews', 'nonofficial', 'nonpharmaceutical', 'nonpregnant', 'nonsevere', 'nonteaching', 'nonvegetarian', 'nonwhite', 'noon', 'nor', 'norm', 'normal', 'normality', 'normally', 'norris', 'north', 'northcote', 'northeast', 'northeastern', 'northern', 'northshore', 'northumberland', 'northwest', 'northwestern', 'norway', 'nose', 'nostradamus', 'nostril', 'not', 'not.�', 'note', 'noted', 'nothing', 'notice', 'noticed', 'notification', 'notifications@drtedros', 'notified\\u2063', 'notify', 'noting', 'notion', 'nouri', 'novartis', 'novel', 'novelist', 'november', 'november.�', 'novotel', 'now', 'now)', 'now.', 'now.�', 'nowhttps:bit.ly3emukei', 'npis', 'nrl', 'nsci', 'nsw', 'nude', 'nudged', 'number', 'numerous', 'nurse', 'nurse\"', 'nursing', 'nutrient', 'nutrition', 'nutritional', 'nuñez', 'nv', 'nwajiuba', 'ny', 'nyc', 'nyers', 'nynjct', 'nyt', 'nz', 'nz5', 'nzs', 'oath', 'obama', 'obamacare', 'obamas', 'obese.�', 'obesity', 'obey', 'object', 'obscure', 'obscures', 'observation', 'observational', 'observe', 'observed', 'observer', 'observes', 'observing', 'obtain', 'obvious', 'obviously', 'occasionally', 'occupancy', 'occupational', 'occupies', 'occur', 'occurred', 'occurring', 'occurs', 'ocd', 'oct', 'october', 'ocular', 'odd', 'odds', 'odia', 'odisha', 'odorata', 'oecd', 'of', 'off', 'off.�', 'off@drtedros', 'offence', 'offending', 'offense', 'offense�', 'offer', 'offered', 'offering', 'office', 'officer', 'official', 'officially', 'offlabel', 'offline', 'offloaded', 'offset', 'offsetting', 'often', 'of…', 'of😷in', 'ogden', 'ogun', 'ogun1', 'ogun10', 'ogun108', 'ogun11', 'ogun12', 'ogun13', 'ogun14', 'ogun15', 'ogun16', 'ogun17', 'ogun18', 'ogun19', 'ogun2', 'ogun23', 'ogun24', 'ogun29', 'ogun3', 'ogun30', 'ogun31', 'ogun34', 'ogun35', 'ogun36', 'ogun37', 'ogun4', 'ogun42', 'ogun49', 'ogun5', 'ogun57', 'ogun6', 'ogun7', 'ogun8', 'ogun9', 'oh', 'ohio', 'ohomai', 'oil', 'ok', 'okay', 'oklahoma', 'okthen', 'old', 'older', 'olive', 'olly', 'oluwaniyi', 'olympic', 'olympics', 'on', 'onboard', 'once', 'onceinacentury', 'ondo', 'ondo1', 'ondo10', 'ondo11', 'ondo13', 'ondo15', 'ondo16', 'ondo17', 'ondo18', 'ondo19', 'ondo2', 'ondo20', 'ondo22', 'ondo23', 'ondo28', 'ondo29', 'ondo3', 'ondo32', 'ondo37', 'ondo38', 'ondo4', 'ondo41', 'ondo46', 'ondo5', 'ondo56', 'ondo6', 'ondo7', 'ondo76', 'ondo8', 'ondo9', 'one', 'oneday', 'onefifth', 'oneself', 'onestop', 'onethird', 'onetime', 'onetwo', 'ongoing', 'onion', 'onitsha', 'online', 'onlinedistance', 'only', 'ons', 'onset', 'onto', 'open', 'opened', 'opening', 'operate', 'operating', 'operation', 'ophthalmologist', 'opinion', 'opponent', 'opportunity', 'oppose', 'opposes', 'opposite', 'opposition', 'ops', 'opt', 'optimal', 'optimisation', 'optimistic', 'optimistically', 'optimization', 'option', 'or', 'oral', 'orana', 'orange', 'orangutan', 'order', 'ordered', 'ordering', 'orders.', 'ordinary', 'oregon', 'organ', 'organic', 'organisation', 'organisationhelp', 'organising', 'organisms.', 'organization', 'organization\\u200b', 'organization\\u2063', 'organized', 'organizing', 'origin', 'original', 'originally', 'originate', 'originated', 'originated.�', 'originator', 'orleans', 'ormoc', 'ormore', 'orwell', 'os', 'osama', 'oscillococcinum', 'osha', 'osmania', 'osmar', 'osun', 'osun1', 'osun10', 'osun12', 'osun13', 'osun14', 'osun15', 'osun17', 'osun2', 'osun20', 'osun21', 'osun23', 'osun26', 'osun27', 'osun29', 'osun3', 'osun32', 'osun37', 'osun41', 'osun6', 'osun7', 'osun8', 'otc', 'other', 'others', 'others@drtedros', 'otherwise', 'other\\u2063', 'othe�', 'otoh', 'ottawa', 'ou', 'ought', 'our', 'ourselves.', 'ous', 'out', 'out.', 'out:', 'outage', 'outbid', 'outbreak', 'outbreak\"', 'outbreak.', 'outbreaks—but', 'outbreak—has', 'outburst', 'outcome', 'outdated', 'outdoor', 'outdoors', 'outlawing', 'outlet', 'outlier', 'outline', 'outlined', 'outofarea', 'outpaced', 'outpacing', 'outpatient', 'output', 'outrage', 'outset', 'outside', 'outsider', 'outstanding', 'outwards', 'outweigh', 'out\\u2063', 'over', 'overall', 'overarching', 'overblown', 'overcome', 'overcrowding', 'overdoses', 'overflow', 'overheard', 'overlaid', 'overload', 'overloaded', 'overloading', 'overly', 'overnight', 'overreaction', 'overseas', 'overseeing', 'oversight', 'oversold', 'overstated', 'overtaken', 'overtakes', 'overtaking', 'overtime', 'overturned', 'overwhelmed', 'overwhelming', 'owaisi', 'owe', 'own', 'owned', 'owner', 'owning', 'owns', 'oxford', 'oxfordastrazeneca', 'oxygen', 'oxygenation', 'oyo', 'oyo1', 'oyo10', 'oyo103', 'oyo11', 'oyo12', 'oyo14', 'oyo141', 'oyo15', 'oyo16', 'oyo17', 'oyo18', 'oyo19', 'oyo191', 'oyo2', 'oyo20', 'oyo25', 'oyo27', 'oyo3', 'oyo30', 'oyo31', 'oyo4', 'oyo40', 'oyo41', 'oyo43', 'oyo45', 'oyo47', 'oyo5', 'oyo51', 'oyo52', 'oyo53', 'oyo56', 'oyo6', 'oyo67', 'oyo69', 'oyo7', 'oyo76', 'oyo8', 'oyo9', 'o…', 'p', 'pa', 'pacaembu', 'pace', 'pacific', 'pack', 'package', 'packaging', 'packed', 'packet', 'page', 'paid', 'pain', 'painful', 'painted', 'pair', 'pak', 'pakistan', 'pakistani', 'palermo', 'palliative', 'palm', 'palmer', 'pamphlet', 'panama', 'panchagavya', 'panda', 'pandemic', \"pandemic'\", 'pandemic.', 'pandemic.�', 'pandemic@drtedros', 'pandemicdriven', 'pandemicno', 'pandemicrelated', 'pandemic🙏', 'pandem…', 'pandeyji', 'panel', 'pangolin', 'panic', 'panicbuying', 'panicked', 'panicking', 'pant', 'pantin', 'papad', 'paper', 'pappu', 'paracetamol', 'paragraph', 'paraguay', 'paraguayan', 'paralyzed', 'parameter', 'paramilitary', 'parasite', 'parent', 'parental', 'paris', 'parisien', 'park', 'parker', 'parliament', 'parliamentary', 'parmeshwar', 'part', 'partial', 'partially', 'participant', 'participant…', 'participate', 'participating', 'participation', 'particle', 'particular', 'particularly', 'parties\\u2063', 'partner', 'partnership', 'party', 'partylist', 'party’s', 'part—to', 'parviz', 'pará', 'pas', 'paschim', 'pass', 'passage', 'passed', 'passenger', 'passengerexpress', 'passing', 'past', 'pasted', 'pastor', 'past—its', 'patanjali', 'patarroyo', 'patch', 'patel', 'patent', 'patented', 'path', 'pathogenesis', 'pathology', 'patience', 'patient', 'patiently', 'patientswho', 'patientswhose', 'patients…', 'patil', 'patio', 'patna', 'patrick', 'patriotic', 'patron', 'patronize', 'pattern', 'pattern�', 'patting', 'pattinson', 'paul', 'pauline', 'paulo', 'paulos', 'pause', 'paused', 'paved', 'paw', 'pawars', 'pay', 'payback', 'payer', 'paying', 'payment', 'payroll', 'pa…', 'pcr', 'pcrtest', 'pcrtested', 'peace', 'peacock', 'peak', 'peaked', 'pearl', 'pedestrian', 'pediatric', 'pediatrician', 'pedophile', 'peel', 'peeling', 'peeping', 'peer', 'pegged', 'pelican', 'pelosi', 'pelosis', 'pelted', 'pelting', 'penalised', 'penalty', 'pences', 'pence�', 'pending', 'penetrate', 'penis', 'pennsylvania', 'penny', 'pension', 'pentagon', 'people', 'people\"', 'people)', 'people.', 'people.�', 'peoplehe', 'pepper', 'peptide', 'per', 'perambra', 'percapita', 'percent', 'percentage', 'percentpositive', 'percent”', 'perfect', 'perfected', 'perform', 'performance', 'performed', 'performer', 'performing', 'perfume', 'perhaps', 'perilous', 'perinatal', 'period', 'periodic', 'permanent', 'permanently', 'permission', 'permit', 'permitted', 'peroxide', 'perpetrated', 'persisted', 'persistent', 'persists', 'person', 'personal', 'personalised', 'personality', 'personally', 'personnel', 'persontoperson', 'personvia', 'perspective', 'pertains', 'pertussis', 'peruvian', 'per…', 'pet', 'petal', 'petas', 'petrol', 'pfms', 'pgimer', 'ph', 'pharma', 'pharmaceutical', 'pharmacist', 'pharmacological', 'pharmacy', 'phase', 'phased', 'phe', 'phenolic', 'phenomenal', 'phenomenon', 'pheocs', 'philadelphia', 'philanthropy', 'philippine', 'phone', 'phone.', 'phones!erted', 'phoning', 'photo', 'photograph', 'photographer', 'physic', 'physical', 'physically', 'physician', 'pib', 'pic.twitter.com4uovmnkvey', 'pick', 'picked', 'picking', 'pickup', 'picture', 'pie', 'piece', 'pier', 'pig', 'pigeon', 'pile', 'piling', 'pill', 'pillow', 'pilot', 'piltdown', 'pin', 'pinal', 'pinch', 'pinol', 'pioneer', 'pipe', 'piss', 'pissed', 'pisspoor', 'pistol', 'pitanga', 'pitching', 'pitt', 'pivot', 'placard', 'place', 'placebo', 'placed', 'placement', 'placing', 'plague', 'plain', 'plamsarelated', 'plan', 'plan\"', 'plandemic', 'plane', 'planet', 'planned', 'planning', 'plant', 'planting', 'plaque', 'plasma', 'plastic', 'plasticwrapped', 'plate', 'plateau', 'plateau1', 'plateau10', 'plateau11', 'plateau12', 'plateau13', 'plateau15', 'plateau16', 'plateau17', 'plateau18', 'plateau183', 'plateau186', 'plateau19', 'plateau2', 'plateau20', 'plateau21', 'plateau22', 'plateau23', 'plateau24', 'plateau25', 'plateau26', 'plateau27', 'plateau3', 'plateau31', 'plateau34', 'plateau35', 'plateau37', 'plateau38', 'plateau39', 'plateau4', 'plateau40', 'plateau5', 'plateau54', 'plateau6', 'plateau64', 'plateau68', 'plateau8', 'plateau81', 'plateau9', 'plateaued', 'platform', 'play', 'play.', 'play.�', 'playbook', 'played', 'player', 'player�', 'playing', 'plaza', 'plea', 'pleads', 'please', 'pleased', 'pledge', 'plenty', 'pleurisy', 'plight', 'plot', 'pls', 'plug', 'plummeting', 'plunge', 'plus', 'pluscoronil', 'plz', 'pm', 'pmay', 'pmjjby', 'pmo', 'pmsby', 'pneumococcal', 'pneumonia', 'pns', 'pocket', 'podcast', 'poe', 'poem', 'poet', 'point', 'pointed', 'pointing', 'pointless', 'point”', 'poised', 'poison', 'poisonous', 'pokhriyal', 'pole', 'poleaxed', 'police', 'policed', 'policeman', 'policing', 'policy', 'policy.', 'polio', 'poliolike', 'polish', 'political', 'politically', 'politician', 'politicians..dont', 'politicized', 'politics', 'politifact', 'poll', 'pollen', 'polling', 'pollutant', 'pollution', 'pollution—which', 'polymerase', 'pompeo', 'pondicherry', 'pool', 'pooled', 'pooling', 'poor', \"poor'selders\", 'poorly', 'pope', 'popped', 'popping', 'popular', 'populated', 'population', 'population\"', 'populous', 'port', 'portal', 'portend', 'portfolio', 'portion', 'porto', 'portraying', 'portrays', 'portsmouth', 'portugal', 'portuguese', 'pose', 'posed', 'posing', 'position', 'positioned', 'positive', 'positive+negative', 'positively', 'positives.', 'positive�', 'positivity', 'possession', 'possibility', 'possible', 'possible.@drtedros', 'possibly', 'post', 'postbrexit', 'postcovid', 'posted', 'poster', 'posting', 'postintensive', 'postlockdown', 'postpone', 'postponed', 'postponement', 'postponing', 'postregistration', 'postventilation', 'pot', 'potency', 'potent', 'potential', 'potentially', 'pothole', 'poultry', 'pound', 'pour', 'poverty', 'powder', 'power', 'powerful', 'powerpoint', 'ppe', 'ppes', 'ppi', 'ppl', 'pp…', 'practice', 'practiced', 'practices.@drtedros', 'practicing', 'practise', 'practitioner', 'pradesh', 'pradeshs', 'pradhan', 'pragya', 'praise', 'praised', 'praising', 'prasad', 'prattle', 'pray', 'prayed', 'prayer', 'prayer)', 'praying', 'pre-register', 'precaution', 'precautionary', 'preceding', 'precious', 'precipitously', 'precise', 'preclinical', 'predator', 'predicament', 'predict', 'predicted', 'predicting', 'prediction', 'predictive', 'predicts', 'preexisting', 'prefect', 'prefectural', 'prefer', 'preference', 'preferred', 'pregnancy', 'pregnant', 'prejuly', 'preliminary', 'prelockdown', 'premature', 'premier', 'premji', 'prenatal', 'prepair', 'prepandemic', 'preparation', 'prepare', 'prepared', 'preparedness', 'prepares', 'preparing', 'prequalified', 'preregister', 'pres', 'prescribe', 'prescribed', 'prescribing', 'prescription', 'presence', 'present', 'presentation', 'presented', 'presenter', 'presenting', 'presently', 'preserve', 'preserved', 'presidency', 'president', 'presidential', 'press', 'presser', 'pressure', 'presumably', 'presumed', 'presumptive', 'presymptomatic', 'pretence', 'pretend', 'pretended', 'pretending', 'preterm', 'pretty', 'prevalence', 'prevent', 'prevented', 'preventing', 'prevention', 'preventive', 'prevents', 'preview', 'previewed', 'previous', 'previously', 'prexisting', 'price', 'priest', 'primarily', 'primary', 'primate', 'prime', 'prince', 'princess', 'principal', 'prior', 'prioritise', 'prioritised', 'prioritize', 'priority', 'priority.', 'prison', 'prisoner', 'priti', 'pritzker', 'privacy', 'private', 'priyanka', 'prize', 'prizewinning', 'proactively', 'probability', 'probable', 'probably', 'probiden', 'problem', 'problem.', 'procedure', 'proceed', 'proceeding', 'process', 'processed', 'processed\\u200b', 'processing', 'procession', 'proclaim', 'procovid', 'procurement', 'produce', 'produced', 'producing', 'product', 'production', 'prof', 'professional', 'professor', 'professorso', 'profile', 'profit', 'profitable', 'program', 'programme', 'progress', 'progress@drtedros', 'progressed', 'progression', 'progressive', 'progressively', 'prohibit', 'prohibited', 'prohibiting', 'prohibits', 'project', 'projected', 'projecting', 'projection', 'prolonged', 'promise', 'promised', 'promising', 'promote', 'promoted', 'promoting', 'promotion', 'prompt', 'promptly', 'prone', 'prong', 'pronounced', 'proof', 'propaganda', 'proper', 'properly', 'properly,[565', 'property', 'prophesied', 'prophet', 'prophetess', 'prophylactic', 'prophylaxis', 'proportion', 'proportional', 'proposal', 'proposed', 'proposes', 'prospect', 'prostata', 'prostatitis', 'prostrate', 'protect', 'protected', 'protecting', 'protection', 'protection@drtedros', 'protective', 'protects', 'protein', 'protest', 'protester', 'protesting', 'protestors', 'protocol', 'protocol&ampprocedure', 'protocolprocedure', 'proud', 'prove', 'proved', 'proven', 'provide', 'provided', 'provider', 'provides', 'providing', 'province', 'proving', 'provision', 'provisional', 'pro–united', 'psa', 'psychological', 'ptf', 'pub', 'public', 'publication', 'publicly', 'publish', 'published', 'publishes', 'publishing', 'publi…', 'puducherry', 'puebla', 'puerto', 'pulaski', 'pull', 'pulled', 'pulling', 'pullman', 'pulmonologists', 'pulp', 'pump', 'punch', 'punch!', 'pundit', 'pune', 'punishable', 'punished', 'punishing', 'punishment', 'punjab', 'pupil', 'pur', 'purchase', 'purchasing', 'pure', 'puri', 'purnima', 'puro', 'purohit', 'purple', 'purported', 'purportedly', 'purpose', 'purposefully', 'push', 'pushed', 'pushing', 'pushpa', 'pussy', 'put', 'putin', 'putting', 'puzzled', 'pvt', 'pvt.', 'p…', 'q', 'q&amp;a', 'q&ampa', 'qanon', 'qatar', 'qd', 'qq', 'qr', 'quadruple', 'quadrupled', 'quality', 'quantify', 'quantitative', 'quantity', 'quarantine', 'quarantine.', 'quarantined', 'quarantining', 'quarter', 'quaver', 'quebec', 'queen', 'queenstown', 'quercetin', 'query', 'question', 'questionable', 'questioned', 'queue', 'queuing', 'quick', 'quickly', 'quickly@drtedros', 'quietly', 'quinine', 'quintero', 'quit', 'quite', 'quito', 'quits', 'quitting', 'quiz', 'quote', 'quoted', 'quoting', 'quran', 'r', 'r$', 'r&ampd', 'r0', 'ra', 'raab', 'raam', 'raccoon', 'race', 'raceethnicity', 'rachael', 'rachel', 'raches', 'racial', 'racing', 'racism', 'racist', 'radcliffe', 'radiation', 'radio', 'rahman', 'rahul', 'rai', 'raid', 'raided', 'rail', 'railway', 'rain', 'raina', 'raise', 'raised', 'raising', 'raj', 'rajapaksa', 'rajasthan', 'rajasthans', 'rajkot', 'rajoelina', 'rajpura', 'rally', 'ram', 'rama', 'ramadan', 'ramakrishna', 'ramaphosa', 'ramdev', 'ramdevs', 'ramesh', 'ramp', 'ramped', 'ramping', 'rampup', 'ramu', 'ran', 'randomized', 'randomly', 'range', 'rank', 'ranking', 'rao', 'raoult', 'rape', 'rapid', 'rapidly', 'rare', 'rasam', 'rash', 'rashid', 'rashtriya', 'ratan', 'rate', 'rate)', 'rate.�', 'rated', 'rate…', 'rather', 'rating', 'ratio', 'ration', 'ravi', 'ravindra', 'raw', 'ray', 'raymond', 'rayner', 'rayners', 'rbi', 're', 're-elected', 're-election.’', 're-occupation', 're-opening', 'reach', 'reached', 'reached.�', 'reaching', 'reacting', 'reaction', 'reactivated', 'reacts', 'read', 'reader', 'readily', 'reading', 'ready', 'reagent', 'reais', 'real', 'real???', 'realised', 'realistic', 'reality', 'realize', 'realized', 'really', 'realtime', 'reappraisal', 'reason', 'reasonable', 'reassurance', 'reassured', 'reassuring', 'rebirth', 'rebound', 'rebounded', 'rebuild', 'rebuilt', 'rebuking', 'recall', 'recalling', 'recast', 'receive', 'received', 'receiver', 'receives', 'receiving', 'recent', 'recently', 'reception', 'recession', 'recieved', 'recipe', 'recipient', 'recirculated', 'recital', 'recite', 'reciting', 'reckoning', 'recognise', 'recognition', 'recognize', 'recognized', 'recognizing', 'recommend', 'recommendation', 'recommended', 'recommends', 'reconfigure', 'reconvening', 'record', 'recorded', 'recorded…', 'recording', 'recover', 'recovered', 'recoveredrecovered', 'recoveries…', 'recovering', 'recovers', 'recovery', 'reco…', 'recreated', 'rectifying', 'rec…', 'red', 'reddit', 'reddy', 'redefined', 'redeployed', 'redfield', 'redistributing', 'redraws', 'reduce', 'reduced', 'reduces', 'reducing', 'reduction', 'reduction\"', 'reduction.', 'reef', 'reesmogg', 'refactor', 'refer', 'reference', 'referencing', 'referral', 'referred', 'referring', 'refers', 'reff', 'reffective', 'reflect', 'reflected', 'reflection', 'reflects', 'reformats', 'refrigerator/1800ice', 'refund', 'refuse', 'refused', 'refusing', 'regard', 'regarding', 'regardless', 'regime', 'regime,', 'region', 'regional', 'register', 'registered', 'registering', 'registration', 'registry', 'regret', 'regular', 'regularly', 'regulation', 'rehabilitation', 'reicher', 'reignite', 'reimbursement', 'reimplementation', 'reimposed', 'reimposing', 'reina', 'reinfected', 'reinfection', 'reinforce', 'reinforced', 'reiterate', 'reiterated', 'reiterates', 'reject', 'rejecting', 'rejoice', 'relactation', 'related', 'relating', 'relationship', 'relative', 'relatively', 'relax', 'relaxation', 'relaxed', 'relaxing', 'release', 'released', 'releasing', 'relevance', 'relevant', 'reliable', 'reliably', 'reliance', 'relief', 'relieved', 'religion', 'religious', 'reluctance', 'reluctantly', 'rely', 'relying', 'remain', 'remained', 'remaining', 'remains', 'remark', 'remarkable', 'remarkably', 'remdesivir', 'remedy', 'remember', 'remembering', 'remind', 'reminded', 'reminder', 'reminds', 'removal', 'remove', 'removed', 'renata', 'rendesiver', 'renew', 'renewed', 'renovation', 'renowned', 'rent', 'renter', 'reopen', 'reopened', 'reopening', 'reopenings', 'reopens', 'reopen�', 'rep', 'repairer', 'repatriated', 'repeat', 'repeatable', 'repeated', 'repeatedly', 'replace', 'replaced', 'replicant', 'replication', 'report', 'report\"', 'report..', 'report.@alexismadrigal', 'reportage', 'reported', 'reportedly', 'reporter', 'reporting', 'report\\u200b', 'report…', 'report\\u2063', 'report\\u2063\\u2063\\u2063\\u2063', 'repositioning', 'repository', 'reposting', 'repo…', 'reprehensible', 'represent', 'representation', 'representative', 'represented', 'representing', 'represents', 'repression', 'reprinted', 'reproducible', 'reproduction', 'reproductive', 'republic', 'republican', 'repurposed', 'reqest', 'request', 'requested', 'requesting', 'require', 'required', 'required.�', 'requirement', 'requires', 'requiring', 'rerun', 'rescue', 'rescued', 'rescuing', 'research', 'researcher', 'reservation', 'reserve', 'reserved', 'reservoir', 'residence', 'resident', 'residual', 'residue', 'resign', 'resigned', 'resigns', 'resist', 'resistiré', 'resists', 'resolutely', 'resolution', 'resolve', 'resolved', 'resolving', 'resort', 'resorting', 'resource', 'respect', 'respected', 'respecting', 'respective', 'respectively', 'respects.', 'respirator', 'respiratory', 'respond', 'responded', 'responder', 'responding', 'responds', 'response', 'responsibility', 'responsible', 'responsive', 'responsiveness', 'rest', 'restart', 'restaurant', 'restored', 'restrict', 'restricted', 'restricting', 'restriction', 'restrictions.', 'restrictions.�', 'restrictive', 'result', 'resulted', 'resulting', 'results@drtedros', 'results…', 'resume', 'resumed', 'resuming', 'resumption', 'resurgence', 'res…', 'retail', 'retested', 'rethink', 'retitling', 'retracted', 'retrieved', 'retroactively', 'retrovirus', 'return', 'returned', 'returnee', 'returnees', 'returning', 'retweet', 'retweeted', 'reused', 'reusing', 'revalidation', 'reveal', 'revealed', 'revealing', 'reveals', 'revenue..think', 'reversal', 'reverse', 'reversed', 'reversegenetic', 'reversible', 'review', 'review\"', 'reviewed', 'reviewing', 'revise', 'revised', 'revived', 'revoke', 'revoked', 'revoking', 'reward', 'rfid', 'rhesus', 'rheumatoid', 'rhinovirus', 'rhode', 'rhondda', 'ri', 'ri)', 'riaz', 'riazs', 'ribbon', 'rice', 'richard', 'richest', 'richie', 'rico', 'rid', 'ride', 'ridiculous', 'rife', 'riga', 'right', 'right!�', 'right?!', 'rightbold', 'righthand', 'rightwing', 'rigorous', 'rink', 'rinse', 'rinsing', 'rio', 'rioja', 'riot', 'rioting', 'rip', 'risa', 'rise', 'risen', 'rishi', 'rishte', 'rising', 'risk', 'risk@drtedros', 'riskbased', 'risking', 'riskreward', 'risky', 'risk…', 'rita', 'rivaled', 'river', 'river10', 'river2', 'river3', 'river4', 'river5', 'rivers1', 'rivers10', 'rivers11', 'rivers12', 'rivers127', 'rivers13', 'rivers14', 'rivers15', 'rivers16', 'rivers17', 'rivers18', 'rivers19', 'rivers2', 'rivers20', 'rivers21', 'rivers22', 'rivers24', 'rivers25', 'rivers26', 'rivers3', 'rivers30', 'rivers33', 'rivers35', 'rivers36', 'rivers39', 'rivers40', 'rivers43', 'rivers48', 'rivers49', 'rivers5', 'rivers56', 'rivers6', 'rivers65', 'rivers68', 'rivers7', 'rivers8', 'rivers9', 'riyaz', 'rizwan', 'rmds', 'rna', 'rnadependent', 'rnc', 'road', 'roadblock', 'roadmap', 'roaming', 'rob', 'robbery', 'robbery.�', 'robert', 'roberto', 'robin', 'robredo', 'roche', 'rock', 'rodrigo', 'rohingya', 'rohtak', 'role', 'roll', 'rollback', 'rolled', 'rolling', 'rollout', 'rome', 'ron', 'ronaldo', 'ronan', 'roof', 'roofer', 'room', 'room…', 'rooney', 'roosevelt', 'rose', 'rosewood', 'roskill', 'rotorua', 'rough', 'roughly', 'round', 'roundup', 'route', 'routine', 'routinely', 'row', 'roy', 'royal', 'royce', 'rs15000', 'rs3900000', 'rs5000', 'rsv', 'rt', 'rt-pcr', 'rtpcr', 'rtve', 'rubber', 'ruby', 'rudakov/bloomberg', 'rudd', 'rudimentary', 'rudy', 'ruin', 'rukh', 'rule', 'ruled', 'rules.�', 'ruling', 'rumor', 'rumour', 'run', 'rundown', 'running', 'runni…', 'runny', 'rupee', 'rural', 'rurmeric', 'rush', 'rushed', 'russell', 'russia', 'russia.', 'russian', 'rvsv', 'rw', 'ryanair', 'rydges', 'r…', 's', 's1s2', 'saad', 'sack', 'sacred', 'sacrifice', 'sacrifices’', 'saddam', 'saddened', 'sadiq', 'sadly', 'sadness', 'saeed', 'safe', 'safely', 'safely?', 'safely😷👇🏿', 'safety', 'safe…', 'saf…', 'sage', 'sai', 'said', 'said.', 'sail', 'sailed', 'saint', 'sake', 'salad', 'salariesluxury', 'salary', 'sale', 'saleh', 'saline', 'saliva', 'salivabased', 'sallah', 'salt', 'salute', 'saluting', 'salvador', 'salvatore', 'salwar', 'sam', 'same', 'samitis', 'sample', 'samplesday', 'sampling', 'sampoerna', 'samuel', 'san', 'sanatan', 'sanchez', 'sanctuary', 'sander', 'sang', 'sangh', 'sani', 'sanitiser', 'sanitize', 'sanitized', 'sanitizer', 'sanitizers', 'sanitizing', 'sanskrit', 'santa', 'santiago', 'santo', 'santojanni', 'sao', 'sara', 'sarah', 'sarcastic', 'sard', 'sars', 'sars-cov-2', 'sars-cov2', 'sarscov', 'sarscov2', 'sars–cov2', 'sat', 'satellite', 'sathosa', 'satire', 'saturation', 'saturday', 'satyendar', 'satyendra', 'saudi', 'saurab', 'savarkar', 'save', 'saved', 'saves.', 'saving', 'saw', 'say', 'sayardaw', 'sayha', 'saying', 'sbi', 'sc', 'scale', 'scaled', 'scaleup@drtedros', 'scaling', 'scam', 'scan', 'scanned', 'scanner', 'scapegoat', 'scare', 'scared', 'scarf', 'scary', 'scathing', 'scattered', 'scenario', 'scenario..#coronavirus', 'scene', 'scenery', 'schedule', 'scheduled', 'scheduling', 'scheme', 'schizophrenia', 'school', 'schoolchildren', 'schooling@drtedros', 'schoolkids', 'schwabe', 'science', 'scientific', 'scientifically', 'scientist', 'sclerosis', 'scoffed', 'scope', 'score', 'scorecard', 'scotland', 'scott', 'scramble', 'scraper', 'scream', 'screaming', 'screen', 'screened', 'screening', 'screenshot', 'scripps', 'script', 'scrub', 'scrutiny', 'sd', 'sea', 'sealed', 'seamless', 'sean', 'search', 'searching', 'seashore', 'season', 'season.�', 'seasonal', 'seat', 'seated', 'seattle', 'seawater', 'sec', 'secession', 'sechenov', 'secluedo', 'second', 'secondary', 'secondhighest', 'secondly', 'seconds\"', 'secon…', 'secret', 'secretary', 'secretarygeneral', 'secretion', 'secretly', 'section', 'sector', 'secure', 'secured', 'secures', 'securing', 'security', 'security@drtedros', 'sedated', 'see', 'seed', 'seedso', 'seeing', 'seek', 'seeker', 'seeking', 'seem', 'seemingly', 'seems', 'seen', 'segment', 'seldom', 'selected', 'selecting', 'selectively', 'self', 'self-isolate', 'self-isolation', 'self-isolation\\u200b', 'selfadministered', 'selfcare', 'selfcheck', 'selfchecker', 'selfcheckup', 'selffinancing', 'selfie', 'selfish', 'selfisolate', 'selfisolating', 'selfisolation', 'selfless', 'selflessly', 'selfmedicate', 'selfmonitor', 'selfmonitoring', 'selfquarantine', 'selfquarantined', 'selftest', 'sell', 'seller', 'selling', 'selva', 'sen', 'senate', 'senator', 'send', 'sender', 'sending', 'sends', 'senegal', 'senegalese', 'senior', 'sensational', 'sense', 'sensible', 'sensitisation', 'sensitivity', 'sensor', 'sent', 'sentence', 'seoul', 'sep', 'separate', 'separated', 'separately', 'sepsis', 'sept', 'september', 'september@drtedros', 'septum', 'sept…', 'sequel', 'sequence', 'sequencing', 'serbia', 'serf', 'sergio', 'serial', 'series', 'serious', 'seriously', 'seriously\"', 'seriousness', 'sero', 'serology', 'seroprevalence', 'serum', 'servant', 'serve', 'served', 'server', 'service', 'sesame', 'set', 'setting', 'settle', 'setup', 'seva', 'seven', 'sevenday', 'seventeen', 'seventh', 'several', 'severe', 'severely', 'severity', 'sex', 'sexual', 'sgrh', 'shadab', 'shade', 'shadow', 'shah', 'shaheed', 'shaheen', 'shahrukh', 'shake', 'shakespeare', 'shakeup', 'shaking', 'shall', 'sham', 'shamble', 'shame', 'shameful', 'shands', 'shangrila', 'shape', 'shapps', 'sharad', 'sharda', 'share', 'shared', 'sharepic', 'sharing', 'sharma', 'sharp', 'sharply', 'shashi', 'shattock', 'shave', 'shaving', 'she', 'shea', 'shed', 'sheep', 'sheeran', 'sheet', 'shelf', 'shell', 'shelter', 'shelteringinplace', 'shelterinplace', 'shenzhen', 'shetty', 'shi', 'shield', 'shift', 'shifting', 'shijian', 'shincheonji', 'ship', 'shipped', 'shipping', 'shipwreck', 'shirt', 'shit', 'shiva', 'shivaya', 'shivraj', 'shocked', 'shocking', 'shockingly', 'shoe', 'shook', 'shoot', 'shooter', 'shooting', 'shop', 'shopper', 'shopping', 'shore', 'short', 'shortage', 'shortest', 'shortly', 'shortly.', 'shortness', 'shortsighted', 'shortterm', 'shot', 'should', 'shouldering', 'shouldnt', 'should\\u2063', 'shout', 'shouting', 'shouting)', 'shoutout', 'show', 'showcasing', 'showed', 'shower', 'showing', 'shown', 'shown.', 'showrunner', 'shri', 'shrime', 'shrinking', 'shrinking)', 'shripad', 'shut', 'shutdown', 'shuts', 'shutting', 'siam', 'sibling', 'sick', 'sick.', 'sicker', 'sickness', 'sickness!!', 'siddaramaiah', 'side', 'sidewalk', 'sight', 'sign', 'signage', 'signal', 'signed', 'significant', 'significantly', 'signing', 'sikora', 'silent', 'silently', 'silver', 'similar', 'similarity', 'similarly', 'simple', 'simply', 'simpson', 'simpsons�', 'simulated', 'simulation', 'simultaneously', 'since', 'sindh', 'singapore', 'singer', 'singh', 'singing', 'single', 'single-day', 'single-server', 'singleday', 'single…', 'sinha', 'sinn', 'sinopharms', 'sinovac', 'sinovacs', 'sip', 'sir', 'sisi', 'sister', 'sister.�', 'sit', 'site', 'sitting', 'situation', 'situation.', 'six', 'sixth', 'sizable', 'size', 'sizeable', 'si…', 'skill', 'skilled', 'skin', 'skintoskin', 'skip', 'skull', 'sky', 'skyrocket', 'slack', 'slacker', 'slang', 'slaughter', 'slavery', 'sleep', 'sleepless', 'slice', 'slide', 'slight', 'slightly', 'slippery', 'slovakia', 'slow', 'slowdown', 'slowed', 'slowing', 'slowly', 'slows', 'slpp', 'sluggish', 'slum', 'slurry', 'sm', 'small', 'smaller', 'smart', 'smart.', 'smartphone', 'smartphones', 'smell', 'smell/taste', 'smelltaste', 'smile', 'smith', 'smoke', 'smoked', 'smoker', 'smoking', 'smoky', 'smooth', 'smt', 'smugly', 'snake', 'snap', 'snapchat', 'snapped', 'snapshot', 'sneeze', 'sneezes/coughs', 'sneezing', 'sniff', 'snitch', 'snow', 'snowdon', 'snuck', 'snugly', 'so', 'so,dont', 'soap', 'soar', 'soared', 'socalled', 'soccer', 'social', 'socialism', 'society', 'sociopathic', 'soda', 'soda)', 'sodium', 'soft', 'software', 'sofía', 'sokoto', 'sokoto1', 'sokoto11', 'sokoto12', 'sokoto2', 'sokoto3', 'sold', 'soldier', 'sole', 'solid', 'solidarity', 'solid—', 'solution', 'solution)', 'solve', 'solved', 'solvent', 'somalia', 'some', 'some1nd2findout', 'somebody', 'somehow', 'someone', 'something', 'something.', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'son', 'song', 'sonko', 'sony', 'soon', 'soon\"', 'sooner', 'soon\\u2063', 'soon💚', 'sop', 'sophisticated', 'sore', 'soren', 'soros', 'sorosglobalistsdem', 'soros�', 'sorrow', 'sorrowful', 'sorry', 'sort', 'sosa', 'sound', 'soup', 'souplike', 'source', 'source\\u200b', 'sourcing', 'south', 'southcentral', 'southeast', 'southern', 'southwest', 'southwestcoast', 'so…', 'sp', 'space', 'spaghetti', 'spain', 'spanish', 'spanishlanguage', 'spanning', 'spared', 'spark', 'sparked', 'spate', 'spawned', 'speak', 'speaker', 'speaking', 'speaks', 'special', 'specialist', 'specialized', 'specie', 'specific', 'specifically', 'specified', 'specifies', 'specifying', 'specimen', 'spectre', 'spectrum', 'speech', 'speed', 'speedy', 'spelled', 'spend', 'spending', 'spends', 'spent', 'sperm', 'spice', 'spicy', 'spike', 'spiked', 'spiky', 'spilled', 'spin', 'spirit', 'spiritual', 'spit', 'spitalongadon', 'spite', 'spitting', 'spoil', 'spoke', 'spoken', 'spokesman', 'spokesperson', 'sponsor', 'sponsored', 'spoon', 'spoonful', 'sport', 'spot', 'spot.�', 'sprawled', 'spray', 'sprayed', 'spraying', 'spraying.', 'spread', 'spreader', 'spreader.low', 'spreading', 'spreadsheet', 'spreadsheetbased', 'spread…', 'sprea�', 'spree', 'spring', 'sprinklr', 'spur', 'sputnik', 'sputum', 'square', 'squash', 'squeezed', 'sri', 'sridhar', 'srinivas', 'st', 'stabbed', 'stabilise', 'stable', 'stably', 'stacked', 'stadium', 'staff', 'staffing', 'stafford', 'stage', \"stage'..\", 'stage3', 'staggered', 'staggering', 'stake', 'stakeholder', 'stalling', 'stamford', 'stamping', 'stance.�', 'stand', 'standard', 'standardised', 'standardize', 'standardized', 'standby', 'standing', 'stanford', 'staphylococcus', 'star', 'stared', 'starmer', 'start', 'started', 'starting', 'startup', 'starving', 'stat', 'state', 'state.', 'state.�', 'state/uts', 'statebystate', 'stated', 'statelevel', 'statemandated', 'statement', 'stateoftheart', 'stateowned', 'staterun', 'states.', 'states/uts', 'statesmaharashtra', 'statesman', 'statesmanship', 'statesterritories', 'statesthey', 'statesut', 'statesuts', 'stateuts', 'statewide', 'statewise', 'stating', 'station', 'statistic', 'statistically', 'statisticslink', 'stats', 'statue', 'status', 'statutory', 'stay', 'stayathome', 'stayed', 'staying', 'sta…', 'std', 'steadily', 'steady', 'steal', 'stealth', 'steam', 'steamgaraare', 'steep', 'steer', 'stefano', 'stella', 'stemi', 'stemming', 'step', 'stephen', 'stepping', 'sterility', 'sterilization', 'sterilized', 'steroid', 'stethoscope', 'stevensville', 'stick', 'sticker', 'sticking', 'stigma', 'still', 'stillbirth', 'stimulate', 'stimulus', 'stir', 'stock', 'stocked', 'stockpile', 'stockton', 'stoked', 'stoking', 'stomach', 'stomped', 'stone', 'stoner', 'stood', 'stool', 'stop', 'stoping', 'stopped', 'stopping', 'storage', 'store', 'storehouse', 'stores\"', 'stores.�', 'storm', 'storming', 'story', 'stoush', 'stove', 'straight', 'straightforward', 'strain', 'strand', 'stranded', 'strange', 'strapped', 'strategic', 'strategy', 'stream', 'streamlining', 'street', 'street.', 'strength', 'strengthen', 'strengthening', 'stress', 'stressed', 'stressful', 'stressing', 'stretched', 'strewn', 'strict', 'stricter', 'strictest', 'strictly', 'strike', 'stripped', 'stripper', 'stroke', 'strong', 'stronger', 'strongest', 'structure', 'structured', 'struggle', 'struggled', 'struggling', 'strung', 'stubbornly', 'stuck', 'student', 'studied', 'studied.', 'studied.�', 'study', 'stuff', 'stumbling', 'stunning', 'stupid', 'sturgeon', 'stuttering', 'style', 'sub-1000', 'suba', 'subcategories', 'subcluster', 'subject', 'subjected', 'subjecting', 'submarine', 'submit', 'submitted', 'subnational', 'subscribe', 'subsequently', 'subsided', 'substance', 'substantial', 'substantially', 'substantially—nearly', 'substitute', 'subtle', 'subtracting', 'suburban', 'succeed', 'success', 'successful', 'successfully', 'successive', 'successively', 'successor', 'successor.�', 'successorbarack', 'succumbed', 'such', 'suck', 'sudan', 'sudden', 'suddenly', 'sudima', 'suffer', 'suffered', 'sufferer', 'suffering', 'sufficient', 'sugarcreek', 'suggest', 'suggested', 'suggesting', 'suggestion', 'suggests', 'suicidal', 'suicide', 'suit', 'suitable', 'suite', 'sulfur', 'sultanpuri', 'sum', 'sumac', 'suman', 'summarizes', 'summary', 'summer', \"summer'\", 'summon', 'sun', 'sunak', 'sunday', 'sunderland', 'sunk', 'sunlight', 'sunmon', 'suntan', 'sun…', 'super', 'super-spreaders', 'super-wealthy', 'superimposed', 'superintendent', 'supermarket', 'superspreaders', 'superstar', 'supervised', 'supervision', 'supervisor', 'supplement', 'supplementary', 'supplementation', 'supplier', 'supply', 'supplying', 'support', 'supported', 'supported…', 'supporter', 'supporting', 'suppose', 'supposed', 'supposedly', 'suppress', 'suppressed', 'suppressing', 'supremacist', 'supreme', 'surabaya', 'suraksha', 'surat', 'sure', 'surely', 'surest', 'surface', 'surge', 'surged', 'surgeon', 'surgery', 'surgical', 'surpass', 'surpassed', 'surpasses', 'surprise', 'surprised', 'surprising', 'surrender', \"surrender'\", 'surrendered', 'surreptitiously', 'surveillance', 'survey', 'surveyed', 'survival', 'survive', 'survived', 'survivers', 'survives', 'surviving', 'survivor', 'sur…', 'suspect', 'suspected', 'suspended', 'suspending', 'suspends', 'suspension', 'sustain', 'sustainability', 'sustainable', 'sustained', 'suu', 'swab', 'swabbing', 'swamp', 'swamped', 'swanston', 'swastika', 'swat', 'swatantra', 'swayamsevak', 'swears', 'sweat', 'sweden', 'sweden…', 'sweep', 'sweeping', 'sweet', 'swept', 'swift', 'swiftly', 'swimming', 'swine', 'switched', 'switching', 'switzerland', 'swung', 'sydney', 'symbol', 'symptom', 'symptom-free', 'symptomatic', 'symptombased', 'symptoms)', 'symptoms.�', 'synchronised', 'synchronized�', 'syncytial', 'syndrome', 'syria', 'system', 'system\"', 'system.', 'systematic', 'systematically', 'systemic', 'são', 's…', 'tab', 'table', 'tablespoon', 'tablet', 'tablighi', 'tabligi', 'tablik', 'tabloid', 'tackle', 'tackled', 'tackling', 'tactic', 'taf', 'tag', 'taht', 'tainted', 'taipei', 'taiwan', 'taiwanese', 'taj', 'tak', 'take', 'takeaway', 'takedown', 'taken', 'takeout', 'takeover', 'taking', 'taki…', 'talavera', 'talented', 'talk', 'talked', 'talker', 'talking', 'talkwithus', 'tally', 'tallying', 'taluk', 'tamarind', 'tamil', 'tamilnadu', 'tamped', 'tanda', 'tangihanga', 'tangihanga\\u2063', 'tank', 'tanzania', 'tanzanian', 'tap', 'tape', 'taraba3', 'taraba4', 'taraba5', 'target', 'targeting', 'target…', 'task', 'taskforce', 'taste', 'tasuku', 'tata', 'tatas', 'tax', 'taxi', 'taxpayer', 'tb', 'tchotchke', 'tea', 'teach', 'teacher', 'teaching', 'team', 'tear', 'tearing', 'teaspoon', 'tech', 'techbiotechbig', 'technical', 'technically', 'technician', 'technique', 'technology', 'tectonic', 'ted', 'tedros', 'teen', 'teenager', 'teething', 'teich', 'telangana', 'telecast', 'telecom', 'telecommunication', 'telecounselling', 'telehealth', 'telemedicine', 'telephone', 'televangelist', 'television', 'tell', 'telling', 'temp', 'temperature', 'template', 'temple', 'temporary', 'ten', 'tenant', 'tend', 'tends', 'tennessee', 'tension', 'tent', 'tenyear', 'term', 'terminate', 'terminated', 'terminator', 'terra', 'terrassa', 'terrible', 'terrified', 'terrifying', 'territorial', 'territory', 'terrius', 'terrorist', 'tertiary', 'tesco', 'tesla', 'test', 'test\"', 'test)', 'test.�', 'tested', 'tested\"', 'tested.', 'tester', 'testifying', 'testing', 'testingconfirmed', 'testi…', 'tests\"', 'testsday', 'testsdaymillion', 'teststhat', 'tests—a', 'tests—second', 'tests—the', 'testtracktreat', 'test�', 'tes…', 'tetanus', 'texas', 'text', 'textile', 'th', 'thaali', 'thackeray', 'thailand', 'thali', 'than', 'than17', 'thane', 'thank', 'thankfully', 'thanks', 'tharoor', 'that', 'that,', 'that.', 'thatll', 'thats', 'that…', 'that…https:t.corbznvpwlhr', 'the', 'theatre', 'thecoronavirus', 'theft', 'their', 'their👐afterward', 'them.', 'them..', 'them.@drtedros', 'them.�', 'them?', 'theme', 'them—cases', 'then', 'thenpresident', 'theobromine', 'theophylline', 'theorist', 'theory', 'therapeutic', 'therapy', 'there', 'therefore', 'therell', 'thereof', 'thermal', 'thermometer', 'these', 'these…', 'they', 'theyd', 'theyll', 'theyre', 'theyve', 'they…', 'the…', 'the🌍🌎🌏', 'the🌎@drtedros', 'thick', 'thing', 'thing.', 'think', 'thinkin', 'thinking', 'thinner', 'third', 'thirdhighest', 'thirteen', 'thirty', 'thirtyeight', 'thirtyfive', 'thirtyfour', 'thirtynine', 'thirtythree', 'this', 'this.', 'this.�', 'this…', 'this👇some', 'thoracic', 'thorough', 'thoroughbred', 'thoroughly', 'those', 'though', 'thought', 'thousand', 'thousandbed', 'thrashed', 'thread', 'threat', 'threatened', 'threatening', 'threatens', 'three', 'three-fourths', 'three�', 'threw', 'thrice', 'thriller', 'thrive', 'thrives', 'throat', 'thrombocytopenia', 'thrombosis', 'throne', 'through', 'throughout', 'throughwe', 'throw', 'throwing', 'thrown', 'thru', 'thulped', 'thumb', 'thumb)', 'thursday', 'thus', 'thwarting', 'thyrocare', 'thyrotoxicosis', 'th…', 'th�', 'tick', 'ticked', 'ticket', 'ticketdebit', 'tidbit', 'tie', 'tied', 'tiffany', 'tiger', 'tightened', 'tighter', 'tightly', 'tightness', 'tijuana', 'tik', 'tiktok', 'tilak', 'till', 'time', 'time.', 'timeline', 'timely', 'timing', 'timothy', 'timothyhallett', 'tinapa', 'tincture', 'tiny', 'tip', 'tipping', 'tire', 'tired', 'tireless', 'tissue', 'title', 'tn', 'to', 'tobacco', 'tobacconist', 'today', 'today)', 'today.', 'todaywe', 'today\\u200b', 'today\\u200b\\u2063', 'today—close', 'today\\u2063', 'together', 'togetherness', 'toi', 'toil', 'toilet', 'tok', 'token', 'tokoroa', 'tokyo', 'told', 'toll', 'tom', 'tomato', 'tomb', 'tommy', 'tomorrow', 'ton', 'tone', 'tongue', 'tonight', 'tony', 'too', 'took', 'tool', 'toolkit', 'toothpaste', 'top', 'top5', 'topic', 'topped', 'toronto', 'tortuous', 'tory', 'total', 'totally', 'totaltestresults', 'tota…', 'touch', 'touched', 'touching', 'tough', 'tougher', 'toulouse', 'tour', 'tourist', 'tout', 'touted', 'touting', 'toward', 'towards', 'tower', 'town', \"towns'\", 'toxin', 'toy', 'tpm', 'trace', 'traced', 'tracer', 'tracing', 'tracingapp-feedback@healthgovtnz', 'track', 'tracked', 'tracker', 'tracker—@dribram', 'tracker—the', 'tracking', 'track…', 'trade', 'tradition', 'traditional', 'traffic', 'tragedy', 'tragic', 'trail', 'trailing', 'train', 'trained', 'trainee', 'training', 'trajectory', 'trajectory)', 'tranche', 'transcript', 'transferred', 'transform', 'transformational', 'transformed', 'transfusion', 'transited', 'transitional', 'translated', 'translates', 'transmission', 'transmission@drtedros', 'transmit', 'transmitted', 'transmitting', 'transparency', 'transparent', 'transparently', 'transport', 'transportation', 'trap', 'trauma', 'travel', 'traveled', 'traveler', 'traveling', 'travelled', 'traveller', 'travelling', 'travolta', 'tray', 'trchnology', 'treasury', 'treat', 'treated', 'treating', 'treatment', 'treatment…', 'tree', 'trehan', 'tremendous', 'tremend…', 'trend', 'trended', 'trending', 'trey', 'triaging', 'trial', 'trial#', 'trials)', 'tribal', 'tribe', 'tribute', 'trick', 'tried', 'triggered', 'triggering', 'trillanes', 'trillion', 'trip', 'triple', 'tripled', 'tripping', 'tripura', 'triump', 'trolley', 'troop', 'trophy', 'trouble', 'troubling', 'truck', 'trudeau', 'trudeaus', 'true', 'truenat', 'truenatantigen', 'true😞', 'truly', 'trump', 'trump�', 'trupti', 'trust', 'trusted', 'truth', 'truth—donald', 'try', 'trying', 'tsa', 'tshirt', 'tsunami', 'tube', 'tuberculosis', 'tuberville', 'tucked', 'tucker', 'tues', 'tuesday', 'tuesdayfriday', 'tulsa', 'tumbleweed', 'tumor', 'tune', 'tunisia', 'tunisian', 'turd', 'turkey', 'turkish', 'turkmenistan', 'turmeric', 'turn', 'turnaround', 'turnaroundtime', 'turned', 'turning', 'tuscaloosa', 'tv', 'tv9news', 'tw', 'twatty', 'tweet', 'tweeted', 'tweeting', 'twenty', 'twentyone', 'twentyseven', 'twentythree', 'twice', 'twice!�', 'twilight', 'twin', 'twitter', 'twitter.', 'two', 'twofold', 'twothirds', 'twoweek', 'tx', 'tx)', 'tycoon', 'tyneside', 'type', 'typically', 'typing', 'typo', 't…', 't�', 'u', 'u.s.', 'uae', 'uber', 'ucla', 'uddhav', 'ufc', 'uganda', 'ugandan', 'uighur', 'uk', 'ukgovernment', 'ukrainian', 'ukusa', 'ulsan', 'ultimate', 'ultimately', 'ultrarich', 'ultraviolet', 'uma', 'umbrella', 'un', 'unable', 'unacceptable', 'unanimously', 'unattended', 'unauthorized', 'unavailability', 'unbelievable', 'uncaptured', 'uncertainty', 'unchanged', 'uncle', 'unclear', 'uncomfortable', 'unconfirmed', 'unconscionable', 'uncut', 'under', 'undercount', 'undercounting', 'undergo', 'undergoing', 'underground', 'underlying', 'underrated', 'underscore', 'understand', 'understanding', 'understands', 'understood', 'undertaken', 'undertaking', 'underutilised', 'underway', 'undetected', 'undoubtedly', 'unemployed', 'unemployment', 'unequally', 'unequivocal', 'unequivocally', 'unessential', 'unethical', 'uneven', 'unevenly', 'unexpected', 'unfair', 'unfolds', 'unforeseen', 'unfortunate', 'unfortunately', 'unfrozen', 'unfulfilled', 'uni', 'unicef', 'unidentified', 'unimaginable', 'unimed', 'uninterested', 'union', 'unique', 'unison', 'unisted', 'unit', 'unite', 'united', 'unity', 'univeristy', 'universal', 'universitario', 'university', 'unjustifiable', 'unknown', 'unknown@drtedros', 'unless', 'unlike', 'unlikely', 'unnamed', 'unnecessarily', 'unofficial', 'unprecedented', 'unproven', 'unrecognized', 'unrestricted', 'unrestrictive', 'unsafe', 'unsafely', 'unseat', 'unstable', 'unstoppable', 'unsung', 'unsurprisingly', 'until', 'unto', 'untoward', 'untreated', 'unused', 'unusual', 'unusually', 'unveils', 'unverified', 'unwarranted', 'unwashed', 'unwell', 'unwind', 'unwittingly', 'up', 'up.', 'upcoming', 'update', 'updated', 'updates.�', 'update\\u200b', 'update\\u200b\\u2063\\u2063', 'update…', 'update⠀', 'updating', 'upfront', 'upgrade', 'upgraded', 'uphold', 'uplifted', 'upload', 'uploaded', 'upon', 'upper', 'uppermiddle', 'upside', 'upsurge', 'uptake', 'uptick', 'upto', 'uptodate', 'uptrend', 'upward', 'upwards', 'urban', 'urge', 'urged', 'urgency', 'urgent', 'urgently', 'urging', 'urine', 'urinedung', 'urologist', 'uruguay', 'us', 'us$2', 'usa', 'usa.', 'usable', 'usage', 'usama', 'usb', 'uschinese', 'usd', 'usd35', 'use', 'used', 'used@drtedros', 'useful', 'useful.', 'usefulness', 'useless', 'useless.', 'user', 'username', 'users..', 'usfda', 'using', 'usman', 'usual', 'usually', 'usurped', 'ut', 'utah', 'utilisation', 'utilise', 'utilitising', 'utilized', 'uttar', 'uttarakhand', 'uv', 'uw', 'v', \"v'\", 'va', 'vacancy', 'vacationing', 'vaccinate', 'vaccinated', 'vaccinated.�', 'vaccinating', 'vaccination', 'vaccine', 'vaccine\"', 'vaccine.', 'vaccine.@drtedros', 'vaccine@drtedros', 'vaccinepreventable', 'vaccines.�', 'vaccines@drtedros', 'vaccine–preventable', 'vadra', 'valet', 'valid', 'validated', 'validation', 'vall', 'vallance', 'valle', 'valley', 'valuable', 'value', 'valuedetriment', 'van', 'vandalizing', 'vann', 'vapor', 'vaporized', 'varadkar', 'vargas', 'variability', 'variable', 'variation', 'varies', 'variety', 'various', 'varvara', 'vary', 'vasant', 'vasconcellos', 'vast', 'vastly', 'vati', 'vatican', 'vax', 'vcs', 'vector', 'vegetable', 'vegetarian', 'vehicle', 'veil', 'vendor', 'venezuela', 'venezuela.', 'venezuelan', 'venko', 'ventilated', 'ventilation', 'ventilator', 'ventilators@drtedros', 'vento', 'venue', 'verge', 'verification', 'verified', 'verify', 'verity', 'vermont', 'verse', 'version', 'versus', 'vertical', 'very', 'veteran', 'veterinarian', 'veterinary', 'via', 'viability', 'viable', 'vial', 'viamed', 'vic', 'vice', 'vicepresident', 'viciously', 'victim', 'victoria', 'victorian', 'vidal', 'video', 'videoconferencing', 'vienna', 'viennetta', 'vietnam', 'view', 'viewed', 'viewer', 'vigil', 'vigilant', 'vigilants', 'village', 'villavicencio', 'vincent', 'vincenzo', 'vinci', 'vinegar', 'vinod', 'violate', 'violated', 'violating', 'violation', 'violence', 'violent', 'violently', 'vip', 'viral', 'virality', \"viralogy's\", 'virgin', 'virginia', 'virologist', 'virology', 'virtual', 'virtually', 'virus', 'virus\"', \"virus'\", 'virus)', 'virus.', 'virus.@drtedros', 'virus.�', 'virus@drtedros', 'viruses,', 'virusinfected', 'virusno', 'virus�', 'virus😧', 'visa', 'visible', 'visit', 'visited', 'visiting', 'visitor', 'visor', 'visual', 'visualization', 'visualize', 'viswabharathi', 'vit', 'vital', 'vitamin', 'viz', 'vk', 'vladimir', 'vo', 'vocal', 'vodka', 'voice', 'volleyball', 'volume', 'voluntarily', 'voluntary', 'volunteer', 'vote', 'vote.�', 'voted', 'voting', 'voucher', 'vow', 'voyage', 'vp', 'vte', 'vulnerability', 'vulnerable', 'vulnerablefacing', 'vvip', 'vyas', 'víctor', 'vò', 'w', 'wa', 'wage', 'waikato', 'wait', 'waitakere', 'waited', 'waitemata', 'waiter', 'waiting', 'wake', 'wakeup', 'wale', 'walker', 'walkin', 'walking', 'wall', 'wallace', 'walmart', 'wampanoag', 'wand', 'wandering', 'wane', 'wang', 'wank', 'want', 'wanted', 'wanting', 'war', 'ward', 'warded', 'ward\\u200b', 'warehouse', 'warfare', 'warm', 'warn', 'warn-app', 'warned', 'warning', 'warns', 'warp', 'warrant', 'warrior', 'was.', 'wash', 'washable', 'washing', 'washington', 'wasnt', 'wasnt!�', 'wasn’t!', 'wastage', 'wasted', 'wasting', 'watch', 'watched', 'watching', 'watchlist', 'water', 'waterford', 'watery', 'watford', 'watsapp', 'wave', 'wave�', 'way', 'way@drtedros', 'wayne', 'ways@drtedros', 'wa…', 'wcvb', 'we', 'weak', 'weakened', 'weaker', 'weakness', 'weak—that', 'wealthy', 'weapon', 'wear', 'wearer', 'wearing', 'weather', 'webinar', 'webinars', 'webpage', 'website', 'website)', 'wed', 'wedding', 'wedge', 'wednesday', 'weed', 'week', \"week's\", 'week.', 'weekday', 'weekend', 'weekend\\u2063', 'weekly', 'weeks@drtedros', 'week\\u200b', 'week—the', 'week🔽', 'weeping', 'wef', 'weighed', 'weighing', 'weight', 'welcome', 'welcoming', 'welfare', 'well', 'wellbeing', 'wellchild', 'wellconnected', 'wellington', 'wellness', 'well…', 'welsh', 'wenliang', 'went', 'wept', 'were', 'west', 'westcoast', 'western', 'westminster', 'wet', 'wetherspoons', 'weve', 'we…', 'what', 'whatever', 'whatmasks', 'whats', 'whatsapp', 'whatsapp.', 'wheat', 'wheelchair', 'wheeled', 'when', 'where', 'where2', 'whereas', 'wherein', 'wheres', 'whether', 'which', 'while', 'whistleblower', 'whistling', 'whitbread', 'whitcomb', 'white', 'whitepaper', 'whitmer', 'whitmers', 'whitty', 'who', 'who.', 'whole', 'whose', 'why', 'wi', 'wichita', 'wide', 'widely', 'widen', 'widening', 'widens', 'wider', 'widespread', 'widow', 'wife', 'wikipedia', 'wild', 'wildfire', 'wildflower', 'wildland', 'wildly', 'will', 'willbe', 'william', 'willing', 'willto', 'wilson', 'win', 'wind', 'window', 'wine', 'wing', 'winner', 'winning', 'winter', 'winter.', 'wipe', 'wiped', 'wire', 'wiri', 'wisconsin', 'wise', 'wish', 'wishing', 'with', 'withdraw', 'withdrawn', 'within', 'without', 'witness', 'witnessed', 'wlou', 'wo', 'woke', 'woman', 'wonder', 'wondered', 'wonderful', 'wondering', 'wondrous', 'wont', 'woodward', 'word', 'wore', 'worest', 'work', 'work.', 'work.@alexismadrigal', 'worked', 'worker', 'workers@drtedros', 'workflow', 'workforce', 'working', 'workout', 'workplace', 'work�', 'world', 'world.', 'worldis', 'worldoutside', 'worldwide', 'world�', 'worn', 'worried', 'worrisome', 'worry', 'worrying', 'worse', 'worsen', 'worship', 'worst', 'worstcase', 'worsthit', 'worth', 'would', 'wouldnt', 'wound', 'wreaked', 'wring', 'wrinkle', 'write', 'writer', 'writing', 'written', 'wrong', 'wrongly', 'wrote', 'wth', 'wuflu', 'wuhan', 'wv', 'wwii', 'wwn', 'wy', 'w…', 'x', 'xenophobic.�', 'xi', 'y', 'y+', 'yacht', 'yale', 'yall', 'yalman', 'yan', 'yangon', 'ye!', 'yeah', 'year', 'year,', 'year.�', 'year@drtedros', 'yearold', 'years.', 'years.�', 'yedikule', 'yediyurappa', 'yelling', 'yellow', 'yemen', 'yen', 'yes', 'yesterday', 'yesterday\\u200b\\u2063', 'yesterday—were', 'yet', 'yield', 'yobe', 'yobe1', 'yobe2', 'yobe3', 'yoga', 'yojana', 'yojana(pmjjby', 'yojana(pmsby', 'york', 'yorkers', 'yorkshire', 'york—and', 'you', 'youll', 'young', 'younger', 'your', 'youre', 'youtc', 'youth', 'youtube', 'youve', 'yr', 'yumzers', 'yvonne', 'y…', 'zacks', 'zambales', 'zambia', 'zamfara2', 'zanzibar', 'zaria', 'zealand', 'zealander', 'zealand\\u200b\\u2063', 'zealand\\u2063', 'zee', 'zekiri', 'zero', 'zhong', 'ziberi', 'zika', 'zillionaire', 'zinc', 'zip', 'zithromax', \"zithromax'.\", 'zomatos', 'zone', 'zone/cityspecific', 'zoo', 'zookeepers', 'zoology', 'zoom', 'zoonotic', 'zydus', 'zyphr.�', '|', '~10-11', '~10k-40k', '~142', '~20', '~20%', '~22', '~275k', '~279k', '~300000', '~30k', '~31k', '~416', '~50', '~70', '~89', '~@chikwei', '£1000', '£10000', '£130', '£150', '£225', '£315', '£500', '£95', 'à', 'áñez', 'आँकड़ा', 'इस', 'कर', 'करने', 'के', 'को', 'ख़त्म', 'छोटी', 'जड़', 'ज़रूरी', 'जाएगा।', 'देश', 'पार', 'बहुत', 'में', 'लिए', 'सावधानियाँ', 'सी', 'से', 'हफ़्ते', 'हमारे', 'है', '\\u200b', '\\u200b1043', '\\u200bof', '\\u200bthe', '\\u200bwe', '\\u200b\\u2063', '\\u200b\\u2063today', '\\u200b\\u2063\\u2063', '–', '—', '‘asleep', '‘balance', '‘biological', '‘comatose', \"‘coronavirus.'\", '‘courageous', '‘covaxin’', '‘covid-19', '‘dont', '‘dr', '‘funded', '‘high', '‘imagine', '‘inconvenient', '‘lovin', '‘moderate', '‘moonshot', '‘normal', '‘orgies', '‘plandemic', '‘positive', '‘rna’', '‘significant', '‘theres', '‘virus.', '‘wont', '“360000', '“80', '“alsalatu', '“bidens', '“bioengineered', '“bloodbrain', '“cant', '“coronavirus', '“couldve', '“didnt', '“dont', '“do’s”', '“former', '“gamechanger', '“gratitude', '“hyped', '“its', '“ive', '“kills', '“long-haulers', '“memo', '“now”', '“only', '“plandemic', '“poison”', '“r-naught”', '“reeducation', '“seamless', '“so-called', '“sold', '“spikes', '“stay-at-home', '“surge', '“theyre', '“were', '“weve', '“widespread.', '“works.', '“wouldnt', '•', '•avoid', '•continue', '•stay', '•wash', '•wear', '•\\u200btheres', '…', '…for', '\\u2063', '\\u2063\\u2063', '\\u2063\\u2063\\u2063\\u2063', '\\u2066@davezuckermanvt\\u2069', '\\u2066@govphilscott\\u2069', '\\u2066@potus\\u2069', '\\u2066@realdonaldtrump\\u2069', '€1', '€15', '€30bn', '₹120000', '₹4000test', 'ℹ️', '↗️', '↗️isolate', '⏺️53322', '⏺️recovery', '▪️', '▶️1.60', '▶️1.63', '▶️1.64', '▶️1.67', '▶️1.75', '▶️1.78', '▶️1.83', '▶️17.15', '▶️17.54', '▶️18.28', '▶️19.73', '▶️19.84', '▶️20.08', '▶️20.68', '▶️21.16', '▶️21.59', '▶️21.93', '▶️4497867', '▶️76.24', '▶️76.63', '▶️77.09', '▶️77.65', '▶️78.28', '▶️78.53', '▶️78.64', '▶️80.12', '▶️81.25', '▶️88935', '▶️975861', '◾', '☎️', '☑adults', '☑children', '☑people', '☑pregnant', '☺', '⚖️', '⛪funerals', '✅', '✅#wearafacemask', '✅1970', '✅449', '✅active', '✅active…', '✅adhere', '✅akwa', '✅avoid', '✅carry', '✅clean', '✅discourage', '✅educate', '✅enforcement', '✅get', '✅hig…', '✅ibadan', '✅if', '✅india', '✅indias', '✅invest', '✅jigawa', '✅mandatory', '✅more', '✅new', '✅observe', '✅observing', '✅only', '✅over', '✅pool', '✅practice', '✅provide', '✅provision', '✅recovery', '✅share', '✅sneezecough', '✅stay', '✅the', '✅wash', '✅washing', '✅wear', '✅wearing', '✈adherence', '✉️', '✔️fda', '✔️tell', '❄️', '❌', '❌avoiding', '❗', '❤️', '➡', '➡35', '➡emergency', '➡️', '➡️#covid19', '➡️#covid19related', '➡️1.60', '➡️1.61', '➡️1.65', '➡️1.72', '➡️1.73', '➡️1.8', '➡️1.82', '➡️1.88', '➡️18.72', '➡️19.1', '➡️20', '➡️20.47', '➡️20.96', '➡️21.04', '➡️21.6', '➡️21.90', '➡️43', '➡️4380', '➡️54', '➡️76', '➡️76.28', '➡️76.6', '➡️77.23', '➡️77.32', '➡️77.88', '➡️779000', '➡️79.29', '➡️79.68', '➡️active', '➡️an', '➡️avoid', '➡️clinical', '➡️confirmed', '➡️damascus', '➡️deaths', '➡️distribution', '➡️enhanced', '➡️high', '➡️improves', '➡️in', '➡️interventions', '➡️lockdown', '➡️malaria', '➡️mean', '➡️mobility', '➡️new', '➡️no', '➡️patients', '➡️percentage', '➡️presumptively', '➡️programs', '➡️publicly', '➡️r', '➡️recovered', '➡️reproduction', '➡️shortterm', '➡️states', '➡️substantial', '➡️those', '➡️total', '➡️uk', '➡️using', '⠀', '⬇️', '監獄絕食抗議', '被監視居住', '￼207538', '�', '�america', '�however', '�if', '𝗰𝗼𝗺𝗽𝗹𝗲𝘁𝗲𝗹𝘆', '𝗶𝗻𝗮𝗰𝘁𝗶𝘃𝗮𝘁𝗲', '🆕', '🆙', '🇧🇿', '🇮🇪', '🇮🇳', '🇰🇷', '🇲🇻', '🇺🇬', '🇻🇳🇰🇭🇹🇭🇳🇿🇮🇹🇪🇸', '🇿🇲', '🌍', '🌍@drtedros', '🌎', '🌎🌍🌏', '🌐', '🌐s', '🍔', '🎉', '🎧', '🏠', '🏠✔️stay', '🏥icu', '🏪operational', '🏫', '🏫promote', '🏫schools', '🐍', '🐕', '👀', '👇', '👇read', '👇report', '👇🏽', '👉', '👉12', '👉60', '👉62282', '👉79', '👉a', '👉as', '👉https:t.cocpnzytjslz', '👉https:t.cofxhntoslvr', '👉https:t.cog5dqhjvyu7', '👉https:t.cogjisuk6g4w', '👉https:t.cohssghajmuk', '👉https:t.com7dmn1umpe', '👉https:t.con6olbbadbh', '👉https:t.confy2lhilkz', '👉https:t.copax5gvmukf', '👉https:t.copz2dhnrve1', '👉https:t.cor5ssfz6cdl', '👉https:t.cotdkogmwrir', '👉https:t.cowgabah5com', '👉https:t.coyccw7laqeo', '👉https:t.coyvzbe0v24m', '👉in', '👉india', '👉less', '👉maharashtra', '👉more', '👉nearly', '👉new', '👉recovered', '👉the', '👉with', '👉🏼', '👉🏾https:t.cooc56svri2p', '👍', '👏', '👦', '👧👦', '👨\\u200d🏫statesuts', '👩\\u200d⚕️', '💉2', '💊245', '💦', '📃read', '📈', '📈25', '📈26', '📈covid', '📉4', '📉5', '📍', '📍#covid19', '📍according', '📍follow', '📍guidelines', '📍increasing', '📍metro', '📍mha', '📍sop', '📍statewise', '📍steady', '📍steps', '📍total', '📍updates', '📏physical', '📢#coronavirusupdates', '📢#covid19nigeria', '📢#ncdcinthenews', '📢disregard', '📢ease', '📢nigeria', '📣', '📨to', '📱', '📺', '📺https:t.coociqwdbtdu', '🔰full', '🔰https:t.co0sw9dsfsim', '🔰https:t.cocvscc6s2mq', '🔰https:t.cozph7hdrboq', '🔰read', '🔰report', '🔴', '🔴49000', '🔴breaking', '🔴covid19', '🔴four', '🔴grandparents', '🔴only', '🔴pm', '🔴trump', '🔴uk', '🔹️1107', '🔹️89852', '🔹️total', '🕌ban', '🕌restricted', '🕐', '🕖', '🕗daily', '🕘curfew', '🕤', '🗒️', '😂', '😅', '😠', '😣🙏', '😭', '😷', '😷mandatory', '😷more', '😷wear', '😷wearing', '🙂', '🙄🙄🙄', '🙊🙊🙊', '🙌', '🙏', '🙏🙏🙏', '🙏🙏🙏icai', '🚍', '🚎', '🚓', '🚨', '🚫', '🚶\\u200d♀️social', '🚶🏽', '🚶🏿', '🛡️more', '🟠', '🟡', '🟢clean', '🟢discard', '🟢not', '🟢wear', '🤔is', '🤱🏿yes', '🥡', '🥫', '🥼', '🥼more', '🦟', '🧑\\u200d🏫', '🧔', '🧤more', '🧤no', '🧪', '🧪afriglobal', '🧪ahmadu', '🧪increase', '🧪plateau', '🧪sahel', '🧪test', '🧪testing', '🧪usman', '🧫', '🧬']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform"
      ],
      "metadata": {
        "id": "l7IRYu7XtBRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words = TF_IDF_Vectorizer.transform(X_train[\"tweet\"])\n",
        "bag_of_words = pd.DataFrame(bag_of_words.toarray(), index = X_train.index, columns = TF_IDF_Vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "laKfx_8Fx4Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Añadir atributos al nuevo dataframe de TFIDF"
      ],
      "metadata": {
        "id": "aP8B8t9KZaie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words['largoDocumento'] = X_train['largoDocumento']\n",
        "bag_of_words['CantidadPalabras'] = X_train['CantidadPalabras']\n",
        "bag_of_words['cantidad de letras'] = X_train['cantidad de letras']\n",
        "bag_of_words['cantidad de covid']  = X_train['cantidad de covid'] \n",
        "bag_of_words['cantidad de hashtag'] = X_train['cantidad de hashtag']\n",
        "bag_of_words['cantidad de emojis'] = X_train['cantidad de emojis']"
      ],
      "metadata": {
        "id": "BmRkiQpXZZ5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opJG0dcgRUN-",
        "outputId": "b45cd2c5-fa52-4154-c622-3d700c8c87c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               !  \"[the  \"akira  \"chaotic\"  \"covid-(1).  \"covid19  \\\n",
              "id                                                                  \n",
              "5685  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "2927  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "5900  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "6670  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "1936  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "...     ...  ...    ...     ...        ...          ...       ...   \n",
              "5735  0.088  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "5192  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "5391  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "861   0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "7271  0.000  0.0    0.0     0.0        0.0          0.0       0.0   \n",
              "\n",
              "      \"exterminated\"  \"heres  \"hoax\"  ...  🧪testing  🧪usman    🧫    🧬  \\\n",
              "id                                    ...                               \n",
              "5685             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "2927             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "5900             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "6670             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "1936             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "...              ...     ...     ...  ...       ...     ...  ...  ...   \n",
              "5735             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "5192             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "5391             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "861              0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "7271             0.0     0.0     0.0  ...       0.0     0.0  0.0  0.0   \n",
              "\n",
              "      largoDocumento  CantidadPalabras  cantidad de letras  cantidad de covid  \\\n",
              "id                                                                              \n",
              "5685             111                 9                  73                 73   \n",
              "2927             212                35                 161                161   \n",
              "5900              88                 8                  60                 60   \n",
              "6670             139                20                 102                102   \n",
              "1936              79                 7                  60                 60   \n",
              "...              ...               ...                 ...                ...   \n",
              "5735             304                44                 180                180   \n",
              "5192             150                17                  96                 96   \n",
              "5391             241                36                 188                188   \n",
              "861              212                32                 153                153   \n",
              "7271             273                37                 201                201   \n",
              "\n",
              "      cantidad de hashtag  cantidad de emojis  \n",
              "id                                             \n",
              "5685                   40                   2  \n",
              "2927                    0                   0  \n",
              "5900                   20                   0  \n",
              "6670                   10                   0  \n",
              "1936                    0                   0  \n",
              "...                   ...                 ...  \n",
              "5735                   30                   2  \n",
              "5192                    0                   0  \n",
              "5391                   30                   0  \n",
              "861                     0                   0  \n",
              "7271                   10                   0  \n",
              "\n",
              "[5706 rows x 15006 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d56c9ee0-86ff-41ba-b32f-9625031bcdd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>\"[the</th>\n",
              "      <th>\"akira</th>\n",
              "      <th>\"chaotic\"</th>\n",
              "      <th>\"covid-(1).</th>\n",
              "      <th>\"covid19</th>\n",
              "      <th>\"exterminated\"</th>\n",
              "      <th>\"heres</th>\n",
              "      <th>\"hoax\"</th>\n",
              "      <th>...</th>\n",
              "      <th>🧪testing</th>\n",
              "      <th>🧪usman</th>\n",
              "      <th>🧫</th>\n",
              "      <th>🧬</th>\n",
              "      <th>largoDocumento</th>\n",
              "      <th>CantidadPalabras</th>\n",
              "      <th>cantidad de letras</th>\n",
              "      <th>cantidad de covid</th>\n",
              "      <th>cantidad de hashtag</th>\n",
              "      <th>cantidad de emojis</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5685</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>111</td>\n",
              "      <td>9</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2927</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>212</td>\n",
              "      <td>35</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5900</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6670</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>139</td>\n",
              "      <td>20</td>\n",
              "      <td>102</td>\n",
              "      <td>102</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79</td>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5735</th>\n",
              "      <td>0.088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>304</td>\n",
              "      <td>44</td>\n",
              "      <td>180</td>\n",
              "      <td>180</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5391</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>241</td>\n",
              "      <td>36</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>212</td>\n",
              "      <td>32</td>\n",
              "      <td>153</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7271</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>273</td>\n",
              "      <td>37</td>\n",
              "      <td>201</td>\n",
              "      <td>201</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5706 rows × 15006 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56c9ee0-86ff-41ba-b32f-9625031bcdd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d56c9ee0-86ff-41ba-b32f-9625031bcdd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d56c9ee0-86ff-41ba-b32f-9625031bcdd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal"
      ],
      "metadata": {
        "id": "ilGGPtUT0xFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "metadata": {
        "id": "e8pMorDV1DI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer='Adam'\n",
        "loss='binary_crossentropy'\n",
        "metric='accuracy'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_shape=(bag_of_words.shape[1],)))\n",
        "model.add(Activation(LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(30, use_bias=True))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1, use_bias=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss=loss, optimizer=adam_optimizer, metrics=[metric])"
      ],
      "metadata": {
        "id": "lW8SiL-t01M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "X_train_array = np.asarray(bag_of_words)\n",
        "Y_train_array = np.asarray(Y_train)\n",
        "\n",
        "training = model.fit(X_train_array, Y_train_array, epochs=200, batch_size=100, validation_split=0.2)"
      ],
      "metadata": {
        "id": "gY0iDNOLDG88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "model.save(\"basic_model\")\n",
        "saved_model = keras.models.load_model(\"basic_model\")"
      ],
      "metadata": {
        "id": "rCRKAKT9oRpN",
        "outputId": "ba5e641c-fcbd-46db-9891-ef21add6d6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag = TF_IDF_Vectorizer.transform(X_validation[\"tweet\"])\n",
        "X_Validation_Bag_df = pd.DataFrame(X_Validation_Bag.toarray(), index = X_validation.index,columns = TF_IDF_Vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "40thu1nco6Nu",
        "outputId": "42cd37de-9930-4f04-f6dd-65e153f94d1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag_df['largoDocumento'] = X_validation['largoDocumento']\n",
        "X_Validation_Bag_df['CantidadPalabras'] = X_validation['CantidadPalabras']\n",
        "X_Validation_Bag_df['cantidad de letras'] = X_validation['cantidad de letras']\n",
        "X_Validation_Bag_df['cantidad de covid']  = X_validation['cantidad de covid']\n",
        "X_Validation_Bag_df['cantidad de hashtag'] = X_validation['cantidad de hashtag']\n",
        "X_Validation_Bag_df['cantidad de emojis'] = X_validation['cantidad de emojis']"
      ],
      "metadata": {
        "id": "J91gPkLchKKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag_df_array = np.asarray(X_Validation_Bag_df)\n",
        "Y_Validation_Predict = saved_model.predict(X_Validation_Bag_df_array)"
      ],
      "metadata": {
        "id": "0Fy5rxxbnw3U",
        "outputId": "37698c0a-d906-43f8-f9a6-c23a7e96196c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformPrediction(df, predNumber, predLabel):\n",
        "  copy = df.copy()\n",
        "  for i in range(len(copy)):\n",
        "    if copy[i][0] > 0.5:\n",
        "      predNumber.append([1])\n",
        "      predLabel.append([\"real\"])\n",
        "    else:\n",
        "      predNumber.append([0])\n",
        "      predLabel.append([\"fake\"])\n"
      ],
      "metadata": {
        "id": "EWu5_-xv-smt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predValidationNumbers = []\n",
        "predValidationLabels = []\n",
        "transformPrediction(Y_Validation_Predict, predValidationNumbers, predValidationLabels)"
      ],
      "metadata": {
        "id": "i1hDHEULlcDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationNumbers = []\n",
        "validationLabels = []\n",
        "copy = np.asarray(Y_validation).copy()\n",
        "for i in range(len(copy)):\n",
        "  if copy[i] > 0.5:\n",
        "    validationNumbers.append([1])\n",
        "    validationLabels.append([\"real\"])\n",
        "  else:\n",
        "    validationNumbers.append([0])\n",
        "    validationLabels.append([\"fake\"])"
      ],
      "metadata": {
        "id": "ODiTBndqlzWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(Y_validation)"
      ],
      "metadata": {
        "id": "hnmR9lfkk3J1",
        "outputId": "10a47662-92da-4004-ae15-4b1d2d8caa31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(predValidationLabels,validationLabels))"
      ],
      "metadata": {
        "id": "AhJZ1LxVaC0D",
        "outputId": "399948a9-1961-40d7-94f3-bea6ef765c8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9358794674141556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K fold"
      ],
      "metadata": {
        "id": "lsp7hcI0Xlx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "WBbrhQ1qayX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "k = 5\n",
        "\n",
        "def k_folds(X, y, k):\n",
        "  assert(len(X) == len(y))\n",
        "  folds_X = []\n",
        "  folds_y = []\n",
        "  initial_pos = 0\n",
        "\n",
        "  for i in range(k):\n",
        "    to_pos = min(math.ceil(len(X)/k)*(i+1), len(X))\n",
        "    \n",
        "    x_fold = X[initial_pos:to_pos]\n",
        "    y_fold = y[initial_pos:to_pos]\n",
        "\n",
        "    folds_X.append(x_fold)\n",
        "    folds_y.append(y_fold)\n",
        "    initial_pos = to_pos\n",
        "\n",
        "  return folds_X, folds_y"
      ],
      "metadata": {
        "id": "Mf9ISG6OXlV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_to_eval, Y_to_eval):\n",
        "    Y_Prediction = model.predict(np.asarray(X_to_eval))\n",
        "    numbers = []\n",
        "    prediction_labels = []\n",
        "    transformPrediction(Y_Prediction, numbers, prediction_labels)\n",
        "\n",
        "    validationLabels = []\n",
        "    copy = np.asarray(Y_to_eval).copy()\n",
        "    for i in range(len(copy)):\n",
        "      if copy[i] > 0.5:\n",
        "        validationLabels.append([\"real\"])\n",
        "      else:\n",
        "        validationLabels.append([\"fake\"])\n",
        "\n",
        "    return accuracy_score(validationLabels, prediction_labels)"
      ],
      "metadata": {
        "id": "DAADQdFEYKtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_val(folds_X, folds_y, model):\n",
        "  assert(len(folds_X) == len(folds_y))\n",
        "  X_to_train = []\n",
        "  y_to_train = []\n",
        "  X_to_eval = 0\n",
        "  y_to_eval = 0\n",
        "  scores = []\n",
        "  for i in range(len(folds_X)):\n",
        "    X_to_train = []\n",
        "    y_to_train = []\n",
        "    for j in range(len(folds_X)):\n",
        "      if  i == j:\n",
        "        X_to_eval = folds_X[i]\n",
        "        y_to_eval = folds_y[i]\n",
        "      else:\n",
        "        X_to_train.append(folds_X[j])\n",
        "        y_to_train.append(folds_y[j])\n",
        "    \n",
        "    X_train = np.concatenate(X_to_train)\n",
        "    y_train = np.concatenate(y_to_train)\n",
        "    model.fit(X_train,y_train, epochs=200, batch_size=100, validation_split=0.2)\n",
        "    score = evaluate(model, X_to_eval, y_to_eval)\n",
        "    scores.append(score)\n",
        "  return np.mean(np.array(scores)), scores"
      ],
      "metadata": {
        "id": "iWHnyEvRY_5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds_X, folds_y = k_folds(np.asarray(bag_of_words), np.asarray(Y_train), 5)\n"
      ],
      "metadata": {
        "id": "iYJyO491ZBgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean, k_fold_result_arr = k_fold_cross_val(folds_X, folds_y, model)"
      ],
      "metadata": {
        "id": "1lH1Uz4HbMln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36765172-8ae9-4241-af73-071a13978b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 1.1106e-08 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.9157\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 7.4413e-09 - accuracy: 1.0000 - val_loss: 1.0199 - val_accuracy: 0.9168\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 0.7171 - accuracy: 0.9485 - val_loss: 1.0587 - val_accuracy: 0.9102\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.0103 - val_accuracy: 0.9058\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 3.1217e-06 - accuracy: 1.0000 - val_loss: 1.0379 - val_accuracy: 0.9047\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4258e-06 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.9047\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0421e-06 - accuracy: 1.0000 - val_loss: 1.0350 - val_accuracy: 0.9036\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8277e-06 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.9047\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.6823e-06 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.9047\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.5672e-06 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.9047\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.4673e-06 - accuracy: 1.0000 - val_loss: 1.0304 - val_accuracy: 0.9047\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3918e-06 - accuracy: 1.0000 - val_loss: 1.0294 - val_accuracy: 0.9047\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3168e-06 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.9036\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2588e-06 - accuracy: 1.0000 - val_loss: 1.0275 - val_accuracy: 0.9036\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2015e-06 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.9036\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1553e-06 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.9036\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.1086e-06 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.9036\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0676e-06 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.9036\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0284e-06 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.9025\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.9280e-07 - accuracy: 1.0000 - val_loss: 1.0229 - val_accuracy: 0.9025\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.6191e-07 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.9036\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 9.2816e-07 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.9047\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.9853e-07 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.9047\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.7058e-07 - accuracy: 1.0000 - val_loss: 1.0202 - val_accuracy: 0.9047\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.4706e-07 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.9047\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.1895e-07 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.9047\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.9625e-07 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.9047\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.7414e-07 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.9047\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.5201e-07 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.9047\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7.3268e-07 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.9047\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.1257e-07 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.9047\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.9559e-07 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.9047\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 6.7542e-07 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.9047\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.5871e-07 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.9047\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.4217e-07 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.9047\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 6.2600e-07 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.9047\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 6.1084e-07 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.9047\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.9559e-07 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.9047\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.8237e-07 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.9047\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.6719e-07 - accuracy: 1.0000 - val_loss: 1.0113 - val_accuracy: 0.9047\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.5437e-07 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.9047\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.4242e-07 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.9047\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.2992e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9047\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.1739e-07 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.9047\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.0622e-07 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.9047\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.9403e-07 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.9058\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.8299e-07 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.9058\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.6885e-07 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.9058\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.5932e-07 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.9058\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.4911e-07 - accuracy: 1.0000 - val_loss: 1.0063 - val_accuracy: 0.9058\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.4060e-07 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.9058\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.3044e-07 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.9058\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.2192e-07 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 0.9058\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.1359e-07 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.9058\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.0492e-07 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.9058\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.9677e-07 - accuracy: 1.0000 - val_loss: 1.0038 - val_accuracy: 0.9069\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.8925e-07 - accuracy: 1.0000 - val_loss: 1.0032 - val_accuracy: 0.9069\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.8075e-07 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.9069\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.7345e-07 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.9069\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.6592e-07 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 0.9069\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.5881e-07 - accuracy: 1.0000 - val_loss: 1.0016 - val_accuracy: 0.9069\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.5175e-07 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.9069\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.4383e-07 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.9069\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.3647e-07 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.9069\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.3030e-07 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9069\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.2378e-07 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.9069\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.1759e-07 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.9069\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.1194e-07 - accuracy: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.9069\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.0593e-07 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.9069\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.0009e-07 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.9069\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9418e-07 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.9069\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.8771e-07 - accuracy: 1.0000 - val_loss: 0.9972 - val_accuracy: 0.9080\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8289e-07 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.9080\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.7801e-07 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.9091\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7243e-07 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.9091\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.6784e-07 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.9091\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.6335e-07 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.9091\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5852e-07 - accuracy: 1.0000 - val_loss: 0.9950 - val_accuracy: 0.9091\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.5374e-07 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.9091\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.4932e-07 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.9091\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.4512e-07 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.9091\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.4062e-07 - accuracy: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.9091\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3662e-07 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.9091\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3233e-07 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.9102\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2843e-07 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.9102\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.2443e-07 - accuracy: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.9102\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2026e-07 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.9102\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1609e-07 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.9113\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.1233e-07 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.9113\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.0865e-07 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.9113\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0580e-07 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.9124\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.0179e-07 - accuracy: 1.0000 - val_loss: 0.9903 - val_accuracy: 0.9124\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.9843e-07 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.9124\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.9528e-07 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.9124\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.9211e-07 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.9124\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8914e-07 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.9124\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8576e-07 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.9124\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8265e-07 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.9124\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7966e-07 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.9124\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7642e-07 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.9124\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7275e-07 - accuracy: 1.0000 - val_loss: 0.9874 - val_accuracy: 0.9124\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.6986e-07 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.9124\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.6761e-07 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9124\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.6441e-07 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.9124\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6187e-07 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.9124\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5933e-07 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.9124\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.5685e-07 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.9124\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.5455e-07 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.9124\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.5201e-07 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.9124\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4959e-07 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.9124\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4751e-07 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.9124\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4514e-07 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.9124\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4274e-07 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.9124\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4077e-07 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.9124\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3847e-07 - accuracy: 1.0000 - val_loss: 0.9834 - val_accuracy: 0.9124\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.3620e-07 - accuracy: 1.0000 - val_loss: 0.9830 - val_accuracy: 0.9124\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3386e-07 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.9124\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3184e-07 - accuracy: 1.0000 - val_loss: 0.9824 - val_accuracy: 0.9124\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2992e-07 - accuracy: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.9124\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2794e-07 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.9124\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2606e-07 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.9124\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.9124\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2242e-07 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.9124\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2057e-07 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.9135\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1876e-07 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.9135\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1715e-07 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.9135\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1535e-07 - accuracy: 1.0000 - val_loss: 0.9800 - val_accuracy: 0.9135\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.1360e-07 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.9168\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1201e-07 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.9168\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.1033e-07 - accuracy: 1.0000 - val_loss: 0.9794 - val_accuracy: 0.9168\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0883e-07 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.9168\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0728e-07 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.9168\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0576e-07 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.9168\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0424e-07 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9168\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0272e-07 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.9168\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1.0137e-07 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.9168\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.9855e-08 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.9168\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.8450e-08 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.9168\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.7105e-08 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.9168\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.5784e-08 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.9168\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.4343e-08 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.9168\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.3126e-08 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.9168\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.1956e-08 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9168\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.0563e-08 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.9168\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 8.9303e-08 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.9168\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.8256e-08 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.9168\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.6908e-08 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.9168\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.5788e-08 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.9168\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.4606e-08 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.9168\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.3563e-08 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.9168\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.2483e-08 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.9168\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.1276e-08 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.9168\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.0230e-08 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.9168\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.9208e-08 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.9168\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.8230e-08 - accuracy: 1.0000 - val_loss: 0.9733 - val_accuracy: 0.9179\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.7134e-08 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.9179\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.6195e-08 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.9189\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.5201e-08 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.9179\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.4220e-08 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.9179\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.3315e-08 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.9179\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.2372e-08 - accuracy: 1.0000 - val_loss: 0.9719 - val_accuracy: 0.9179\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.1412e-08 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.9179\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.0543e-08 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.9179\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.9749e-08 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.9179\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.8817e-08 - accuracy: 1.0000 - val_loss: 0.9711 - val_accuracy: 0.9179\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.7988e-08 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.9179\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.7129e-08 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.9179\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.6337e-08 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.9179\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 6.5543e-08 - accuracy: 1.0000 - val_loss: 0.9703 - val_accuracy: 0.9179\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.4704e-08 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.9179\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.4022e-08 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9179\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.3171e-08 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.9179\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.2457e-08 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.9179\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.1725e-08 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.9179\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.1008e-08 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.9179\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 6.0316e-08 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9179\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.9568e-08 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.9179\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.8880e-08 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9179\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.8200e-08 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.9179\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.7536e-08 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.9179\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.6910e-08 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.9179\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.6276e-08 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.9179\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.5650e-08 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.9179\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.5015e-08 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.9179\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.4447e-08 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.9168\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.3818e-08 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.9168\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.3286e-08 - accuracy: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.9168\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.2669e-08 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.9168\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.2075e-08 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.9168\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.1537e-08 - accuracy: 1.0000 - val_loss: 0.9662 - val_accuracy: 0.9168\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.0999e-08 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.9168\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.0453e-08 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.9168\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.0006e-08 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.9168\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.9398e-08 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9168\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.8904e-08 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.9168\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.8440e-08 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.9168\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.7904e-08 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.9168\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.7447e-08 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.9168\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.7003e-08 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.9168\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.6503e-08 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.9168\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2299e-08 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.9168\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.0897e-08 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9168\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.9611e-08 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9168\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.8412e-08 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.9168\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.7355e-08 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.9168\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.6294e-08 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.9168\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.5364e-08 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.9168\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.4407e-08 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.9168\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.3512e-08 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.9168\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.2720e-08 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.9168\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.1997e-08 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.9168\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5.1141e-08 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.9168\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.0501e-08 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.9168\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.9720e-08 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.9168\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.9061e-08 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.9168\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.8470e-08 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.9168\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.7802e-08 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.9168\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.7212e-08 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.9168\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.6536e-08 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.9168\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.5959e-08 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.9157\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 4.5427e-08 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.9157\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.4895e-08 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.9157\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.4381e-08 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.9157\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.3919e-08 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.9157\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.3448e-08 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.9157\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.2968e-08 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.9157\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.2534e-08 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9157\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.2126e-08 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.9146\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.1669e-08 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.9146\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.1307e-08 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.9146\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.0871e-08 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.9146\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4.0560e-08 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.9146\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.0118e-08 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9146\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.9789e-08 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.9146\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.9424e-08 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.9146\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.9062e-08 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.9146\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.8743e-08 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.9146\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.8421e-08 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.9146\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.8124e-08 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.9146\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.7804e-08 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9146\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.7517e-08 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9146\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.7217e-08 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.9146\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 3.6953e-08 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.9146\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 3.6673e-08 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.9146\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 3.6409e-08 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9146\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 3.6174e-08 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9135\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.5889e-08 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.9135\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.5572e-08 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9135\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.5342e-08 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9135\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.5118e-08 - accuracy: 1.0000 - val_loss: 0.9571 - val_accuracy: 0.9135\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4891e-08 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.9146\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4669e-08 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.9146\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4464e-08 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.9146\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4222e-08 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.9146\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.4022e-08 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.9146\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.3830e-08 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.3641e-08 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.3457e-08 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9146\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.3264e-08 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9135\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.3091e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9135\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.2910e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9135\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.2746e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9135\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.2592e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9135\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.2422e-08 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.9135\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.2271e-08 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.9135\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.2110e-08 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9135\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.1936e-08 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9135\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.1794e-08 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9135\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.1653e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9135\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.1512e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9135\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.1391e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9135\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.1254e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9135\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.1132e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9135\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.1017e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9135\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.0891e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9135\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.0776e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9135\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.0659e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9135\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.0526e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9135\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.0398e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9135\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.0298e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9135\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.0193e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9135\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3.0095e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9135\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3.0000e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9135\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.9905e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9135\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9814e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9732e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9638e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9551e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9470e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.9383e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.9303e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.9233e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9148e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.9073e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.9004e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8921e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8853e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8782e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8724e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8651e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8547e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8494e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8430e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8361e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8300e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8229e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8180e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8125e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.8045e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7992e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9146\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7937e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7880e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7820e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7767e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7702e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7643e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7585e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7525e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7476e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9146\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7416e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9146\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7366e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9146\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7309e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9146\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7253e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9146\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7188e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9146\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.7149e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7082e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7036e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2.6972e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6932e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6863e-08 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9146\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6812e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9146\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6748e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9146\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6704e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9146\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6656e-08 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9146\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6593e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9146\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.6538e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9146\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6477e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9146\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6438e-08 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9146\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.6378e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9146\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6321e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9146\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.6258e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9146\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.6217e-08 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9146\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6156e-08 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9146\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.6097e-08 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9146\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.6071e-08 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9146\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5998e-08 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9146\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5936e-08 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9146\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5869e-08 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9146\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5854e-08 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.9146\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5767e-08 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.9146\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.5708e-08 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.9146\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5652e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9146\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5609e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9146\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5554e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9146\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5487e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9146\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5430e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9146\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5374e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9146\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5329e-08 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9146\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5265e-08 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9146\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5204e-08 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9146\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5157e-08 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9146\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5095e-08 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9146\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5038e-08 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4986e-08 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4929e-08 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4868e-08 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.9146\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4809e-08 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.9146\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4768e-08 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.9146\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4701e-08 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.9146\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4647e-08 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.9146\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4575e-08 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.9146\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4517e-08 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.9146\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4484e-08 - accuracy: 1.0000 - val_loss: 0.9571 - val_accuracy: 0.9146\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4420e-08 - accuracy: 1.0000 - val_loss: 0.9571 - val_accuracy: 0.9146\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4345e-08 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9146\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4292e-08 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9146\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4229e-08 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9146\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4166e-08 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.9146\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4105e-08 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.9146\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4049e-08 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.9146\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.4009e-08 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9146\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3928e-08 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9146\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3861e-08 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.9146\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.3818e-08 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.9146\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3768e-08 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.9146\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3684e-08 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.9146\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3618e-08 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9146\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3555e-08 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9146\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.3521e-08 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9146\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.3421e-08 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9146\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3365e-08 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.9146\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3307e-08 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.9146\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3234e-08 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.9146\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3196e-08 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.9146\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3113e-08 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.9146\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.3069e-08 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.9146\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2987e-08 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.9146\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2925e-08 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.9146\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2863e-08 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.9146\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2799e-08 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.9146\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 2.3157e-08 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9146\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 2.3068e-08 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9146\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 2.2981e-08 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.9146\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 2.2920e-08 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.9146\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 2.2820e-08 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.9146\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 2.2748e-08 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.9146\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.2650e-08 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.9146\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2581e-08 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.9146\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2481e-08 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.9146\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2404e-08 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.9146\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2330e-08 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.9146\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.2261e-08 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9146\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2186e-08 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9146\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2079e-08 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.9146\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.2006e-08 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.9146\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1945e-08 - accuracy: 1.0000 - val_loss: 0.9599 - val_accuracy: 0.9146\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1865e-08 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.9146\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1777e-08 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.9146\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1689e-08 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.9146\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1642e-08 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.9146\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1532e-08 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.9146\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1451e-08 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.9146\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.1391e-08 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.9146\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.1308e-08 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.9146\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.1231e-08 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.9146\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1135e-08 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.9146\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1076e-08 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.9146\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0983e-08 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.9146\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0911e-08 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.9146\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0818e-08 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.9146\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0736e-08 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.9146\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0678e-08 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.9146\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.0578e-08 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.9146\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0507e-08 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.9146\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.0426e-08 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.9146\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.0361e-08 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.9146\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0227e-08 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.9146\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.0155e-08 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.9146\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0082e-08 - accuracy: 1.0000 - val_loss: 0.9625 - val_accuracy: 0.9146\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.9988e-08 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.9146\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.9895e-08 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.9146\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9812e-08 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.9146\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.9731e-08 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.9146\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.9660e-08 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.9146\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9555e-08 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.9146\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.9488e-08 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.9146\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 1.9407e-08 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9146\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 1.9308e-08 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9146\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 1.9214e-08 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.9146\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 1.9141e-08 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9146\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9043e-08 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.9146\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.8964e-08 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.9146\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.8879e-08 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.9146\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8788e-08 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.9146\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8667e-08 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.9146\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8661e-08 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.9146\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8506e-08 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.9146\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8405e-08 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.9146\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8311e-08 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9146\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8205e-08 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.9146\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8118e-08 - accuracy: 1.0000 - val_loss: 0.9659 - val_accuracy: 0.9146\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8028e-08 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.9146\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7972e-08 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.9146\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7863e-08 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.9146\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7775e-08 - accuracy: 1.0000 - val_loss: 0.9666 - val_accuracy: 0.9146\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7665e-08 - accuracy: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.9146\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7598e-08 - accuracy: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.9146\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7501e-08 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.9146\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7406e-08 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.9146\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7366e-08 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.9146\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.7241e-08 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.9146\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7124e-08 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.9146\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7045e-08 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.9146\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.6961e-08 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9146\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6865e-08 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.9146\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6757e-08 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.9146\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.6670e-08 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.9146\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6600e-08 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.9146\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6489e-08 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.9146\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6406e-08 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.9146\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6297e-08 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.9146\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6198e-08 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.9146\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.6102e-08 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.9146\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.6073e-08 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.9146\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5909e-08 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.9146\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5826e-08 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.9146\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.5813e-08 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.9146\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5632e-08 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.9146\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5543e-08 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.9146\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.5450e-08 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.9146\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.5369e-08 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.9146\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5288e-08 - accuracy: 1.0000 - val_loss: 0.9725 - val_accuracy: 0.9146\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5161e-08 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.9146\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5072e-08 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.9146\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4963e-08 - accuracy: 1.0000 - val_loss: 0.9733 - val_accuracy: 0.9146\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4892e-08 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.9146\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4799e-08 - accuracy: 1.0000 - val_loss: 0.9739 - val_accuracy: 0.9146\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4654e-08 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.9146\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4613e-08 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.9146\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.4450e-08 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.9146\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4362e-08 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.9146\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4269e-08 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.9146\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4162e-08 - accuracy: 1.0000 - val_loss: 0.9755 - val_accuracy: 0.9146\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4066e-08 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.9146\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.4026e-08 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9146\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3885e-08 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.9146\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3793e-08 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.9146\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3665e-08 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.9146\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.3556e-08 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.9146\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3458e-08 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.9146\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3403e-08 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9146\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3262e-08 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9146\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3156e-08 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.9146\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3043e-08 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.9146\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2988e-08 - accuracy: 1.0000 - val_loss: 0.9795 - val_accuracy: 0.9146\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2810e-08 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.9146\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2740e-08 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.9146\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2613e-08 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.9146\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2502e-08 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9146\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2457e-08 - accuracy: 1.0000 - val_loss: 0.9812 - val_accuracy: 0.9146\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2331e-08 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.9146\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2255e-08 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.9146\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2114e-08 - accuracy: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.9146\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2023e-08 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.9146\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1984e-08 - accuracy: 1.0000 - val_loss: 0.9829 - val_accuracy: 0.9146\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1839e-08 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.9146\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1731e-08 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.9146\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.1674e-08 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.9146\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1622e-08 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.9146\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1434e-08 - accuracy: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.9146\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1352e-08 - accuracy: 1.0000 - val_loss: 0.9851 - val_accuracy: 0.9146\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1254e-08 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.9146\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1145e-08 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.9146\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1043e-08 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.9146\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0983e-08 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9146\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0883e-08 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.9146\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0784e-08 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.9146\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0689e-08 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.9146\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.0580e-08 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.9146\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0489e-08 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 0.9146\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0375e-08 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.9146\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0324e-08 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.9157\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0196e-08 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.9146\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0140e-08 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.9157\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0061e-08 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.9157\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.9295e-09 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.9146\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.8069e-09 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.9146\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.7241e-09 - accuracy: 1.0000 - val_loss: 0.9921 - val_accuracy: 0.9157\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.7210e-09 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.9157\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.5582e-09 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.9157\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.4385e-09 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.9157\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.3581e-09 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.9157\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 9.3207e-09 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.9157\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.1951e-09 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.9135\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.0714e-09 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.9157\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.0295e-09 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.9157\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.9220e-09 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.9157\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.8090e-09 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.9157\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.7547e-09 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.9157\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.6753e-09 - accuracy: 1.0000 - val_loss: 0.9977 - val_accuracy: 0.9157\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.6499e-09 - accuracy: 1.0000 - val_loss: 0.9982 - val_accuracy: 0.9157\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.4817e-09 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.9157\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.3822e-09 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.9157\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.3525e-09 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.9157\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.2054e-09 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.9157\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.1242e-09 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.9157\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.0738e-09 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.9157\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.9918e-09 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.9157\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.8790e-09 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.9157\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.8328e-09 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.9157\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.7759e-09 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.9157\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.6743e-09 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.9157\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.6028e-09 - accuracy: 1.0000 - val_loss: 1.0043 - val_accuracy: 0.9157\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.5208e-09 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.9157\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.4508e-09 - accuracy: 1.0000 - val_loss: 1.0053 - val_accuracy: 0.9157\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.3314e-09 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.9157\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.3039e-09 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.9157\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.1816e-09 - accuracy: 1.0000 - val_loss: 1.0069 - val_accuracy: 0.9157\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.0928e-09 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.9157\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.0291e-09 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.9157\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.0172e-09 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.9157\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.8844e-09 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.9157\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.7994e-09 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.9157\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.7702e-09 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.9157\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.6639e-09 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9146\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.6441e-09 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.9157\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.5137e-09 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.9157\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.4528e-09 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.9157\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.3832e-09 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9157\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2450e-09 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.9157\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.2468e-09 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.9157\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.1541e-09 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9157\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.0381e-09 - accuracy: 1.0000 - val_loss: 1.0155 - val_accuracy: 0.9157\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.0591e-09 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.9157\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.9398e-09 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.9157\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.8691e-09 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.9157\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.8388e-09 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9157\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.7256e-09 - accuracy: 1.0000 - val_loss: 1.0186 - val_accuracy: 0.9157\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.6661e-09 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.9157\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.6532e-09 - accuracy: 1.0000 - val_loss: 1.0197 - val_accuracy: 0.9157\n",
            "36/36 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.9806e-09 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.9157\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.9107e-09 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.9157\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8803e-09 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.9157\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2.7989e-09 - accuracy: 1.0000 - val_loss: 1.0210 - val_accuracy: 0.9146\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8141e-09 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.9157\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.7749e-09 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.9146\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.7289e-09 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.9157\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.7931e-09 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.9157\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.7255e-09 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.9146\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.6885e-09 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.9146\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6266e-09 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.9157\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6214e-09 - accuracy: 1.0000 - val_loss: 1.0233 - val_accuracy: 0.9157\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5765e-09 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.9157\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6080e-09 - accuracy: 1.0000 - val_loss: 1.0239 - val_accuracy: 0.9157\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5531e-09 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.9146\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5462e-09 - accuracy: 1.0000 - val_loss: 1.0245 - val_accuracy: 0.9146\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5656e-09 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.9157\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4891e-09 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.9157\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.5909e-09 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.9146\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.4058e-09 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.9146\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4210e-09 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.9157\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3956e-09 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.9157\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3519e-09 - accuracy: 1.0000 - val_loss: 1.0267 - val_accuracy: 0.9157\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3265e-09 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.9157\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.3441e-09 - accuracy: 1.0000 - val_loss: 1.0272 - val_accuracy: 0.9157\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.3314e-09 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.9157\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.2902e-09 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.9157\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.2408e-09 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.9157\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2810e-09 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.9157\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2557e-09 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.9146\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1855e-09 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 0.9157\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.1774e-09 - accuracy: 1.0000 - val_loss: 1.0294 - val_accuracy: 0.9157\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.1517e-09 - accuracy: 1.0000 - val_loss: 1.0298 - val_accuracy: 0.9157\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.1538e-09 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.9157\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.1273e-09 - accuracy: 1.0000 - val_loss: 1.0304 - val_accuracy: 0.9157\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 2.1093e-09 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.9157\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0694e-09 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.9157\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.1369e-09 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.9157\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0943e-09 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.9157\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.0077e-09 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.9157\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0742e-09 - accuracy: 1.0000 - val_loss: 1.0325 - val_accuracy: 0.9157\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.0310e-09 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.9157\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.0005e-09 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.9157\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.9736e-09 - accuracy: 1.0000 - val_loss: 1.0334 - val_accuracy: 0.9157\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.9998e-09 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.9157\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.9090e-09 - accuracy: 1.0000 - val_loss: 1.0341 - val_accuracy: 0.9157\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.9578e-09 - accuracy: 1.0000 - val_loss: 1.0344 - val_accuracy: 0.9157\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.9477e-09 - accuracy: 1.0000 - val_loss: 1.0348 - val_accuracy: 0.9157\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.9004e-09 - accuracy: 1.0000 - val_loss: 1.0351 - val_accuracy: 0.9157\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8839e-09 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.9157\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.8644e-09 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.9157\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8451e-09 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.9157\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8643e-09 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.9157\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8848e-09 - accuracy: 1.0000 - val_loss: 1.0368 - val_accuracy: 0.9157\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.8067e-09 - accuracy: 1.0000 - val_loss: 1.0372 - val_accuracy: 0.9157\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.8066e-09 - accuracy: 1.0000 - val_loss: 1.0375 - val_accuracy: 0.9157\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8518e-09 - accuracy: 1.0000 - val_loss: 1.0379 - val_accuracy: 0.9157\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.7601e-09 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.9157\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7910e-09 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.9157\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.8308e-09 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.9157\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7152e-09 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.9157\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7155e-09 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.9157\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7094e-09 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.9157\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7055e-09 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.9157\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6506e-09 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.9146\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6917e-09 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.9157\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6558e-09 - accuracy: 1.0000 - val_loss: 1.0416 - val_accuracy: 0.9157\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.6018e-09 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.9157\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.7095e-09 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.9157\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6601e-09 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.9157\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5719e-09 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.9146\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6107e-09 - accuracy: 1.0000 - val_loss: 1.0433 - val_accuracy: 0.9157\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.6029e-09 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 0.9157\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5896e-09 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.9157\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5445e-09 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.9157\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5401e-09 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.9157\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5021e-09 - accuracy: 1.0000 - val_loss: 1.0453 - val_accuracy: 0.9157\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5211e-09 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.9146\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5070e-09 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.9157\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.5101e-09 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.9157\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4540e-09 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.9157\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4584e-09 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.9146\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4479e-09 - accuracy: 1.0000 - val_loss: 1.0478 - val_accuracy: 0.9146\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4436e-09 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.9157\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4123e-09 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.9146\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.9157\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3702e-09 - accuracy: 1.0000 - val_loss: 1.0493 - val_accuracy: 0.9146\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.4518e-09 - accuracy: 1.0000 - val_loss: 1.0496 - val_accuracy: 0.9157\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.9157\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3818e-09 - accuracy: 1.0000 - val_loss: 1.0509 - val_accuracy: 0.9146\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3981e-09 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.9157\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3253e-09 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.9146\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3536e-09 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.9146\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3259e-09 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.9146\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3024e-09 - accuracy: 1.0000 - val_loss: 1.0529 - val_accuracy: 0.9146\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.3178e-09 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.9146\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3415e-09 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.9157\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2558e-09 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.9146\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3123e-09 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.9157\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3072e-09 - accuracy: 1.0000 - val_loss: 1.0544 - val_accuracy: 0.9157\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2257e-09 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.9146\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2294e-09 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.9146\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2547e-09 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9146\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3279e-09 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.9157\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1734e-09 - accuracy: 1.0000 - val_loss: 1.0571 - val_accuracy: 0.9146\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2403e-09 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.9146\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2580e-09 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.9146\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1903e-09 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.9146\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2083e-09 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.9146\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2016e-09 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.9146\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1882e-09 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.9146\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1406e-09 - accuracy: 1.0000 - val_loss: 1.0595 - val_accuracy: 0.9146\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1493e-09 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.9146\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1330e-09 - accuracy: 1.0000 - val_loss: 1.0616 - val_accuracy: 0.9146\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2357e-09 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.9146\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1913e-09 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.9146\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1755e-09 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.9146\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0877e-09 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.9157\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0943e-09 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.9146\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1362e-09 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.9146\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1146e-09 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.9146\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1006e-09 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.9146\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0492e-09 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9146\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1336e-09 - accuracy: 1.0000 - val_loss: 1.0643 - val_accuracy: 0.9157\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1070e-09 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.9146\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0225e-09 - accuracy: 1.0000 - val_loss: 1.0675 - val_accuracy: 0.9157\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1136e-09 - accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.9146\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0773e-09 - accuracy: 1.0000 - val_loss: 1.0658 - val_accuracy: 0.9146\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0625e-09 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.9146\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0189e-09 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.9157\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0823e-09 - accuracy: 1.0000 - val_loss: 1.0677 - val_accuracy: 0.9146\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0210e-09 - accuracy: 1.0000 - val_loss: 1.0679 - val_accuracy: 0.9146\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0493e-09 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.9146\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.9515e-10 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.9157\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0625e-09 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.9146\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.6990e-10 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.9146\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0085e-09 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.9157\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.7471e-10 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.9146\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.4668e-10 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.9146\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.9525e-10 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.9146\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.7467e-10 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.9146\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0062e-09 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9146\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.3120e-10 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.9146\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.3908e-10 - accuracy: 1.0000 - val_loss: 1.0730 - val_accuracy: 0.9146\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.2225e-10 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.9146\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.4234e-10 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.9146\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.1442e-10 - accuracy: 1.0000 - val_loss: 1.0735 - val_accuracy: 0.9146\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.7638e-10 - accuracy: 1.0000 - val_loss: 1.0735 - val_accuracy: 0.9146\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.2257e-10 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.9146\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.2980e-10 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.9146\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.2716e-10 - accuracy: 1.0000 - val_loss: 1.0746 - val_accuracy: 0.9146\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.5727e-10 - accuracy: 1.0000 - val_loss: 1.0761 - val_accuracy: 0.9146\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.2090e-10 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.9146\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.3022e-10 - accuracy: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.9146\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.5872e-10 - accuracy: 1.0000 - val_loss: 1.0763 - val_accuracy: 0.9146\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.8374e-10 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.9146\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.3101e-10 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.9146\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.6570e-10 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.9146\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.5355e-10 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.9168\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.9309e-10 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.9157\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.7559e-10 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.9146\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.4979e-10 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9146\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.5315e-10 - accuracy: 1.0000 - val_loss: 1.0825 - val_accuracy: 0.9168\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.9542e-10 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.9146\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.1112e-10 - accuracy: 1.0000 - val_loss: 1.0801 - val_accuracy: 0.9146\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.2421e-10 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.9146\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.2323e-10 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.9146\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.5507e-10 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.9146\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.8575e-10 - accuracy: 1.0000 - val_loss: 1.0817 - val_accuracy: 0.9146\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.0560e-10 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9146\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.3800e-10 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9146\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.2677e-10 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.9146\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.8590e-10 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.9146\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.6434e-10 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.9146\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.9310e-10 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.9168\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.8971e-10 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9146\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.4813e-10 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.9146\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.4363e-10 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9146\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.5743e-10 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.9135\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.7622e-10 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.9146\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.1036e-10 - accuracy: 1.0000 - val_loss: 1.0852 - val_accuracy: 0.9146\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.9429e-10 - accuracy: 1.0000 - val_loss: 1.0866 - val_accuracy: 0.9146\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.7305e-10 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.9146\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.8517e-10 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.9168\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.8087e-10 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.9146\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.1157e-10 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.9146\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.4871e-10 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.9146\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.6337e-10 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.9146\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.9679e-10 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.9146\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.5317e-10 - accuracy: 1.0000 - val_loss: 1.0898 - val_accuracy: 0.9146\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.6717e-10 - accuracy: 1.0000 - val_loss: 1.0882 - val_accuracy: 0.9124\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.6324e-10 - accuracy: 1.0000 - val_loss: 1.0886 - val_accuracy: 0.9135\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.3919e-10 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 0.9146\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.3114e-10 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 0.9146\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.2276e-10 - accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 0.9135\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.9769e-10 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.9146\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.1322e-10 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.9146\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.9395e-10 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.9146\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.1370e-10 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.9135\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2686e-09 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.9135\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5247e-09 - accuracy: 1.0000 - val_loss: 9.0363e-09 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.7295e-10 - accuracy: 1.0000 - val_loss: 8.5042e-09 - val_accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.5180e-10 - accuracy: 1.0000 - val_loss: 8.5018e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.1434e-10 - accuracy: 1.0000 - val_loss: 8.4541e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.8765e-10 - accuracy: 1.0000 - val_loss: 8.4330e-09 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.7977e-10 - accuracy: 1.0000 - val_loss: 8.3853e-09 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.3129e-10 - accuracy: 1.0000 - val_loss: 8.3507e-09 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.8386e-10 - accuracy: 1.0000 - val_loss: 8.3566e-09 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 6.1884e-10 - accuracy: 1.0000 - val_loss: 8.3814e-09 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 6.3287e-10 - accuracy: 1.0000 - val_loss: 8.3112e-09 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.7264e-10 - accuracy: 1.0000 - val_loss: 8.2637e-09 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 7.0837e-10 - accuracy: 1.0000 - val_loss: 8.4857e-09 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.4039e-10 - accuracy: 1.0000 - val_loss: 8.2627e-09 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.7479e-10 - accuracy: 1.0000 - val_loss: 8.4916e-09 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.7229e-10 - accuracy: 1.0000 - val_loss: 8.1839e-09 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.0437e-10 - accuracy: 1.0000 - val_loss: 8.1656e-09 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.8887e-10 - accuracy: 1.0000 - val_loss: 8.4367e-09 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.7674e-10 - accuracy: 1.0000 - val_loss: 8.1344e-09 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.2191e-10 - accuracy: 1.0000 - val_loss: 8.3627e-09 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.5400e-10 - accuracy: 1.0000 - val_loss: 8.0862e-09 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.1478e-10 - accuracy: 1.0000 - val_loss: 8.0763e-09 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.4378e-10 - accuracy: 1.0000 - val_loss: 8.0442e-09 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.7535e-10 - accuracy: 1.0000 - val_loss: 8.1913e-09 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.8530e-10 - accuracy: 1.0000 - val_loss: 8.0062e-09 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.1847e-10 - accuracy: 1.0000 - val_loss: 7.9702e-09 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.3562e-10 - accuracy: 1.0000 - val_loss: 8.1391e-09 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.1064e-10 - accuracy: 1.0000 - val_loss: 8.0280e-09 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.5416e-10 - accuracy: 1.0000 - val_loss: 7.9343e-09 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2031e-10 - accuracy: 1.0000 - val_loss: 7.9913e-09 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8023e-09 - accuracy: 1.0000 - val_loss: 8.6451e-09 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.3216e-10 - accuracy: 1.0000 - val_loss: 7.8460e-09 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.7344e-10 - accuracy: 1.0000 - val_loss: 7.7790e-09 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.5752e-10 - accuracy: 1.0000 - val_loss: 8.1705e-09 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.9212e-10 - accuracy: 1.0000 - val_loss: 8.1675e-09 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.6039e-10 - accuracy: 1.0000 - val_loss: 7.8019e-09 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.5965e-10 - accuracy: 1.0000 - val_loss: 7.7212e-09 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.8779e-10 - accuracy: 1.0000 - val_loss: 7.7931e-09 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2949e-10 - accuracy: 1.0000 - val_loss: 7.6651e-09 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.9766e-10 - accuracy: 1.0000 - val_loss: 8.2148e-09 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 5.7936e-10 - accuracy: 1.0000 - val_loss: 7.6327e-09 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.0052e-10 - accuracy: 1.0000 - val_loss: 7.6020e-09 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.4602e-10 - accuracy: 1.0000 - val_loss: 7.6111e-09 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.4239e-10 - accuracy: 1.0000 - val_loss: 7.7606e-09 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.3475e-10 - accuracy: 1.0000 - val_loss: 9.2954e-09 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2872 - accuracy: 0.9220 - val_loss: 3.0821 - val_accuracy: 0.7746\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.3497 - accuracy: 0.9598 - val_loss: 1.1675e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.2565e-05 - accuracy: 1.0000 - val_loss: 7.4945e-05 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4.1441e-05 - accuracy: 1.0000 - val_loss: 7.3009e-05 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.4891e-05 - accuracy: 1.0000 - val_loss: 6.8738e-05 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3.0956e-05 - accuracy: 1.0000 - val_loss: 6.5546e-05 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.8297e-05 - accuracy: 1.0000 - val_loss: 6.2960e-05 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.6331e-05 - accuracy: 1.0000 - val_loss: 6.0878e-05 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4743e-05 - accuracy: 1.0000 - val_loss: 5.9204e-05 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.3516e-05 - accuracy: 1.0000 - val_loss: 5.7625e-05 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.2442e-05 - accuracy: 1.0000 - val_loss: 5.6349e-05 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.1496e-05 - accuracy: 1.0000 - val_loss: 5.5283e-05 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.0725e-05 - accuracy: 1.0000 - val_loss: 5.4239e-05 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0019e-05 - accuracy: 1.0000 - val_loss: 5.3399e-05 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.9400e-05 - accuracy: 1.0000 - val_loss: 5.2648e-05 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.8854e-05 - accuracy: 1.0000 - val_loss: 5.2028e-05 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8352e-05 - accuracy: 1.0000 - val_loss: 5.1386e-05 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7881e-05 - accuracy: 1.0000 - val_loss: 5.0788e-05 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.7465e-05 - accuracy: 1.0000 - val_loss: 5.0383e-05 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.7084e-05 - accuracy: 1.0000 - val_loss: 4.9995e-05 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6737e-05 - accuracy: 1.0000 - val_loss: 4.9550e-05 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.6400e-05 - accuracy: 1.0000 - val_loss: 4.9285e-05 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.6103e-05 - accuracy: 1.0000 - val_loss: 4.8989e-05 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5829e-05 - accuracy: 1.0000 - val_loss: 4.8668e-05 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.5555e-05 - accuracy: 1.0000 - val_loss: 4.8443e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.5316e-05 - accuracy: 1.0000 - val_loss: 4.8215e-05 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.5084e-05 - accuracy: 1.0000 - val_loss: 4.8088e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.4867e-05 - accuracy: 1.0000 - val_loss: 4.7863e-05 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.4660e-05 - accuracy: 1.0000 - val_loss: 4.7775e-05 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4470e-05 - accuracy: 1.0000 - val_loss: 4.7656e-05 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.4291e-05 - accuracy: 1.0000 - val_loss: 4.7540e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.4119e-05 - accuracy: 1.0000 - val_loss: 4.7491e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3963e-05 - accuracy: 1.0000 - val_loss: 4.7429e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3807e-05 - accuracy: 1.0000 - val_loss: 4.7392e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3662e-05 - accuracy: 1.0000 - val_loss: 4.7317e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.3527e-05 - accuracy: 1.0000 - val_loss: 4.7335e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3394e-05 - accuracy: 1.0000 - val_loss: 4.7288e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.3264e-05 - accuracy: 1.0000 - val_loss: 4.7312e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.3143e-05 - accuracy: 1.0000 - val_loss: 4.7279e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.3022e-05 - accuracy: 1.0000 - val_loss: 4.7294e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2908e-05 - accuracy: 1.0000 - val_loss: 4.7295e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2801e-05 - accuracy: 1.0000 - val_loss: 4.7379e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2696e-05 - accuracy: 1.0000 - val_loss: 4.7340e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1.2594e-05 - accuracy: 1.0000 - val_loss: 4.7413e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.2497e-05 - accuracy: 1.0000 - val_loss: 4.7451e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.2399e-05 - accuracy: 1.0000 - val_loss: 4.7428e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.2305e-05 - accuracy: 1.0000 - val_loss: 4.7574e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2217e-05 - accuracy: 1.0000 - val_loss: 4.7601e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.2129e-05 - accuracy: 1.0000 - val_loss: 4.7649e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.2043e-05 - accuracy: 1.0000 - val_loss: 4.7668e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1957e-05 - accuracy: 1.0000 - val_loss: 4.7724e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1875e-05 - accuracy: 1.0000 - val_loss: 4.7763e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.1800e-05 - accuracy: 1.0000 - val_loss: 4.7823e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1720e-05 - accuracy: 1.0000 - val_loss: 4.7835e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1640e-05 - accuracy: 1.0000 - val_loss: 4.7892e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1569e-05 - accuracy: 1.0000 - val_loss: 4.7942e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1489e-05 - accuracy: 1.0000 - val_loss: 4.7977e-05 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.1420e-05 - accuracy: 1.0000 - val_loss: 4.8039e-05 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1354e-05 - accuracy: 1.0000 - val_loss: 4.8073e-05 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.1269e-05 - accuracy: 1.0000 - val_loss: 4.8154e-05 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1199e-05 - accuracy: 1.0000 - val_loss: 4.8180e-05 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1138e-05 - accuracy: 1.0000 - val_loss: 4.8171e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.1063e-05 - accuracy: 1.0000 - val_loss: 4.8290e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0996e-05 - accuracy: 1.0000 - val_loss: 4.8338e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0924e-05 - accuracy: 1.0000 - val_loss: 4.8402e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0860e-05 - accuracy: 1.0000 - val_loss: 4.8417e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0792e-05 - accuracy: 1.0000 - val_loss: 4.8460e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0728e-05 - accuracy: 1.0000 - val_loss: 4.8497e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.0658e-05 - accuracy: 1.0000 - val_loss: 4.8571e-05 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0596e-05 - accuracy: 1.0000 - val_loss: 4.8537e-05 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.0533e-05 - accuracy: 1.0000 - val_loss: 4.8719e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.0467e-05 - accuracy: 1.0000 - val_loss: 4.8760e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1.0401e-05 - accuracy: 1.0000 - val_loss: 4.8794e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0333e-05 - accuracy: 1.0000 - val_loss: 4.8859e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.0268e-05 - accuracy: 1.0000 - val_loss: 4.8846e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0213e-05 - accuracy: 1.0000 - val_loss: 4.8833e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0146e-05 - accuracy: 1.0000 - val_loss: 4.8879e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.0079e-05 - accuracy: 1.0000 - val_loss: 4.8871e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1.0017e-05 - accuracy: 1.0000 - val_loss: 4.8942e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.9539e-06 - accuracy: 1.0000 - val_loss: 4.8987e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.8896e-06 - accuracy: 1.0000 - val_loss: 4.9027e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 9.8288e-06 - accuracy: 1.0000 - val_loss: 4.9044e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.7617e-06 - accuracy: 1.0000 - val_loss: 4.9034e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.7024e-06 - accuracy: 1.0000 - val_loss: 4.8994e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.6331e-06 - accuracy: 1.0000 - val_loss: 4.9099e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.5753e-06 - accuracy: 1.0000 - val_loss: 4.9160e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.5093e-06 - accuracy: 1.0000 - val_loss: 4.9174e-05 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.4594e-06 - accuracy: 1.0000 - val_loss: 4.9064e-05 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.3899e-06 - accuracy: 1.0000 - val_loss: 4.9085e-05 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.3178e-06 - accuracy: 1.0000 - val_loss: 4.9116e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.2577e-06 - accuracy: 1.0000 - val_loss: 4.9158e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 9.1943e-06 - accuracy: 1.0000 - val_loss: 4.9171e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.1330e-06 - accuracy: 1.0000 - val_loss: 4.9191e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 9.0636e-06 - accuracy: 1.0000 - val_loss: 4.9100e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 9.0032e-06 - accuracy: 1.0000 - val_loss: 4.9089e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.9358e-06 - accuracy: 1.0000 - val_loss: 4.9127e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 8.8730e-06 - accuracy: 1.0000 - val_loss: 4.9054e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.8004e-06 - accuracy: 1.0000 - val_loss: 4.9068e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.7384e-06 - accuracy: 1.0000 - val_loss: 4.9015e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.6683e-06 - accuracy: 1.0000 - val_loss: 4.9101e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.6065e-06 - accuracy: 1.0000 - val_loss: 4.9074e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 8.5354e-06 - accuracy: 1.0000 - val_loss: 4.9012e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.4749e-06 - accuracy: 1.0000 - val_loss: 4.9040e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.4065e-06 - accuracy: 1.0000 - val_loss: 4.9047e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 8.3466e-06 - accuracy: 1.0000 - val_loss: 4.9083e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.2787e-06 - accuracy: 1.0000 - val_loss: 4.8939e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.2131e-06 - accuracy: 1.0000 - val_loss: 4.9026e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.1429e-06 - accuracy: 1.0000 - val_loss: 4.9026e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.0763e-06 - accuracy: 1.0000 - val_loss: 4.8999e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 8.0155e-06 - accuracy: 1.0000 - val_loss: 4.8912e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.9486e-06 - accuracy: 1.0000 - val_loss: 4.8808e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.8792e-06 - accuracy: 1.0000 - val_loss: 4.8879e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 7.8152e-06 - accuracy: 1.0000 - val_loss: 4.8749e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.7470e-06 - accuracy: 1.0000 - val_loss: 4.8805e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 7.6863e-06 - accuracy: 1.0000 - val_loss: 4.8832e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.6207e-06 - accuracy: 1.0000 - val_loss: 4.8702e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.5557e-06 - accuracy: 1.0000 - val_loss: 4.8752e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 7.4946e-06 - accuracy: 1.0000 - val_loss: 4.8736e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 7.4249e-06 - accuracy: 1.0000 - val_loss: 4.8645e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 7.3593e-06 - accuracy: 1.0000 - val_loss: 4.8657e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 7.2899e-06 - accuracy: 1.0000 - val_loss: 4.8441e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 7.2281e-06 - accuracy: 1.0000 - val_loss: 4.8316e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 7.1621e-06 - accuracy: 1.0000 - val_loss: 4.8207e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 7.0957e-06 - accuracy: 1.0000 - val_loss: 4.8168e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 7.0296e-06 - accuracy: 1.0000 - val_loss: 4.8109e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.9655e-06 - accuracy: 1.0000 - val_loss: 4.8029e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 6.9035e-06 - accuracy: 1.0000 - val_loss: 4.7706e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 6.8380e-06 - accuracy: 1.0000 - val_loss: 4.7644e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 6.7721e-06 - accuracy: 1.0000 - val_loss: 4.7449e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 6.7083e-06 - accuracy: 1.0000 - val_loss: 4.7431e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.6461e-06 - accuracy: 1.0000 - val_loss: 4.7275e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 6.5811e-06 - accuracy: 1.0000 - val_loss: 4.7118e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 1s 13ms/step - loss: 6.5162e-06 - accuracy: 1.0000 - val_loss: 4.7045e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 6.4524e-06 - accuracy: 1.0000 - val_loss: 4.6868e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.3962e-06 - accuracy: 1.0000 - val_loss: 4.6819e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.3327e-06 - accuracy: 1.0000 - val_loss: 4.6537e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2640e-06 - accuracy: 1.0000 - val_loss: 4.6404e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.2020e-06 - accuracy: 1.0000 - val_loss: 4.6325e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6.1368e-06 - accuracy: 1.0000 - val_loss: 4.6127e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 6.0763e-06 - accuracy: 1.0000 - val_loss: 4.6006e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.0122e-06 - accuracy: 1.0000 - val_loss: 4.5906e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.9495e-06 - accuracy: 1.0000 - val_loss: 4.5657e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.8857e-06 - accuracy: 1.0000 - val_loss: 4.5645e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.8237e-06 - accuracy: 1.0000 - val_loss: 4.5417e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.7587e-06 - accuracy: 1.0000 - val_loss: 4.5171e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.6986e-06 - accuracy: 1.0000 - val_loss: 4.5059e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.6375e-06 - accuracy: 1.0000 - val_loss: 4.4927e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.5817e-06 - accuracy: 1.0000 - val_loss: 4.4739e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 5.5178e-06 - accuracy: 1.0000 - val_loss: 4.4605e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 5.4587e-06 - accuracy: 1.0000 - val_loss: 4.4452e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.4003e-06 - accuracy: 1.0000 - val_loss: 4.4289e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.3380e-06 - accuracy: 1.0000 - val_loss: 4.4249e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5.2817e-06 - accuracy: 1.0000 - val_loss: 4.3958e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.2219e-06 - accuracy: 1.0000 - val_loss: 4.3878e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.1650e-06 - accuracy: 1.0000 - val_loss: 4.3701e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5.1072e-06 - accuracy: 1.0000 - val_loss: 4.3515e-05 - val_accuracy: 1.0000\n",
            "36/36 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean"
      ],
      "metadata": {
        "id": "BHDI7I_deLIG",
        "outputId": "308a4edd-8e2e-46d3-d5c9-b1ffe387118b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9869947275922671"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_arr"
      ],
      "metadata": {
        "id": "FOadql0keOYu",
        "outputId": "52fb5c2c-b7c9-45db-fb2b-3ba14be568e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 1.0, 1.0, 0.9349736379613357]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "dQyZTFSjXjir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['id'].astype('str')\n",
        "test['tweet'].astype('str')\n",
        "\n",
        "test_bag = TF_IDF_Vectorizer.transform(test[\"tweet\"])\n",
        "test_bag = pd.DataFrame(test_bag.toarray(), index = test.index, columns = TF_IDF_Vectorizer.get_feature_names())\n",
        "\n",
        "test['largoDocumento'] = test.tweet.str.len()\n",
        "test_bag['largoDocumento'] = test['largoDocumento']\n",
        "\n",
        "test_bag_array = np.asarray(test_bag)\n",
        "test_prediction = saved_model.predict(test_bag_array)\n",
        "\n",
        "copy = test_prediction.copy()\n",
        "predNumber = [];\n",
        "predLabel = [];\n",
        "for i in range(len(copy)):\n",
        "  if copy[i][0] > 0.5:\n",
        "    predNumber.append([1])\n",
        "    predLabel.append([\"real\"])\n",
        "  else:\n",
        "    predNumber.append([0])\n",
        "    predLabel.append([\"fake\"])\n",
        "\n",
        "prediction = pd.DataFrame(predLabel, columns=['label'])\n",
        "prediction.index += 1\n",
        "prediction = prediction.to_csv('prediction.csv')"
      ],
      "metadata": {
        "id": "hZMa_5ZcWMWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3bff43-3533-4d58-aefe-58cd7aaea131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/67 [..............................] - ETA: 1s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('prediction.csv')"
      ],
      "metadata": {
        "id": "odAqKelbXH36",
        "outputId": "9f8f6856-2aca-48e4-9977-b3a1d3ddba5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b49b0da2-b01e-4639-aabc-a0ca07aba50f\", \"prediction.csv\", 20300)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "auJ2yClw527_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats.mstats import winsorize\n",
        "from google.colab import drive, files\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CountVectorizer"
      ],
      "metadata": {
        "id": "MNSO-eRR0uXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Stop words, lematizing, stemming"
      ],
      "metadata": {
        "id": "k_IJ9w4nhXfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar datos y dividir dataset"
      ],
      "metadata": {
        "id": "rBFpCmouf3Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.random import set_seed\n",
        "set_seed(234730)"
      ],
      "metadata": {
        "id": "iRskxHDSvIB1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test_without_label.csv')"
      ],
      "metadata": {
        "id": "EDu6L8kKvMio"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['id'] = train['id'].astype(str)\n",
        "train['tweet'] = train['tweet'].astype(str)\n",
        "train['label'] = train['label'].astype(str)"
      ],
      "metadata": {
        "id": "8bBGRjnTxdsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['id'], axis=1)\n",
        "train.set_index(\"id\", inplace = True)"
      ],
      "metadata": {
        "id": "XwO2hMspxjLi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# parseo de category\n",
        "train[['label']] = train[['label']].apply(lambda col: label_encoder.fit_transform(col))"
      ],
      "metadata": {
        "id": "yI7GxIR9W6xB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
        "    train.drop('label', axis=1),\n",
        "    train['label'],\n",
        "    test_size=(1.0/3), random_state=42)"
      ],
      "metadata": {
        "id": "FXppDGXJxsy2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop words y lemmatize"
      ],
      "metadata": {
        "id": "nEVhjrJqf7Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "#analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_loc = '/root/nltk_data/corpora/wordnet.zip'\n",
        "with ZipFile(file_loc, 'r') as z:\n",
        "  z.extractall('/root/nltk_data/corpora/')"
      ],
      "metadata": {
        "id": "q_vBq9se2qMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a44906f-5dc4-455e-8ffc-7fb357a595e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopwords, lemmatize, punctuacion\n",
        "En las stop words vamos a borrar los @"
      ],
      "metadata": {
        "id": "fv52mEwudEkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#All_punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "All_punct = '''!()-[]{};:'\"\\,<>./?#%^&*_~'''\n",
        "#CountVectorizer con stopwords de Natural Language Toolkit\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def is_Not_Link(word):\n",
        "  return word[0:4] != \"http\"\n",
        "\n",
        "def remove_Punctuation(doc_split):\n",
        "  for i in range(len(doc_split)):\n",
        "    word = doc_split[i];\n",
        "    if is_Not_Link(word):\n",
        "      for elements in word:\n",
        "        if elements in All_punct:\n",
        "          doc_split[i] = word.replace(elements, \"\")\n",
        "  return doc_split\n",
        "\n",
        "def remove_Stopwords(doc_split):\n",
        "  doc_with_Stopwords = doc_split.copy();\n",
        "  i = 0\n",
        "  while i < len(doc_split):\n",
        "    word = doc_split[i];\n",
        "    if word in nltk.corpus.stopwords.words('english'):\n",
        "      doc_with_Stopwords.remove(word);\n",
        "    i = i + 1\n",
        "  return doc_with_Stopwords\n",
        "\n",
        "def new_analyzer(doc):\n",
        "  doc_split = doc.split();\n",
        "  doc_split = remove_Punctuation(doc_split);\n",
        "  doc_split = remove_Stopwords(doc_split);\n",
        "  return (Lemmatizer.lemmatize(w.lower()) for w in doc_split);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV02dxaTsbyP",
        "outputId": "3e4623c1-1e89-4999-9aff-7c634dbf3154"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk.corpus.stopwords.words('english'))"
      ],
      "metadata": {
        "id": "KRFmi9X46sE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit"
      ],
      "metadata": {
        "id": "1Sqi2438Ibd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_stop_words_stemmed = CountVectorizer(analyzer=new_analyzer, max_features=5000)\n",
        "bag_of_words = vectorizer_stop_words_stemmed.fit(X_train[\"tweet\"])\n",
        "\n",
        "print(bag_of_words.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aBmH9uJtACD",
        "outputId": "a7fc26f0-4d32-4ce6-fd2a-73f50cdd3aa8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '#coronacheck', '#coronavirus', '#coronavirusupdates', '#covid', '#covid-19', '#covid19', '#covid19associated', '#covid19like', '#covid19nigeria', '#dyk', '#factcheck', '#gujarat', '#hcps', '#indiafightscorona', '#kayburley', '#sepsis', '#socialdistancing', '$100', '$50', '&amp', '&gt&gt&gt', '(#pmsby', '(1.6%', '(1.7%', '(1.8%', '(1/2', '(2/4', '(21.9%', '(3/4', '(4025079', '(act', '(cfr', '(coronavirus', '(covid-19', '(covid-19)', '(ie', '(india', '(pmjjby', '(ppe)', '(tpm', '(who', '+', '+1', '0', '01', '02', '04', '05', '06', '0800', '0930', '1', '1%', '10', '100', '1000', '1000+', '10000', '100000', '100000+', '1000190000', '100k', '101', '102', '1040', '105', '1054', '107', '10k', '10pm', '10th', '11', '1100', '110000', '111', '1130', '114', '115', '115000', '1154', '1155pm', '116', '117', '1170', '118', '1184', '119', '11th', '12', '120', '120000', '1206', '1217', '1219', '123', '128', '12th', '13', '130', '130000', '134', '13th', '14', '140', '1455', '1481', '14th', '15', '150', '1500', '15000', '15001100000', '1504', '156', '158', '15th', '16', '160', '167', '16th', '17', '170', '176', '17th', '18', '18th', '19', '190', '19000', '195', '19th', '1m', '1ondo', '1plateau', '1st', '1…', '1⃣', '2', '20', '20%', '200', '2000', '20000', '200000', '2001', '2005', '2008', '2009', '200k', '2010', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2020presidentialelection', '2020👇', '2021', '2022', '204', '20k', '21', '21000', '214', '2159', '21k', '22', '2200', '22nd', '23', '232', '233', '23k', '24', '2404585', '242', '247', '24th', '25', '25000', '25th', '26', '2621', '26th', '27', '2700', '276', '27th', '28', '288', '28k', '28th', '29', '299', '29k', '29th', '2bauchi', '2gombe', '2m', '2nd', '2pm', '3', '30', '300', '3000', '30000', '300k', '30th', '31', '31k', '31st', '32', '323', '33', '34', '35', '350', '35k', '36', '37', '38', '385', '38k', '39', '3bauchi', '3borno', '3rd', '4', '40', '400', '4000', '400000', '41', '42', '42k', '43', '4322', '43k', '44', '4422', '44k', '45', '46', '47', '47k', '48', '481', '49', '49000', '4th', '4x', '5', '50', '500', '5000', '50000', '500000', '501', '50k', '51', '52', '53', '54', '55', '55000', '56', '56k', '57', '57k', '58', '59', '5g', '5th', '5x', '6', '60', '600', '6000', '60000', '61', '62', '63', '64', '65', '65+', '65k', '66', '67', '675', '68', '69', '6th', '7', '7.5', '70', '70k', '7103', '72', '73', '74', '75', '76', '77', '78', '7day', '7th', '8', '80', '80%', '800', '8000', '81', '83', '8316', '85', '86', '87', '89', '8am', '8th', '9', '90', '900', '90000+', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9th', '=', '??', '???covid19', '@aajtak', '@aamaadmiparty', '@africacdc', '@airnewsalerts', '@alexismadrigal', '@ani', '@arvindkejriwal', '@ashwinikchoubey', '@biharhealthdept', '@boomlivein', '@butchthorne', '@cdc_hivaids', '@cdcdirector', '@cdcemergency', '@cdcgov', '@cdcmmwr', '@cdctravel', '@chikwei', '@cmoguj', '@cmomaharashtra', '@cnn', '@conservvoice', '@couchmaria', '@covid19tracking', '@covidindiaseva', '@covidnewsbymib', '@csogok', '@ddnewslive', '@dgpgujarat', '@dreoehanire', '@drharshvardhan', '@drhvoffice', '@drjohnwhyte', '@drtedros', '@factchecknet', '@fmohnigeria', '@followlasg', '@gavi', '@geraintmeysydd', '@govrondesantis', '@harvardgh', '@hhsgov', '@hmoindia', '@icmrdelhi', '@imperialcollege', '@julie34479', '@matthancock', '@mbuhari', '@minhealthnz', '@mohfw_india', '@mohfwindia', '@mygovindia', '@narendramodi', '@nature', '@nih', '@niosh', '@nitiaayog', '@normanbrennan', '@nsitharaman', '@ntanewsnow', '@nytimes', '@peterwa97559477', '@pib_india', '@pibindia', '@pjpaton', '@pmoindia', '@prakashjavdekar', '@profbhargava', '@ptfcovid19', '@ptinews', '@realdonaldtrump', '@riccigeri', '@smileygirl19683', '@statedept', '@surgeon_general', '@theatlantic', '@thelancet', '@tony80554056', '@vmaledew', '@webmd', '@whatsapp', '@who', '@whoafro', '@whos', '@yayitsrob', 'a', 'a&ampe', 'aaj', 'aamir', 'abbott', 'abia', 'abia1', 'abia2', 'abia6', 'abia9', 'ability', 'able', 'abortion', 'about', 'absolute', 'abuja', 'acc', 'accelerate', 'accelerating', 'accelerator', 'accept', 'accepted', 'access', 'accidentally', 'according', 'account', 'accounting', 'accurate', 'accused', 'achieve', 'achievement', 'achieves', 'acquired', 'across', 'act', 'actaccelerator', 'acting', 'action', 'activated', 'active', 'actively', 'activist', 'activity', 'actor', 'actress', 'actual', 'actually', 'acute', 'ad', 'adamawa1', 'add', 'added', 'adding', 'addition', 'additional', 'address', 'adhere', 'adjust', 'adjustment', 'administration', 'administrator', 'admins', 'admission', 'admit', 'admits', 'admitted', 'adult', 'advance', 'advantage', 'advice', 'advise', 'advised', 'adviser', 'advises', 'advising', 'advisory', 'affair', 'affect', 'affected', 'affecting', 'africa', 'african', 'after', 'again', 'age', 'aged', 'agency', 'agent', 'aggressive', 'ago', 'agreed', 'agreement', 'agrees', 'ahead', 'aid', 'aiims', 'aim', 'aimed', 'air', 'airborne', 'airline', 'airport', 'airway', 'akwa', 'al', 'alabama', 'album', 'alcohol', 'alert', 'ali', 'alien', 'alive', 'alkaline', 'all', 'allah', 'alleged', 'allegedly', 'allergy', 'allocation', 'allow', 'allowance', 'allowed', 'allows', 'alltime', 'almost', 'alone', 'along', 'alongside', 'already', 'also', 'alternative', 'although', 'always', 'am', 'amazing', 'amazon', 'ambulance', 'america', 'american', 'americold', 'amid', 'amidst', 'amit', 'amitabh', 'among', 'amongst', 'amount', 'an', 'analysis', 'anambra', 'anambra1', 'anambra2', 'and', 'andhra', 'andor', 'and…', 'angela', 'anger', 'angry', 'animal', 'announce', 'announced', 'announcement', 'announces', 'announcing', 'another', 'answer', 'anthony', 'antibiotic', 'antibody', 'antigen', 'antimalarial', 'antiviral', 'antonio', 'anxiety', 'any', 'anybody', 'anyone', 'anything', 'aoc', 'apart', 'api', 'apologise', 'app', 'appalling', 'apparently', 'appeal', 'appear', 'appeared', 'appears', 'apple', 'apply', 'appointed', 'approach', 'appropriate', 'approval', 'approved', 'approximately', 'april', 'ar', 'arabia', 'are', 'area', 'arent', 'aren’t', 'argar', 'argentina', 'arizona', 'arkansas', 'arm', 'army', 'aroha', 'around', 'arrange', 'arrest', 'arrested', 'arrival', 'arrived', 'arriving', 'arsenicum', 'article', 'asia', 'asian', 'aside', 'ask', 'asked', 'asking', 'asks', 'aspect', 'aspirin', 'ass', 'assam', 'assessment', 'assign', 'assigned', 'assist', 'assistance', 'associate', 'associated', 'association', 'assume', 'asymptomatic', 'at', 'athlete', 'attack', 'attacked', 'attempt', 'attempted', 'attend', 'attendance', 'attended', 'attending', 'attention', 'attributed', 'auckland', 'audio', 'aug', 'august', 'auspol', 'australia', 'australian', 'author', 'authority', 'authorization', 'autopsy', 'availability', 'available', 'average', 'avifavir', 'avoid', 'avoiding', 'awaiting', 'aware', 'awareness', 'away', 'ayurveda', 'ayurvedic', 'ayush', 'az', 'azim', 'azithromycin', 'b', 'baba', 'baby', 'back', 'backbone', 'backfill', 'backlog', 'backlogged', 'bacteria', 'bacterium', 'bad', 'bag', 'bakery', 'baking', 'balance', 'bame', 'ban', 'bangalore', 'bank', 'banned', 'banning', 'bar', 'barack', 'baseball', 'based', 'basic', 'basically', 'basis', 'bat', 'bath', 'battle', 'bauchi', 'bauchi1', 'bauchi2', 'bauchi3', 'bauchi8', 'bay', 'bayelsa1', 'bayelsa14', 'bbc', 'be', 'beach', 'beard', 'beat', 'beaten', 'beating', 'became', 'because', 'become', 'becomes', 'becoming', 'bed', 'beef', 'been', 'beer', 'before', 'began', 'begin', 'beginning', 'begun', 'behaviour', 'behind', 'being', 'belief', 'believe', 'belong', 'benchmark', 'benefit', 'bengal', 'benue', 'benue1', 'benue3', 'bereavement', 'berlin', 'besides', 'best', 'betacoronaviruses', 'betadine', 'better', 'beware', 'beyond', 'bharat', 'bicarbonate', 'biden', 'bidensoetoro', 'big', 'biggest', 'bihar', 'bill', 'billion', 'billionaire', 'bima', 'bioengineered', 'biological', 'biology', 'biotech', 'bioweapon', 'bird', 'birth', 'bit', 'bizarre', 'bjp', 'black', 'blame', 'blamed', 'bleach', 'bless', 'block', 'blog', 'blood', 'blowing', 'blue', 'board', 'body', 'boiled', 'boiling', 'bolivia', 'bollywood', 'bolsonaro', 'bolton', 'book', 'boost', 'border', 'boris', 'borno', 'borno1', 'borno12', 'borno2', 'borno6', 'borno8', 'both', 'bought', 'bounce', 'bound', 'bowl', 'box', 'boy', 'brain', 'branch', 'brazil', 'brazilian', 'break', 'breakdown', 'breakfast', 'breaking', 'breastfeed', 'breastfeeding', 'breath', 'breathe', 'breathing', 'brexit', 'brian', 'briefing', 'bring', 'bringing', 'brings', 'britain', 'british', 'briton', 'broad', 'broader', 'broiler', 'broke', 'broken', 'brother', 'brought', 'budget', 'bug', 'build', 'building', 'built', 'bull', 'burden', 'buried', 'burning', 'bury', 'bus', 'business', 'busy', 'but', 'buy', 'buying', 'by', 'c', 'c19', 'ca', 'cabbage', 'cabinet', 'calculate', 'california', 'california’s', 'call', 'called', 'calling', 'came', 'camel', 'camila', 'camp', 'campaign', 'can', 'canada', 'canadian', 'cancel', 'cancellation', 'cancelled', 'cancer', 'candidate', 'candle', 'cannot', 'cant', 'can’t', 'capacity', 'capital', 'caption', 'capture', 'captured', 'capturing', 'caput', 'car', 'carbon', 'card', 'cardiac', 'care', 'careful', 'carefully', 'carolina', 'carona', 'carried', 'carrier', 'carry', 'carrying', 'case', 'caseload', 'cases+deaths', 'casestill', 'cases”', 'cases\\u2063', 'casual', 'casualty', 'cat', 'catch', 'catching', 'category', 'cattle', 'caught', 'cause', 'caused', 'causing', 'caveat', 'ccp', 'cdc', 'cdc’s', 'cdnpoli', 'celebrate', 'celebrating', 'celebratory', 'celebrity', 'cell', 'center', 'central', 'centre', 'centreled', 'ceo', 'certain', 'certainly', 'certificate', 'cfr', 'cghs', 'chain', 'chair', 'chairman', 'challenge', 'challenging', 'chance', 'chancellor', 'chandigarh', 'change', 'changed', 'changing', 'channel', 'charge', 'charity', 'charles', 'chart', 'cheap', 'check', 'checked', 'checker', 'checking', 'chemical', 'chemist', 'chest', 'chhattisgarh', 'chicken', 'chief', 'child', 'childhood', 'child’s', 'chile', 'chin', 'china', 'chinese', 'chip', 'chlorine', 'chloroquine', 'choice', 'choose', 'chris', 'christchurch', 'chronic', 'church', 'chyna', 'cinema', 'circuit', 'circulate', 'circulated', 'circulating', 'circulation', 'circumstance', 'citizen', 'city', 'civil', 'claim', 'claimed', 'claiming', 'claire', 'clarification', 'clarified', 'clarifies', 'clarify', 'class', 'clean', 'cleaner', 'cleaning', 'clear', 'cleared', 'clearly', 'click', 'climate', 'climb', 'clinic', 'clinical', 'clinician', 'clip', 'close', 'closed', 'closely', 'closer', 'closing', 'closure', 'cloth', 'clothes', 'club', 'cluster', 'cm', 'cnn', 'cobra', 'coca', 'cocaine', 'code', 'coffee', 'coffin', 'coin', 'cold', 'collaboration', 'collaborative', 'collapse', 'collapsing', 'colleague', 'collection', 'collective', 'college', 'colloidal', 'colombia', 'color', 'colorado', 'colour', 'combat', 'combination', 'combined', 'come', 'coming', 'commemorative', 'commercial', 'commit', 'commitment', 'commits', 'committed', 'committee', 'common', 'commonly', 'communal', 'communicating', 'communication', 'community', 'communitybased', 'company', 'company’s', 'comparable', 'compare', 'compared', 'comparison', 'compassionate', 'complaint', 'complete', 'completed', 'completely', 'completes', 'complex', 'complicated', 'complication', 'comprehensive', 'comprehensively', 'compulsory', 'computer', 'concentrated', 'concentration', 'concern', 'concerned', 'concluded', 'condition', 'conduct', 'conducted', 'conducting', 'conference', 'confidence', 'confident', 'confirm', 'confirmation', 'confirmed', 'confirming', 'confirms', 'confused', 'congregation', 'congress', 'connected', 'connecticut', 'connection', 'consecutive', 'consequence', 'consider', 'consideration', 'considered', 'considering', 'consistent', 'consistently', 'conspiracy', 'constant', 'consult', 'consultation', 'consuming', 'consumption', 'contact', 'contacted', 'contacting', 'contain', 'containment', 'contains', 'contaminated', 'context', 'continue', 'continued', 'continues', 'continuing', 'continuous', 'continuously', 'contract', 'contracted', 'contracting', 'contrary', 'contribute', 'contributed', 'contributing', 'contribution', 'control', 'controlled', 'controller', 'controlling', 'controversial', 'controversy', 'convalescent', 'convened', 'convention', 'conversation', 'conversion', 'convert', 'converted', 'converting', 'cool', 'coordinate', 'coordinated', 'coordination', 'cop', 'cope', 'copied', 'coping', 'core', 'corona', 'coronabeer', 'coronacheck', 'coronaoutbreak', 'coronaupdate', 'coronaupdates', 'coronaupdatesindia', 'coronavac', 'coronavirus', 'coronavirus.', 'coronavirus.�', 'coronaviruses', 'coronavirusfacts', 'coronavirusindia', 'coronavirusoutbreak', 'coronaviruspandemic', 'coronavirusthemed', 'coronavirusupdate', 'coronavirusupdates', 'coronavirus”', 'coronawarriors', 'coronawatch', 'coronil', 'corporation', 'corps', 'corpse', 'correct', 'corrected', 'correction', 'correctly', 'correctness', 'correlation', 'corridor', 'corrientes', 'corticosteroid', 'cost', 'costco', 'cough', 'coughing', 'could', 'couldnt', 'couldn’t', 'council', 'count', 'counted', 'counter', 'counterpart', 'counting', 'countries@drtedros', 'country', 'country’s', 'county', 'couple', 'coupled', 'course', 'court', 'court’s', 'cov2', 'covax', 'covaxin', 'cover', 'coverage', 'covered', 'covering', 'covid', 'covid-19', 'covid-19.', 'covid-19.�', 'covid-19s', 'covid-19\\u200b', 'covid-19\\u2063', 'covid1', 'covid19', 'covid19india', 'covid19nigeria', 'covid19pakistan', 'covid19pandemic', 'covid19related', 'covid19science', 'covid19vaccine', 'covid19’s', 'covid19…', 'covid2019', 'covidactnow', 'covidindiaseva', 'covidiots', 'covidnet', 'covidrelated', 'covidsafe', 'covidupdates', 'covidview', 'covidー19', 'cow', 'cr', 'crazy', 'cream', 'create', 'created', 'creating', 'credit', 'creeping', 'crematorium', 'creted', 'crew', 'cricket', 'crime', 'criminal', 'criminalized', 'crisis', 'cristiano', 'criterion', 'critical', 'critically', 'crore', 'cross', 'crossed', 'crossing', 'crowd', 'crowded', 'crown', 'crucial', 'cruise', 'cry', 'ct', 'cuba', 'cultural', 'cummings', 'cumulative', 'cumulatively', 'cunial', 'cuomo', 'cup', 'cupboard', 'curbside', 'cure', 'cured', 'cureddischargedmigrated', 'cureddischargedmigrated+active', 'curedrecovered', 'curfew', 'currency', 'current', 'currently', 'curve', 'customer', 'cut', 'cutting', 'cv', 'cv19', 'c…', 'd', 'da', 'dad', 'dadar', 'daily', 'dakota', 'dallas', 'damage', 'dana', 'dancing', 'danger', 'dangerous', 'daniel', 'dark', 'dashboard', 'data', 'dataset', 'date', 'date…', 'dating', 'datoscoronavirus', 'daughter', 'david', 'dawood', 'dawson', 'day', 'dc', 'dcgi', 'de', 'dead', 'deadline', 'deadly', 'deal', 'dear', 'death', 'deathsmillion', 'debate', 'debt', 'debunk', 'debunked', 'debunking', 'decade', 'deceased', 'december', 'decent', 'decide', 'decided', 'deciding', 'decision', 'decisive', 'decisively', 'deck', 'declaration', 'declared', 'declares', 'decline', 'declined', 'declining', 'decontamination', 'decrease', 'decreased', 'decreasing', 'dedicated', 'deep', 'deeper', 'defeat', 'defeated', 'defeating', 'defence', 'defend', 'defense', 'defer', 'deficiency', 'definitely', 'definition', 'degree', 'dehradun', 'del', 'delaware', 'delay', 'delayed', 'deleted', 'delhi', 'delivered', 'delivering', 'delivery', 'delta', 'delta10', 'delta12', 'delta3', 'delta6', 'delta7', 'demand', 'demanding', 'democrat', 'democratic', 'demographic', 'demonstrated', 'denied', 'denies', 'denmark', 'departing', 'department', 'departure', 'depending', 'depends', 'deploy', 'deployed', 'depression', 'deputy', 'desantis', 'describes', 'describing', 'description', 'design', 'despite', 'destroy', 'destroyed', 'detail', 'detect', 'detected', 'detection', 'determine', 'develop', 'developed', 'developer', 'developing', 'development', 'dexamethasone', 'dg', 'diabetes', 'diagnose', 'diagnosed', 'diagnosis', 'diagnostic', 'diagnostics', 'did', 'didnt', 'didn’t', 'dido', 'die', 'died', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'digital', 'dioxide', 'dip', 'direct', 'direction', 'directive', 'directly', 'director', 'directorgeneral', 'directs', 'dirty', 'disaster', 'discharge', 'discharged', 'discontinued', 'discover', 'discovered', 'discrepancy', 'discus', 'discussion', 'disease', 'disinfect', 'disinfectant', 'disinfection', 'disorder', 'disparity', 'disproportionately', 'disrupted', 'disruption', 'distance', 'distancing', 'distributed', 'distributing', 'distribution', 'district', 'diverse', 'dna', 'do', 'doc', 'doctor', 'doctored', 'document', 'documentary', 'doesnt', 'doesn’t', 'dog', 'doha', 'dollar', 'domestic', 'dominic', 'donald', 'donaldtrump', 'donate', 'donated', 'donation', 'done', 'dont', 'don’t', 'door', 'dos', 'dose', 'double', 'doubled', 'doubling', 'doubt', 'doug', 'down', 'download', 'dozen', 'dr', 'dranthonyfauci', 'drink', 'drinking', 'drive', 'driven', 'driver', 'driving', 'drop', 'droplet', 'dropped', 'drove', 'drug', 'dublin', 'duck', 'due', 'during', 'duterte', 'duty', 'dy', 'dying', 'dyk', 'dynamic', 'each', 'ear', 'earlier', 'early', 'earn', 'earth', 'ease', 'easier', 'easily', 'easing', 'east', 'easy', 'eat', 'eating', 'ebola', 'ebonyi11', 'ebonyi3', 'ebonyi4', 'ebonyi9', 'economic', 'economy', 'ecuador', 'ed', 'edo', 'edo1', 'edo17', 'edo22', 'education', 'educational', 'edward', 'effect', 'effective', 'effectively', 'effectiveness', 'efficient', 'efficiently', 'effort', 'eight', 'either', 'ekiti', 'ekiti1', 'ekiti2', 'ekiti4', 'ekiti6', 'elbow', 'elderly', 'elected', 'election', 'elective', 'elevated', 'eligible', 'eliminate', 'eliminates', 'elizabeth', 'else', 'email', 'emerged', 'emergency', 'emerging', 'emirate', 'emission', 'emphasis', 'employee', 'employment', 'empty', 'enable', 'enables', 'encourage', 'encouraged', 'encourages', 'encouraging', 'end', 'ended', 'ending', 'enforce', 'enforcement', 'engagement', 'engaging', 'england', 'enhanced', 'enjoy', 'enough', 'enrollment', 'ensure', 'ensured', 'ensuring', 'enter', 'entered', 'entire', 'entitled', 'entrance', 'entry', 'enugu', 'enugu15', 'enugu2', 'enugu6', 'epidemic', 'epidemiological', 'epidemiologist', 'equipment', 'equitable', 'equity', 'er', 'eradicate', 'erratic', 'erroneously', 'error', 'especially', 'essential', 'established', 'establishes', 'estimate', 'estimated', 'et', 'etc', 'ethnic', 'ethnicity', 'eu', 'europe', 'european', 'evaluate', 'evaluation', 'evangelical', 'evangelicals', 'even', 'evening', 'event', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everywhere', 'eviction', 'evidence', 'exact', 'exactly', 'exaggerated', 'exam', 'examination', 'examines', 'example', 'exceed', 'exceeded', 'exceeds', 'except', 'excess', 'exclusive', 'excuse', 'executive', 'exempt', 'exemption', 'exercise', 'exhausted', 'exist', 'existed', 'existing', 'exists', 'expand', 'expanded', 'expanding', 'expansion', 'expect', 'expected', 'expecting', 'experience', 'experiencing', 'expert', 'explain', 'explained', 'explains', 'exponential', 'exponentially', 'exporting', 'exposed', 'exposure', 'expresident', 'expressly', 'extended', 'extending', 'extends', 'extension', 'extensive', 'extent', 'extra', 'extreme', 'extremely', 'eye', 'fabiflu', 'face', 'facebook', 'facemask', 'facemasks', 'facility', 'facing', 'fact', 'fact-check', 'factcheck', 'factchecking', 'factor', 'fail', 'failed', 'failing', 'failure', 'fair', 'faith', 'fake', 'fakenews', 'fall', 'fallen', 'falling', 'false', 'falsehood', 'family', 'famous', 'fan', 'faq', 'far', 'farmer', 'fascinating', 'fascist', 'fashion', 'fast', 'faster', 'fastest', 'fatal', 'fatality', 'fatalityrate', 'father', 'fatigue', 'fauccis', 'fauci', 'faucian', 'favipiravir', 'favor', 'fbi', 'fct', 'fct138', 'fct14', 'fct25', 'fct26', 'fct29', 'fct34', 'fct35', 'fct38', 'fct52', 'fct60', 'fda', 'fear', 'feature', 'feb', 'february', 'federal', 'feedback', 'feel', 'feeling', 'fell', 'fellowship', 'felt', 'fema', 'female', 'fennel', 'ferguson', 'fernández', 'fever', 'fewer', 'fewest', 'fibrosis', 'fiction', 'field', 'fifth', 'fight', 'fighting', 'figure', 'figuring', 'file', 'filed', 'filipino', 'filled', 'film', 'filmed', 'filming', 'final', 'finalising', 'finally', 'finance', 'financial', 'financially', 'find', 'finding', 'fine', 'fined', 'finished', 'fire', 'firearm', 'fired', 'firing', 'first', 'fiscal', 'fit', 'fitness', 'five', 'fix', 'fixed', 'fixing', 'fl', 'flag', 'flattened', 'flawed', 'flew', 'flight', 'floor', 'florida', 'florida’s', 'flour', 'flouting', 'flu', 'flulike', 'fly', 'flying', 'focus', 'focused', 'focusing', 'focussed', 'folk', 'follow', 'followed', 'follower', 'following', 'follows', 'followup', 'food', 'foodsafety', 'foodshortages', 'foot', 'footage', 'football,', 'for', 'forbade', 'force', 'forced', 'ford', 'ford’s', 'forecast', 'foreign', 'foreigner', 'foreseeable', 'forever', 'forged', 'forget', 'forgotten', 'form', 'former', 'fortaleza', 'forward', 'fought', 'found', 'foundation', 'founder', 'four', 'fourmonth', 'fourteen', 'fourth', 'fox', 'foxnews', 'fraction', 'framework', 'france', 'francis', 'fraud', 'free', 'freedom', 'freely', 'freeview', 'freezing', 'french', 'frequency', 'frequently', 'fresh', 'freshly', 'friday', 'friend', 'frm', 'from', 'front', 'frontline', 'frozen', 'fruit', 'frustration', 'ft', 'fuck', 'fuel', 'full', 'fully', 'fullyimmunizeeverychild', 'fun', 'function', 'functional', 'fund', 'fundamental', 'fundamentally', 'funded', 'funding', 'funeral', 'fungal', 'funneled', 'funny', 'furlough', 'future', 'ga', 'gain', 'galicia', 'game', 'gandhi', 'gandhinagar', 'ganga', 'gap', 'gargle', 'gargling', 'garib', 'garlic', 'gate', 'gather', 'gathered', 'gathering', 'gautambuddhnagar', 'gave', 'gay', 'gear', 'gender', 'general', 'generally', 'generate', 'generated', 'generation', 'genetic', 'genexpert', 'genius', 'genocide', 'genomic', 'gentleman', 'genuine', 'geographical', 'george', 'georgia', 'gerais', 'germ', 'german', 'germany', 'get', 'getting', 'ghana', 'ghana’s', 'ghislaine', 'gift', 'gifted', 'gilead', 'ginger', 'girl', 'give', 'given', 'giving', 'glad', 'global', 'globally', 'globe', 'glove', 'go', 'goal', 'god', 'goi', 'going', 'gold', 'golf', 'gombe', 'gombe1', 'gombe2', 'gombe21', 'gombe3', 'gombe30', 'gombe4', 'gombe5', 'gombe6', 'gone', 'gonna', 'good', 'goodbye', 'goodwill', 'google', 'gop', 'got', 'gotten', 'gourd', 'gov', 'gove', 'government', 'government’s', 'governor', 'govt', 'gowdy', 'gown', 'gp', 'gps', 'grade', 'graded', 'graduate', 'graf', 'grand', 'grandparent', 'grant', 'granted', 'graph', 'graphic', 'grateful', 'gratitude', 'grave', 'graveyard', 'great', 'greater', 'greatest', 'greatly', 'greece', 'green', 'gretchen', 'grieve', 'grim', 'grocery', 'ground', 'groundbreaking', 'group', 'grow', 'growing', 'growth', 'guess', 'guest', 'guidance', 'guide', 'guideline', 'guidelinesnotifications', 'gujarat', 'gun', 'guy', 'gym', 'h1n1', 'ha', 'habit', 'hair', 'hajipur', 'half', 'hall', 'hallmark', 'halt', 'hamster', 'hancock', 'hand', 'handed', 'handing', 'handle', 'handling', 'handwashing', 'hangover', 'hank', 'hantavirus', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'harder', 'harding', 'hardship', 'harm', 'harmful', 'harris', 'harvard', 'haryana', 'hasnt', 'hasn’t', 'have', 'havent', 'haven’t', 'hcq', 'he', 'head', 'headache', 'headline', 'headroom', 'heal', 'health', 'healthcare', 'healthline', 'healthworkers', 'healthy', 'health\\u2063', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heath', 'heavy', 'height', 'held', 'hell', 'hello', 'help', 'helped', 'helping', 'helpline', 'hence', 'her', 'herbal', 'herd', 'here', 'here’s', 'hero', 'he’s', 'hhs', 'hi', 'high', 'higher', 'highest', 'highlight', 'highlighting', 'highly', 'highrisk', 'hill', 'hindu', 'his', 'historic', 'historical', 'history', 'hit', 'hiv', 'hmh', 'hoax', 'hold', 'holding', 'holiday', 'hollywood', 'home', 'homemade', 'homeopathic', 'homequarantine', 'hon', 'honey', 'hong', 'honjo', 'honourable', 'honoured', 'hope', 'hopefully', 'hoping', 'hopkins', 'horizon', 'horny', 'horse', 'hosp', 'hospital', 'hospitalists', 'hospitality', 'hospitalization', 'hospitalizationsicu', 'hospitalized', 'hospitallevel', 'host', 'hosting', 'hot', 'hotel', 'hotline', 'hotspot', 'hour', 'hours.', 'house', 'household', 'housing', 'how', 'however', 'hr', 'https://t.co/03hguvcatu', 'https://t.co/1ato9qo0he', 'https://t.co/25nxirzawb.', 'https://t.co/2caogenfur', 'https://t.co/2l2qxh0m45', 'https://t.co/2rvg3dwbkt.', 'https://t.co/2xlf9mccft.', 'https://t.co/3lb8xsviva', 'https://t.co/4ku7nklzcq', 'https://t.co/4yblkisg6u', 'https://t.co/5l9jptglai', 'https://t.co/5rbbdr4r0u', 'https://t.co/6kydz6twwe', 'https://t.co/7c8w5pwnmp', 'https://t.co/98jmut3igq.', 'https://t.co/9jgwi7gszz', 'https://t.co/9zn2zytaud.', 'https://t.co/a36kao2nwa', 'https://t.co/adsrezpsfh', 'https://t.co/bzvndgpell', 'https://t.co/c0tikpeaju', 'https://t.co/c2ytwok7it', 'https://t.co/cs7uxqrrmn', 'https://t.co/dmfpoapmjw.', 'https://t.co/dmfpob7nbu.', 'https://t.co/dyojlfjhyd', 'https://t.co/e9cshsdhgy', 'https://t.co/ebclrcf6q3', 'https://t.co/eckw6gemjf', 'https://t.co/fqhg5m5xrn', 'https://t.co/ft6cgmampx.', 'https://t.co/g8duiqxiwr.', 'https://t.co/gialss3xd7', 'https://t.co/gudbpy0x9d.', 'https://t.co/i0ya5yftvz', 'https://t.co/ioqv5omdka.', 'https://t.co/kulxwpdc15.', 'https://t.co/kzncyfx70q', 'https://t.co/lcfch0fxct', 'https://t.co/lxwme4nubd.', 'https://t.co/mcp09udspe', 'https://t.co/mlj56qcw37.', 'https://t.co/mp3spdaktl', 'https://t.co/mpuji2yq0v', 'https://t.co/n4zdlimwkk', 'https://t.co/n6iwcmznbk', 'https://t.co/n8oor2o8ep', 'https://t.co/nyzlpjyfxm', 'https://t.co/opc8z4tnib', 'https://t.co/oz9kcdajij', 'https://t.co/pagzfxjnbi', 'https://t.co/pgxjssssu9', 'https://t.co/pqd1i8xgam', 'https://t.co/pzrmh3tkeq', 'https://t.co/pzrmh4bl5y', 'https://t.co/q1dtcxukin.', 'https://t.co/sldrvxxfcz', 'https://t.co/sldrvxxfcz.', 'https://t.co/swcqc3xlyj', 'https://t.co/tt49zoec8n.', 'https://t.co/tt49zon1hf.', 'https://t.co/uargztrh5l.', 'https://t.co/uwscnvzq9m', 'https://t.co/vih89d6gzj', 'https://t.co/wiufbkr3uh', 'https://t.co/wlbfspafzw', 'https://t.co/wlp3gx6f5t', 'https://t.co/wwdyvm3nnl', 'https://t.co/xdfm4f80bx', 'https://t.co/xrey2ncs7n', 'https://t.co/y3qswuj23i', 'https://t.co/yapqkvdncj', 'https://t.co/z9k0shxj1g.', 'https://t.co/zc39azvrge', 'https://t.co/zfgtnxmadb', 'https://t.co/zp4vylo0pb', 'https://t.co/zp4vylo0pb.', 'https://t.co/zqrpneofet', 'https://t.co/zxferiys6i', 'https:…', 'huawei', 'huddled', 'huge', 'hugging', 'human', 'humanitarian', 'humanity', 'humanmade', 'hundred', 'hunger', 'hungry', 'hurricane', 'hurt', 'husband', 'hussain', 'hussein', 'hut', 'hv', 'hyderabad', 'hydroxichloroquine', 'hydroxy', 'hydroxychloroquine', 'hygiene', 'hypermarket', 'hypochlorite', 'hypoxia', 'h…', 'i', 'ibadan', 'ibom', 'ibom11', 'ibom13', 'ibrahim', 'ibuprofen', 'icai', 'ice', 'icmr', 'icmrfightscovid19', 'icu', 'icu\\u2063', 'icymi', 'id', 'idaho', 'idea', 'identification', 'identified', 'identify', 'identifying', 'idiocy', 'ie', 'if', 'ignorance', 'ignore', 'ignoring', 'ii', 'iii', 'iit', 'ill', 'illegal', 'illegally', 'illinois', 'illness', 'im', 'image', 'imam', 'imf', 'immediate', 'immediately', 'immigrant', 'immigration', 'immune', 'immunisation', 'immunity', 'immunization', 'immunizationforall', 'immunoresponse', 'immunosuppression', 'imo', 'imo1', 'imo12', 'imo2', 'imo3', 'imo5', 'imo9', 'impact', 'impacted', 'impeachment', 'imperial', 'implant', 'implement', 'implementation', 'implemented', 'implication', 'implying', 'importance', 'important', 'importantly', 'imported', 'impose', 'imposed', 'impossible', 'impressive', 'improve', 'improved', 'improvement', 'improves', 'improving', 'imran', 'in', 'inching', 'incidence', 'incident', 'incl', 'include', 'included', 'includes', 'including', 'inclusion', 'income', 'incompetence', 'incomplete', 'increase', 'increased', 'increasing', 'incubation', 'incurred', 'independent', 'index', 'india', 'india)', 'india.', 'indiafightscorona', 'indiafightscoronavirus', 'indiafightscovid19', 'indian', 'indiana', 'indiawillwin', 'india’s', 'indicate', 'indicated', 'indicates', 'indicating', 'indication', 'indicator', 'indigenous', 'indigenously', 'individual', 'indonesia', 'indonesian', 'indoors', 'indore', 'industrial', 'industrialist', 'industry', 'ineffective', 'inequity', 'inevitable', 'infant', 'infect', 'infected', 'infecting', 'infection', 'infectious', 'infects', 'inference', 'inflammation', 'inflammatory', 'inflating', 'influence', 'influenza', 'info', 'infodemic', 'inform', 'information', 'informed', 'inhalation', 'inhale', 'inhaling', 'inhibitor', 'initial', 'initiated', 'initiation', 'initiative', 'injecting', 'injection', 'inmate', 'inside', 'insight', 'insists', 'instagram', 'instant', 'instead', 'institute', 'institution', 'institutional', 'instruction', 'insurance', 'intended', 'intense', 'intensive', 'interest', 'interested', 'interim', 'international', 'internet', 'interpret', 'intervention', 'interview', 'introduce', 'introduced', 'introduces', 'introduction', 'invention', 'investigate', 'investigated', 'investigation', 'investigator', 'investment', 'invite', 'invoking', 'involve', 'involved', 'in…', 'iodine', 'ipc', 'iran', 'ireland', 'is', 'islam', 'island', 'isnt', 'isn’t', 'isolate', 'isolated', 'isolating', 'isolation', 'israel', 'issue', 'issued', 'it', 'italian', 'italy', 'item', 'it’s', 'ive', 'ivermectin', 'i…', 'jacksonville', 'jail', 'jair', 'jamaat', 'jan', 'janeiro', 'january', 'japan', 'japanese', 'jeevan', 'jersey', 'jesus', 'jet', 'jharkhand', 'ji', 'jigawa2', 'jihadi', 'jinping', 'job', 'joe', 'john', 'johnson', 'join', 'joined', 'journal', 'journalist', 'joão', 'juice', 'july', 'jump', 'jumped', 'jumping', 'june', 'jurisdiction', 'just', 'justin', 'jyoti', 'k', 'ka', 'kaduna', 'kaduna10', 'kaduna17', 'kaduna19', 'kaduna23', 'kaduna6', 'kaduna8', 'kaduna9', 'kalonji', 'kano', 'kano1', 'kano2', 'kano3', 'kano4', 'kano5', 'kano6', 'kano73', 'kansa', 'karnataka', 'katsina', 'katsina1', 'katsina21', 'katsina6', 'katsina7', 'kayburley', 'kebbi2', 'keep', 'keeping', 'keir', 'kejriwal', 'kentucky', 'kenya', 'kept', 'kerala', 'key', 'khan', 'kia', 'kick', 'kid', 'kidney', 'kill', 'killed', 'killing', 'kind', 'kindly', 'king', 'kingdom', 'kit', 'kitchen', 'kiwi', 'knew', 'know', 'knowledge', 'known', 'kong', 'korea', 'kowheori19', 'kumar', 'kwara', 'kwara10', 'kwara11', 'kwara4', 'kwara5', 'ky', 'la', 'lab', 'labconfirmed', 'label', 'labeled', 'laboratory', 'labour', 'lack', 'lady', 'lag', 'lagos', 'lagos33', 'laid', 'lakh', 'landmark', 'language', 'lanka', 'lankan', 'large', 'largely', 'larger', 'largest', 'last', 'late', 'later', 'latest', 'launch', 'launched', 'laureate', 'law', 'lawsuit', 'laying', 'le', 'lead', 'leader', 'leadership', 'leading', 'leaf', 'leaked', 'leapfrogged', 'learn', 'learned', 'learning', 'least', 'leave', 'leaving', 'led', 'left', 'legal', 'legionnaire', 'lemon', 'length', 'let', 'letter', 'let’s', 'level', 'lgas', 'li', 'liaison', 'licking', 'lieber', 'life', 'lifesaving', 'lifethreatening', 'lift', 'lifted', 'light', 'like', 'likely', 'limit', 'limited', 'limiting', 'line', 'link', 'linked', 'linking', 'lion', 'liquid', 'list', 'listed', 'listen', 'little', 'live', 'liver', 'living', 'load', 'local', 'locally', 'located', 'location', 'lock', 'lockdown', 'lockdown.', 'locked', 'log', 'logo', 'lol', 'london', 'londoner', 'long', 'longer', 'longlasting', 'longterm', 'look', 'looked', 'looking', 'lorry', 'los', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'louisiana', 'love', 'loved', 'low', 'lower', 'lowerincome', 'lowest', 'ltc', 'ltd', 'lucknow', 'lucky', 'luke', 'lumped', 'lung', 'lying', 'lysol', 'm', 'ma', 'macedonia', 'macedonian', 'machine', 'madagascan', 'madagascar', 'maddow', 'made', 'madhya', 'madrid', 'maduro', 'magazine', 'magic', 'magne', 'maharashtra', 'mail', 'main', 'mainbhinewschecker', 'maine', 'maintain', 'maintained', 'maintaining', 'maintains', 'major', 'majority', 'make', 'maker', 'making', 'malaria', 'malaysia', 'male', 'mall', 'man', 'manafort', 'manage', 'managed', 'management', 'manager', 'managing', 'manatū', 'mandate', 'mandated', 'mandatory', 'manipulated', 'manipulation', 'manipur', 'manmade', 'mannequin', 'mantri', 'manual', 'manufacture', 'manufactured', 'manufacturer', 'manufacturing', 'many', 'man’s', 'map', 'marapr', 'march', 'margaret’s', 'marijuana', 'marine', 'mark', 'market', 'marriage', 'marseille', 'martin', 'maryland', 'mascot', 'masjid', 'mask', 'mask-wearing', 'masked', 'masking', 'maskwearing', 'mass', 'massachusetts', 'massive', 'mast', 'match', 'material', 'maternity', 'matt', 'matter', 'maulana', 'maximum', 'maxwell', 'may', 'mayan', 'maybe', 'mayor', 'mcconnell', 'mean', 'meaning', 'meant', 'meantime', 'meanwhile', 'measles', 'measure', 'meat', 'meatpacking', 'mechanical', 'mechanism', 'median', 'medic', 'medical', 'medicare', 'medication', 'medicine', 'medium', 'medscape', 'medtwitter', 'meet', 'meeting', 'megha', 'melbourne', 'melinda', 'member', 'membrane', 'men', 'mental', 'mentioned', 'merkel', 'mers', 'message', 'messaging', 'messed', 'messy', 'met', 'metformin', 'method', 'methodological', 'methylxanthine', 'metre', 'metric', 'metro', 'mexico', 'michigan', 'michigan’s', 'microchip', 'mid-may', 'middle', 'middleincome', 'middlemore', 'midnight', 'midst', 'midwest', 'might', 'migrant', 'mike', 'mikovits', 'milan', 'mild', 'mile', 'milestone', 'military', 'milk', 'millennials', 'millennium', 'million', 'min', 'mina', 'mind', 'mine', 'mineral', 'minimise', 'minister', 'ministry', 'minnesota', 'minority', 'minute', 'miq', 'miracle', 'misconstrue', 'misinformation', 'misleading', 'miss', 'missed', 'missing', 'mission', 'mississippi', 'missouri', 'mistake', 'mistreating', 'mitch', 'mitigate', 'mitigation', 'mix', 'mixing', 'mixture', 'mla', 'mm', 'mn', 'mo', 'mob', 'mobile', 'mobility', 'mobilization', 'mobilized', 'mode', 'model', 'modeling', 'modelling', 'moderate', 'moderatehigh', 'modern', 'modi', 'modified', 'moisture', 'molecular', 'molecule', 'moment', 'monday', 'money', 'monitor', 'monitoring', 'monkey', 'montanari', 'month', 'mooted', 'more', 'moreover', 'morning', 'moron', 'mortality', 'mortgage', 'mortuary', 'mosque', 'mosquito', 'most', 'mostly', 'mother', 'mountain', 'mouth', 'mouthwash', 'move', 'moved', 'movement', 'movie', 'moving', 'mp', 'mr', 'mri', 'mrna', 'mrna-1273', 'mrna1273', 'mt', 'much', 'mucus', 'multiple', 'multisystem', 'mumbai', 'municipal', 'murder', 'muscle', 'musculoskeletal', 'music', 'muslim', 'must', 'mustard', 'mutation', 'my', 'myanmar', 'myocarditis', 'mystery', 'n', 'n95', 'nadu', 'nagpur', 'nail', 'namaz', 'name', 'named', 'nanavati', 'nancy', 'nancypelosi', 'narendra', 'nasa', 'nasal', 'nasarawa', 'nasarawa1', 'nasarawa2', 'nasarawa3', 'nasarawa8', 'nashville', 'nation', 'national', 'nationalist', 'nationally', 'nationwide', 'nation’s', 'natural', 'nature', 'navi', 'nba', 'nba’s', 'nc', 'ncdc', 'ncdclabnetwork', 'ncdcrrt', 'ncdcteam', 'ne', 'near', 'nearing', 'nearly', 'nears', 'nebraska', 'necessarily', 'necessary', 'need', 'needed', 'neem', 'neet', 'negative', 'negligence', 'negligent', 'neighbor', 'neighbour', 'neil', 'neither', 'nelson', 'net', 'netherlands', 'network', 'nevada', 'never', 'new', 'newborn', 'newcase', 'newest', 'newly', 'news', 'newschecker', 'newsinphoto', 'newsletter', 'newspaper', 'newsthump', 'newyork', 'next', 'nfl', 'nh', 'nicola', 'niger', 'niger1', 'niger2', 'nigeria', 'nigerian', 'nigerians”', 'nigeria’s', 'night', 'nih', 'nine', 'nipah', 'nitp', 'niño', 'nj', 'no', 'no1', 'nobel', 'nobody', 'noia', 'noncovid', 'none', 'nonessential', 'nonhispanic', 'noninvasive', 'norm', 'normal', 'normally', 'norris', 'north', 'northeast', 'northeastern', 'northern', 'norway', 'nose', 'nostradamus', 'not', 'note', 'noted', 'nothing', 'notice', 'noticed', 'noting', 'notmypresident', 'novel', 'november', 'novotel', 'now', 'now)', 'now”', 'nude', 'number', 'nurse', 'nursing', 'nutrition', 'nv', 'ny', 'nyc', 'nyt', 'nz', 'obama', 'obamacare', 'obesity', 'obey', 'object', 'observation', 'observed', 'observing', 'obtain', 'obvious', 'obviously', 'occur', 'occurred', 'occurring', 'occurs', 'oct', 'october', 'odd', 'odds', 'odisha', 'of', 'off', 'offence', 'offending', 'offense', 'offer', 'offered', 'offering', 'office', 'officer', 'official', 'officially', 'often', 'of…', 'ogun', 'ogun1', 'ogun12', 'ogun13', 'ogun14', 'ogun19', 'ogun2', 'ogun29', 'ogun3', 'ogun4', 'ogun6', 'ogun7', 'ogun9', 'oh', 'ohio', 'oil', 'ok', 'oklahoma', 'old', 'older', 'olive', 'olympics', 'on', 'once', 'ondo', 'ondo1', 'ondo16', 'ondo3', 'ondo5', 'one', 'one’s', 'ongoing', 'onion', 'online', 'only', 'onpoli', 'onset', 'onto', 'open', 'opening', 'operation', 'opportunity', 'optimisation', 'optimistic', 'optimization', 'option', 'or', 'orange', 'order', 'ordered', 'ordering', 'oregon', 'organisation', 'organization', 'organization\\u200b', 'organization\\u2063', 'organized', 'origin', 'original', 'originated', 'os', 'osun', 'osun1', 'osun2', 'osun20', 'osun3', 'other', 'others', 'our', 'out', 'outbreak', 'outcome', 'outdated', 'outdoor', 'outlet', 'outline', 'outside', 'outwards', 'over', 'overall', 'overcome', 'overloaded', 'overly', 'overnight', 'overseas', 'overtakes', 'overwhelmed', 'overwhelming', 'owe', 'own', 'owner', 'oxford', 'oxygen', 'oyo', 'oyo16', 'oyo17', 'oyo18', 'oyo19', 'oyo20', 'oyo25', 'oyo3', 'oyo31', 'oyo41', 'oyo47', 'oyo5', 'oyo6', 'oyo8', 'o…', 'p', 'pa', 'pacific', 'pack', 'package', 'packaging', 'packed', 'packet', 'page', 'paid', 'pain', 'painful', 'pak', 'pakistan', 'pakistani', 'palm', 'panama', 'panda', 'pandemic', 'pandemic.', 'pandemic.�', 'panel', 'panic', 'panicbuying', 'pant', 'papad', 'paper', 'paracetamol', 'paraguayan', 'paralyzed', 'parameter', 'parasite', 'parent', 'parental', 'paris', 'park', 'parliament', 'part', 'partial', 'partially', 'participant', 'participate', 'participating', 'particle', 'particular', 'particularly', 'partner', 'partnership', 'party', 'party’s', 'pas', 'pass', 'passed', 'passenger', 'passengerexpress', 'passing', 'past', 'pasted', 'patanjali', 'patel', 'patent', 'patented', 'path', 'patient', 'patientswho', 'patients’', 'patient’s', 'patil', 'patrick', 'patron', 'pattern', 'paul', 'pauline', 'paulo', 'pause', 'paused', 'paw', 'pay', 'paying', 'payment', 'pcr', 'pcrtest', 'peace', 'peak', 'peaked', 'pediatric', 'pegged', 'pelosi', 'pelted', 'pelting', 'pending', 'pennsylvania', 'penny', 'people', 'peoples’', 'people’s', 'people”', 'pepper', 'per', 'perambra', 'percapita', 'percent', 'percentage', 'performance', 'performed', 'performing', 'perhaps', 'period', 'permanent', 'permanently', 'permission', 'permitted', 'peroxide', 'persistent', 'person', 'personal', 'personality', 'personnel', 'persontoperson', 'perspective', 'pet', 'petal', 'petrol', 'ph', 'pharma', 'pharmaceutical', 'phase', 'philippine', 'phone', 'photo', 'photograph', 'physical', 'physically', 'physician', 'pib', 'pick', 'picked', 'picking', 'picture', 'pie', 'piece', 'pile', 'pin', 'place', 'placed', 'plague', 'plan', 'plandemic', 'planned', 'planning', 'plasma', 'plastic', 'plateau', 'plateau1', 'plateau11', 'plateau18', 'plateaued', 'platform', 'play', 'player', 'please', 'pleased', 'pledge', 'plot', 'pls', 'pm', 'pneumonia', 'podcast', 'point', 'pointing', 'poison', 'pole', 'police', 'policeman', 'policy', 'polio', 'political', 'politician', 'politics', 'politifact', 'poll', 'polling', 'pondicherry', 'pool', 'pooled', 'poor', 'pope', 'popular', 'population', 'portal', 'portfolio', 'portion', 'pose', 'position', 'positive', 'positivity', 'possible', 'post', 'posted', 'poster', 'posting', 'postpone', 'postponed', 'potential', 'potentially', 'powder', 'power', 'powerful', 'ppe', 'ppl', 'practice', 'practicing', 'pradesh', 'pradhan', 'praise', 'praised', 'pray', 'prayer', 'precaution', 'precautionary', 'precipitously', 'predict', 'predicted', 'prediction', 'predicts', 'preexisting', 'pregnant', 'premier', 'premji', 'prepare', 'prepared', 'preparedness', 'prepares', 'preparing', 'prescribe', 'prescribed', 'prescribing', 'prescription', 'present', 'presentation', 'presented', 'presenting', 'presently', 'president', 'presidential', 'press', 'pressure', 'presymptomatic', 'pretty', 'prevalence', 'prevent', 'prevented', 'preventing', 'prevention', 'preventive', 'prevents', 'previous', 'previously', 'price', 'priest', 'primarily', 'primary', 'primate', 'prime', 'prince', 'princess', 'principal', 'prior', 'prioritised', 'priority', 'prison', 'priti', 'privacy', 'private', 'priyanka', 'prize', 'probability', 'probable', 'probably', 'problem', 'procedure', 'process', 'processed', 'procurement', 'produce', 'produced', 'product', 'production', 'prof', 'professional', 'professor', 'profile', 'program', 'progress', 'progression', 'progressive', 'prohibited', 'project', 'projecting', 'projection', 'promise', 'promising', 'prompt', 'proof', 'propaganda', 'proper', 'properly', 'property', 'prophylactic', 'proportion', 'proposed', 'prospect', 'protect', 'protected', 'protecting', 'protection', 'protective', 'protects', 'protein', 'protest', 'protesting', 'protestors', 'protocol', 'proud', 'prove', 'proved', 'proven', 'provide', 'provided', 'provider', 'provides', 'providing', 'province', 'proving', 'ptfcovid19', 'pub', 'public', 'publication', 'publish', 'published', 'pulled', 'pune', 'punishable', 'pupil', 'purchase', 'purchasing', 'purported', 'purportedly', 'purpose', 'push', 'pushed', 'pushing', 'put', 'putin', 'putting', 'pvt', 'p…', 'q', 'qanda', 'qanon', 'qr', 'quality', 'quarantine', 'quarantined', 'quarantining', 'quarter', 'queen', 'queenstown', 'query', 'question', 'queue', 'quick', 'quickly', 'quietly', 'quinine', 'quite', 'quits', 'quote', 'quoted', 'quran', 'r', 'r&ampd', 'r0', 'ra', 'raab', 'race', 'rachael', 'rachel', 'racial', 'racist', 'radcliffe', 'radiation', 'radio', 'rahul', 'rai', 'rail', 'railway', 'raise', 'raised', 'raising', 'rajasthan', 'rajpura', 'rally', 'ram', 'ramadan', 'ramdev', 'ramesh', 'ramp', 'ramped', 'ramping', 'ramu', 'ran', 'range', 'rapid', 'rapidantigentest', 'rapidly', 'rare', 'rasam', 'rash', 'rashid', 'ratan', 'rate', 'rated', 'rate…', 'rather', 'rating', 'ratio', 'raw', 'ray', 'rayner', 'rbi', 're-opening', 'reach', 'reached', 'reaching', 'reactivated', 'reacts', 'read', 'reader', 'readily', 'reading', 'ready', 'real', 'reality', 'realize', 'really', 'realtime', 'reason', 'reassurance', 'reassured', 'rebuild', 'receive', 'received', 'receiving', 'recent', 'recently', 'recession', 'reciting', 'recognition', 'recognize', 'recommend', 'recommendation', 'recommended', 'recommends', 'record', 'recorded', 'recording', 'recover', 'recovered', 'recovering', 'recovery', 'recoveryrate', 'rec…', 'red', 'redeployed', 'redfield', 'reduce', 'reduced', 'reduces', 'reducing', 'reduction', 'reduction\"', 'reef', 'refer', 'reference', 'referred', 'refers', 'reflect', 'reflected', 'reflection', 'reflects', 'refuse', 'refused', 'refusing', 'regarding', 'regardless', 'regime', 'region', 'regional', 'register', 'registered', 'registration', 'registry', 'regret', 'regular', 'regularly', 'regulation', 'reject', 'related', 'relationship', 'relative', 'relatively', 'relaxed', 'release', 'released', 'releasing', 'reliable', 'reliably', 'relief', 'religious', 'relying', 'remain', 'remained', 'remaining', 'remains', 'remdesivir', 'remedy', 'remember', 'reminder', 'removed', 'rent', 'reopen', 'reopened', 'reopening', 'reopenings', 'reopeningsafely', 'reopens', 'repeat', 'repeatedly', 'report', 'reported', 'reportedly', 'reporter', 'reporting', 'report\\u2063', 'represent', 'representative', 'represented', 'representing', 'republican', 'request', 'requested', 'requesting', 'require', 'required', 'requirement', 'requires', 'requiring', 'rescue', 'research', 'researcher', 'residence', 'resident', 'resigned', 'resolution', 'resorting', 'resource', 'respect', 'respectively', 'respirator', 'respiratory', 'respond', 'responder', 'responding', 'response', 'responsibility', 'responsible', 'rest', 'restart', 'restaurant', 'restriction', 'restrictive', 'result', 'resulted', 'resume', 'resurgence', 'retail', 'retested', 'return', 'returned', 'returnees', 'returning', 'reveal', 'revealed', 'revealing', 'reveals', 'review', 'reviewed', 'revised', 'rice', 'richard', 'rid', 'right', 'rio', 'rise', 'risen', 'rising', 'risk', 'risking', 'risky', 'river', 'river3', 'rivers1', 'rivers12', 'rivers2', 'rivers3', 'rna', 'rnc2020', 'road', 'rob', 'robert', 'roche', 'rodrigo', 'role', 'rolled', 'rolling', 'rollout', 'ron', 'ronaldo', 'room', 'rose', 'roskill', 'rotorua', 'roughly', 'round', 'routine', 'row', 'rt', 'rtpcr', 'rule', 'ruled', 'ruling', 'rumor', 'rumour', 'run', 'running', 'rupee', 'rural', 'rushed', 'russia', 'russian', 'sacrifice', 'sadiq', 'sadly', 'safe', 'safely', 'safety', 'sage', 'said', 'saint', 'salad', 'salary', 'sale', 'saliva', 'salt', 'same', 'sample', 'san', 'sander', 'sanitizer', 'sanitizers', 'sarah', 'sars', 'sars-cov-2', 'sarscov2', 'sat', 'saturday', 'saudi', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'sc', 'scale', 'scaled', 'scaling', 'scan', 'scenario', 'schedule', 'scheme', 'school', 'science', 'scientific', 'scientifically', 'scientist', 'score', 'scotland', 'screen', 'screening', 'screenshot', 'sea', 'sealed', 'search', 'season', 'seasonal', 'seat', 'seated', 'second', 'secondary', 'secondhighest', 'secret', 'secretary', 'secretly', 'section', 'sector', 'security', 'see', 'seed', 'seeing', 'seek', 'seeking', 'seem', 'seems', 'seen', 'segment', 'self', 'self-isolate', 'self-isolation', 'selfchecker', 'selfisolate', 'selfisolating', 'selfisolation', 'selfquarantine', 'selling', 'senate', 'senator', 'send', 'sending', 'senegal', 'senior', 'sense', 'sent', 'sep', 'separate', 'separated', 'sept', 'september', 'series', 'serious', 'seriously', 'serum', 'serve', 'server', 'service', 'set', 'setting', 'seven', 'sevenday', 'several', 'severe', 'severely', 'severity', 'sex', 'shadow', 'shah', 'shall', 'shape', 'share', 'shared', 'sharepic', 'sharing', 'sharp', 'shave', 'shaving', 'she', 'sheep', 'sheet', 'shenzhen', 'shield', 'shift', 'ship', 'shit', 'shiva', 'shooting', 'shop', 'shopper', 'shopping', 'shore', 'short', 'shortage', 'shortly', 'shortness', 'shot', 'should', 'shouldnt', 'show', 'showed', 'showing', 'shown', 'shrinking', 'shut', 'shutdown', 'shutting', 'sick', 'sickness', 'side', 'sign', 'signal', 'signed', 'significant', 'significantly', 'signing', 'silver', 'similar', 'simple', 'simply', 'since', 'singapore', 'singh', 'singing', 'single', 'singleday', 'sir', 'sister', 'site', 'sitting', 'situation', 'six', 'sixth', 'skill', 'skilled', 'skin', 'sky', 'slack', 'slaughter', 'sleep', 'slightly', 'slow', 'slowed', 'slowing', 'slowly', 'slowthespread', 'small', 'smaller', 'smoke', 'smoking', 'sneeze', 'sneezing', 'so', 'soap', 'social', 'socialdistancing', 'society', 'soda', 'sodium', 'sofi2020', 'sokoto', 'sokoto1', 'sokoto2', 'sold', 'solid', 'solidarity', 'solution', 'solve', 'some', 'somehow', 'someone', 'something', 'sometimes', 'son', 'soon', 'sooner', 'sop', 'sore', 'soros', 'sort', 'sound', 'source', 'south', 'southeast', 'southern', 'space', 'spain', 'spanish', 'speak', 'speaker', 'speaking', 'special', 'specialist', 'specific', 'specimen', 'speed', 'speedy', 'spend', 'spent', 'spike', 'spit', 'spitting', 'spoke', 'spoken', 'spokesman', 'sport', 'spot', 'spray', 'spread', 'spreading', 'spring', 'sri', 'st', 'stable', 'stacked', 'stadium', 'staff', 'stage', 'stand', 'standard', 'standing', 'stanford', 'star', 'starmer', 'start', 'started', 'starting', 'state', 'stated', 'statement', 'states/uts', 'statesuts', 'statewise', 'state’s', 'stating', 'station', 'statistic', 'stats', 'status', 'stay', 'stayathome', 'stayhomestaysafe', 'staying', 'staysafe', 'std', 'steadily', 'steady', 'steam', 'steep', 'step', 'steroid', 'stick', 'stigma', 'still', 'stimulus', 'stock', 'stomach', 'stone', 'stop', 'stopped', 'stopping', 'store', 'storm', 'story', 'straight', 'strain', 'stranded', 'strategic', 'strategy', 'street', 'strengthen', 'strengthening', 'stress', 'stressful', 'strict', 'strong', 'stronger', 'struggle', 'struggling', 'student', 'study', 'stuff', 'stupid', 'sturgeon', 'subject', 'submarine', 'substance', 'substantial', 'substantially', 'success', 'successful', 'successfully', 'successive', 'such', 'sudden', 'suffer', 'suffering', 'sufficient', 'suggest', 'suggested', 'suggesting', 'suggestion', 'suggests', 'suicide', 'sum', 'summary', 'summer', 'sun', 'sunday', 'sunlight', 'super', 'supermarket', 'supplement', 'supply', 'support', 'supported', 'supporter', 'supporting', 'supposed', 'supposedly', 'suppress', 'suppressed', 'supreme', 'suraksha', 'surat', 'sure', 'surface', 'surge', 'surgery', 'surge”', 'surgical', 'surpass', 'surpassed', 'surprised', 'surveillance', 'survey', 'survival', 'survive', 'survived', 'suspect', 'suspected', 'suspended', 'sustained', 'swab', 'sweden', 'sweet', 'swimming', 'swine', 'switzerland', 'symptom', 'symptomatic', 'syndrome', 'system', 'systematic', 'são', 'table', 'tablet', 'tablighi', 'tackle', 'tag', 'taiwan', 'tak', 'take', 'taken', 'takeresponsibility', 'taking', 'talk', 'talked', 'talking', 'tally', 'tamil', 'tamilnadu', 'tank', 'taraba3', 'target', 'task', 'taste', 'tasuku', 'tata', 'tax', 'tb', 'tea', 'teacher', 'teaching', 'team', 'tech', 'technology', 'teen', 'telangana', 'telemedicine', 'tell', 'telling', 'temperature', 'temple', 'temporary', 'ten', 'tennessee', 'term', 'territory', 'test', 'tested', 'testing', 'texas', 'text', 'thailand', 'than', 'thane', 'thank', 'thanks', 'that', 'thats', 'that’s', 'that”', 'the', 'their', 'then', 'theory', 'therapeutic', 'therapy', 'there', 'therefore', 'there’s', 'thermal', 'these', 'they', 'theyre', 'they’re', 'the…', 'thing', 'think', 'thinking', 'third', 'this', 'those', 'though', 'thought', 'thousand', 'thread', 'threat', 'threatens', 'three', 'throat', 'thrombosis', 'through', 'throughout', 'throwing', 'thrown', 'thursday', 'thus', 'tick', 'ticked', 'tiger', 'tighter', 'till', 'time', 'timeline', 'timely', 'time”', 'tip', 'tipping', 'to', 'today', 'today\\u200b', 'today’s', 'together', 'toilet', 'tokoroa', 'told', 'toll', 'tom', 'tomorrow', 'tonight', 'took', 'tool', 'toolkit', 'top', 'topic', 'total', 'totally', 'totaltestresults', 'tota…', 'touch', 'touched', 'touching', 'tough', 'touted', 'towards', 'tower', 'town', 'trace', 'traced', 'tracer', 'tracing', 'track', 'tracked', 'tracker', 'tracking', 'trade', 'traditional', 'train', 'trained', 'training', 'transferred', 'transmission', 'transmit', 'transmitted', 'transmitting', 'transparency', 'transport', 'transportation', 'travel', 'traveler', 'travelled', 'traveller', 'travelling', 'treat', 'treated', 'treating', 'treatment', 'trend', 'trending', 'trial', 'tribal', 'trick', 'tried', 'trillion', 'trip', 'trouble', 'truck', 'trudeaus', 'true', 'truenat', 'truly', 'trump', 'trump’s', 'trust', 'truth', 'try', 'trying', 'tshirt', 'tsunami', 'tuberculosis', 'tuesday', 'tune', 'tunisian', 'turkey', 'turn', 'turned', 'turning', 'tv', 'tweet', 'tweeted', 'twenty', 'twice', 'twitter', 'two', 'tx', 'type', 't…', 'u', 'uganda', 'uighur', 'uk', 'ultimately', 'umbrella', 'un', 'un75', 'unable', 'uncertainty', 'unchanged', 'unclear', 'uncomfortable', 'under', 'undergo', 'underlying', 'understand', 'understanding', 'understands', 'underway', 'unemployed', 'unemployment', 'unfortunately', 'unga', 'unicef', 'union', 'unique', 'unit', 'united', 'universal', 'university', 'unknown', 'unless', 'unlike', 'unlikely', 'unlock4', 'unprecedented', 'unwell', 'up', 'update', 'updated', 'update\\u200b', 'updating', 'upgraded', 'upon', 'upper', 'upsurge', 'upto', 'urge', 'urged', 'urgent', 'urgently', 'urging', 'urine', 'us', 'usa', 'usage', 'use', 'used', 'useful', 'useless', 'user', 'using', 'usual', 'usually', 'ut', 'utah', 'uttar', 'uttarpradesh', 'uv', 'v', 'vaccinated', 'vaccination', 'vaccine', 'vaccineswork', 'validated', 'vallance', 'value', 'van', 'varies', 'various', 'vast', 'vati', 'vatican', 'vegetable', 'vegetarian', 'vehicle', 'ventilation', 'ventilator', 'verified', 'vermont', 'verse', 'version', 'via', 'vice', 'victim', 'victoria', 'victorian', 'video', 'view', 'viewed', 'vinegar', 'violated', 'violating', 'violation', 'viral', 'virginia', 'virologist', 'virology', 'virtual', 'virus', 'virus.', 'virus.�', 'virus”', 'visa', 'visit', 'visited', 'visiting', 'vital', 'vitamin', 'vk', 'vladimir', 'voice', 'volleyball', 'volume', 'voluntary', 'volunteer', 'vote', 'voting', 'vp', 'vte', 'vulnerable', 'w', 'wa', 'waikato', 'wait', 'waitakere', 'waiting', 'wake', 'wale', 'walking', 'wall', 'want', 'wanted', 'war', 'ward', 'warm', 'warn', 'warned', 'warning', 'warns', 'warrior', 'wash', 'washing', 'washington', 'wasnt', 'watch', 'watching', 'water', 'wave', 'way', 'we', 'weak', 'weapon', 'wear', 'wearamask', 'wearing', 'weather', 'webinar', 'website', 'wed', 'wedding', 'wednesday', 'weed', 'week', 'weekend', 'weekly', 'well', 'wellbeing', 'wellington', 'wenliang', 'went', 'were', 'west', 'western', 'wet', 'weve', 'we‘ve', 'we’ll', 'we’re', 'we’ve', 'what', 'whatever', 'whats', 'whatsapp', 'what’s', 'when', 'where', 'whereas', 'whether', 'which', 'while', 'whistleblower', 'white', 'whitehouse', 'whitty', 'who', 'whoimpact', 'whole', 'whose', 'who’s', 'why', 'wide', 'widely', 'widespread', 'wife', 'wildfire', 'will', 'william', 'window', 'winning', 'winter', 'wipe', 'wiped', 'wisconsin', 'wise', 'with', 'within', 'without', 'witness', 'woman', 'wonder', 'wonderful', 'wondering', 'wont', 'won’t', 'word', 'wore', 'work', 'worked', 'worker', 'working', 'workplace', 'world', 'worldmaskweek', 'worldwide', 'world’s', 'world”', 'worried', 'worse', 'worship', 'worst', 'worth', 'would', 'wouldnt', 'writing', 'written', 'wrong', 'wrongly', 'wrote', 'wuhan', 'wwn', 'xi', 'yan', 'yeah', 'year', 'yemen', 'yes', 'yesterday', 'yet', 'yobe1', 'yobe2', 'yobe3', 'yoga', 'yojana', 'york', 'york’s', 'you', 'youll', 'young', 'younger', 'your', 'youre', 'youth', 'youtube', 'you’re', 'you’ve', 'zealand', 'zealander', 'zealand’s', 'zero', 'zika', 'zinc', 'zone', '|', '£10000', '£500', '\\u200b', '\\u200b\\u2063', '\\u200b\\u2063\\u2063', '–', '—', '“a', '“all', '“as', '“big', '“every', '“i', '“if', '“in', '“only”', '“seamless”', '“the', '“this', '“totally', '“we', '“we’re', '•', '…', '\\u2063', '\\u2063\\u2063', '\\u2063\\u2063\\u2063\\u2063', '▪️', '▶️1.60', '◾', '✅', '✅indias', '✅more', '✅observe', '✅over', '✅wash', '❗', '➡', '➡️active', '➡️confirmed', '➡️deaths', '➡️interventions', '➡️recovered', '➡️states', '➡️total', '⠀', '🌍', '🏫', '👇', '👉', '👉india', '👉the', '👍', '📍', '📍covid19', '📍increasing', '📍statewise', '📍steady', '📍total', '📢#coronavirusupdates', '📱', '📺', '🔰full', '🔰read', '🔰report', '🔴', '😷', '🙌']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform"
      ],
      "metadata": {
        "id": "l7IRYu7XtBRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words = vectorizer_stop_words_stemmed.transform(X_train[\"tweet\"])\n",
        "bag_of_words = pd.DataFrame(bag_of_words.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())"
      ],
      "metadata": {
        "id": "laKfx_8Fx4Nb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words.shape[1]"
      ],
      "metadata": {
        "id": "D68kVvh8wXfW",
        "outputId": "f304cc20-09bc-460d-81f2-4785d28c61c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal"
      ],
      "metadata": {
        "id": "ilGGPtUT0xFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "metadata": {
        "id": "e8pMorDV1DI9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer='Adam'\n",
        "loss='binary_crossentropy'\n",
        "metric='accuracy'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_shape=(bag_of_words.shape[1],)))\n",
        "model.add(Activation(LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(30, use_bias=True))\n",
        "model.add(Activation(LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(1, use_bias=True))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss=loss, optimizer=adam_optimizer, metrics=[metric])"
      ],
      "metadata": {
        "id": "lW8SiL-t01M0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_array = np.asarray(bag_of_words)\n",
        "Y_train_array = np.asarray(Y_train)\n",
        "\n",
        "training = model.fit(X_train_array, Y_train_array, epochs=200, batch_size=100, validation_split=0.2)"
      ],
      "metadata": {
        "id": "gY0iDNOLDG88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "model.save(\"basic_model\")\n",
        "saved_model = keras.models.load_model(\"basic_model\")"
      ],
      "metadata": {
        "id": "rCRKAKT9oRpN",
        "outputId": "2114b9c2-f322-4756-f894-210e97a8b5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as leaky_re_lu_2_layer_call_fn, leaky_re_lu_2_layer_call_and_return_conditional_losses, leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag = vectorizer_stop_words_stemmed.transform(X_validation[\"tweet\"])\n",
        "X_Validation_Bag_df = pd.DataFrame(X_Validation_Bag.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())"
      ],
      "metadata": {
        "id": "40thu1nco6Nu",
        "outputId": "341070d4-3892-4097-b056-153e3502d513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag_df_array = np.asarray(X_Validation_Bag_df)\n",
        "Y_Validation_Predict = saved_model.predict(X_Validation_Bag_df_array)"
      ],
      "metadata": {
        "id": "0Fy5rxxbnw3U",
        "outputId": "a7baa94a-fa63-47fc-d0de-a964d60bf605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Validation_Predict"
      ],
      "metadata": {
        "id": "YpPOc0IL5Wyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformPrediction(df, predNumber, predLabel):\n",
        "  copy = df.copy()\n",
        "  for i in range(len(copy)):\n",
        "    if copy[i][0] > 0.5:\n",
        "      predNumber.append([1])\n",
        "      predLabel.append([\"real\"])\n",
        "    else:\n",
        "      predNumber.append([0])\n",
        "      predLabel.append([\"fake\"])\n"
      ],
      "metadata": {
        "id": "EWu5_-xv-smt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predValidationNumbers = []\n",
        "predValidationLabels = []\n",
        "transformPrediction(Y_Validation_Predict, predValidationNumbers, predValidationLabels)"
      ],
      "metadata": {
        "id": "i1hDHEULlcDX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationNumbers = []\n",
        "validationLabels = []\n",
        "copy = np.asarray(Y_validation).copy()\n",
        "for i in range(len(copy)):\n",
        "  if copy[i] > 0.5:\n",
        "    validationNumbers.append([1])\n",
        "    validationLabels.append([\"real\"])\n",
        "  else:\n",
        "    validationNumbers.append([0])\n",
        "    validationLabels.append([\"fake\"])"
      ],
      "metadata": {
        "id": "ODiTBndqlzWX"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(Y_validation)"
      ],
      "metadata": {
        "id": "hnmR9lfkk3J1",
        "outputId": "525146fd-96a7-4f5d-a6b4-2db2564d2073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(predValidationLabels,validationLabels))"
      ],
      "metadata": {
        "id": "AhJZ1LxVaC0D",
        "outputId": "30a42b82-641c-4219-e99b-17f30e59ccc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5073580939032937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K fold"
      ],
      "metadata": {
        "id": "lsp7hcI0Xlx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "WBbrhQ1qayX_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "k = 5\n",
        "\n",
        "def k_folds(X, y, k):\n",
        "  assert(len(X) == len(y))\n",
        "  folds_X = []\n",
        "  folds_y = []\n",
        "  initial_pos = 0\n",
        "\n",
        "  for i in range(k):\n",
        "    to_pos = min(math.ceil(len(X)/k)*(i+1), len(X))\n",
        "    \n",
        "    x_fold = X[initial_pos:to_pos]\n",
        "    y_fold = y[initial_pos:to_pos]\n",
        "\n",
        "    folds_X.append(x_fold)\n",
        "    folds_y.append(y_fold)\n",
        "    initial_pos = to_pos\n",
        "\n",
        "  return folds_X, folds_y"
      ],
      "metadata": {
        "id": "Mf9ISG6OXlV_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_to_eval, Y_to_eval):\n",
        "    Y_Prediction = model.predict(np.asarray(X_to_eval))\n",
        "    numbers = []\n",
        "    prediction_labels = []\n",
        "    transformPrediction(Y_Prediction, numbers, prediction_labels)\n",
        "\n",
        "    validationLabels = []\n",
        "    copy = np.asarray(Y_to_eval).copy()\n",
        "    for i in range(len(copy)):\n",
        "      if copy[i] > 0.5:\n",
        "        validationLabels.append([\"real\"])\n",
        "      else:\n",
        "        validationLabels.append([\"fake\"])\n",
        "\n",
        "    return accuracy_score(prediction_labels, validationLabels)"
      ],
      "metadata": {
        "id": "DAADQdFEYKtZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_val(folds_X, folds_y, model):\n",
        "  assert(len(folds_X) == len(folds_y))\n",
        "  X_to_train = []\n",
        "  y_to_train = []\n",
        "  X_to_eval = 0\n",
        "  y_to_eval = 0\n",
        "  scores = []\n",
        "  for i in range(len(folds_X)):\n",
        "    X_to_train = []\n",
        "    y_to_train = []\n",
        "    for j in range(len(folds_X)):\n",
        "      if  i == j:\n",
        "        X_to_eval = folds_X[i]\n",
        "        y_to_eval = folds_y[i]\n",
        "      else:\n",
        "        X_to_train.append(folds_X[j])\n",
        "        y_to_train.append(folds_y[j])\n",
        "    \n",
        "    X_train = np.concatenate(X_to_train)\n",
        "    y_train = np.concatenate(y_to_train)\n",
        "    model.fit(X_train,y_train, epochs=200, batch_size=100, validation_split=0.2)\n",
        "    score = evaluate(model, X_to_eval, y_to_eval)\n",
        "    scores.append(score)\n",
        "  return np.mean(np.array(scores)), scores"
      ],
      "metadata": {
        "id": "iWHnyEvRY_5_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds_X, folds_y = k_folds(np.asarray(bag_of_words), np.asarray(Y_train), 5)\n"
      ],
      "metadata": {
        "id": "iYJyO491ZBgK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean, k_fold_result_arr = k_fold_cross_val(folds_X, folds_y, model)"
      ],
      "metadata": {
        "id": "1lH1Uz4HbMln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean"
      ],
      "metadata": {
        "id": "BHDI7I_deLIG",
        "outputId": "39fd0dda-f029-4ca7-91ce-d440d382bae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9580845124177051"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_arr"
      ],
      "metadata": {
        "id": "FOadql0keOYu",
        "outputId": "21fcb73d-579d-45d9-df35-bd1302fc6d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9010507880910683,\n",
              " 0.978108581436077,\n",
              " 0.9956217162872154,\n",
              " 1.0,\n",
              " 0.9156414762741653]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "dQyZTFSjXjir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['id'].astype('str')\n",
        "test['tweet'].astype('str')\n",
        "\n",
        "test_bag = vectorizer_stop_words_stemmed.transform(test[\"tweet\"])\n",
        "test_bag = pd.DataFrame(test_bag.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())\n",
        "\n",
        "test_bag_array = np.asarray(test_bag)\n",
        "test_prediction = saved_model.predict(test_bag_array)\n",
        "\n",
        "copy = test_prediction.copy()\n",
        "predNumber = [];\n",
        "predLabel = [];\n",
        "for i in range(len(copy)):\n",
        "  if copy[i][0] > 0.5:\n",
        "    predNumber.append([1])\n",
        "    predLabel.append([\"real\"])\n",
        "  else:\n",
        "    predNumber.append([0])\n",
        "    predLabel.append([\"fake\"])\n",
        "\n",
        "prediction = pd.DataFrame(predLabel, columns=['label'])\n",
        "prediction.index += 1\n",
        "prediction = prediction.to_csv('prediction.csv')"
      ],
      "metadata": {
        "id": "hZMa_5ZcWMWo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "5250ae5e-2427-4fcf-852b-ec81e99d6369"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-de8a2edce618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_bag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer_stop_words_stemmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_bag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer_stop_words_stemmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-7e54b6a479ca>\u001b[0m in \u001b[0;36mnew_analyzer\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mdoc_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mdoc_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_Punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mdoc_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_Stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-7e54b6a479ca>\u001b[0m in \u001b[0;36mremove_Stopwords\u001b[0;34m(doc_split)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0mdoc_with_Stopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     19\u001b[0m         return [\n\u001b[1;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, encoding, errors)\u001b[0m\n\u001b[1;32m   1035\u001b[0m            beginning of ``linebuffer`` (which is required by ``tell()``).\"\"\"\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_bom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         \"\"\"The length of the byte order marker at the beginning of\n\u001b[1;32m   1039\u001b[0m            the stream (or None for no byte order marker).\"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_check_bom\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0;31m# Check for each possible BOM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbom_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnew_encoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('prediction.csv')"
      ],
      "metadata": {
        "id": "odAqKelbXH36",
        "outputId": "00458ec1-e224-4c76-cd59-02824c9cced5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d945c047-a51a-4677-9dcd-38afe0cc6a0d\", \"prediction.csv\", 20300)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
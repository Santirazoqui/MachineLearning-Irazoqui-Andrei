{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "auJ2yClw527_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats.mstats import winsorize\n",
        "from google.colab import drive, files\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CountVectorizer"
      ],
      "metadata": {
        "id": "MNSO-eRR0uXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Stop words, lematizing, stemming"
      ],
      "metadata": {
        "id": "k_IJ9w4nhXfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar datos y dividir dataset"
      ],
      "metadata": {
        "id": "rBFpCmouf3Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.random import set_seed\n",
        "set_seed(234730)"
      ],
      "metadata": {
        "id": "iRskxHDSvIB1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test_without_label.csv')"
      ],
      "metadata": {
        "id": "EDu6L8kKvMio"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['id'] = train['id'].astype(str)\n",
        "train['tweet'] = train['tweet'].astype(str)\n",
        "train['label'] = train['label'].astype(str)"
      ],
      "metadata": {
        "id": "8bBGRjnTxdsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['id'], axis=1)\n",
        "train.set_index(\"id\", inplace = True)"
      ],
      "metadata": {
        "id": "XwO2hMspxjLi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# parseo de category\n",
        "train[['label']] = train[['label']].apply(lambda col: label_encoder.fit_transform(col))"
      ],
      "metadata": {
        "id": "yI7GxIR9W6xB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
        "    train.drop('label', axis=1),\n",
        "    train['label'],\n",
        "    test_size=(1.0/3), random_state=42)"
      ],
      "metadata": {
        "id": "FXppDGXJxsy2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop words y lemmatize"
      ],
      "metadata": {
        "id": "nEVhjrJqf7Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "#analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_loc = '/root/nltk_data/corpora/wordnet.zip'\n",
        "with ZipFile(file_loc, 'r') as z:\n",
        "  z.extractall('/root/nltk_data/corpora/')"
      ],
      "metadata": {
        "id": "q_vBq9se2qMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f6b2bf-32b3-40e5-ddb9-597cfa10c6f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopwords, lemmatize, punctuacion\n",
        "Para este experimento, voy a borrar los links"
      ],
      "metadata": {
        "id": "fv52mEwudEkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#All_punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "All_punct = '''!()-[]{};:'\"\\,<>./?%^&*_~'''\n",
        "#CountVectorizer con stopwords de Natural Language Toolkit\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def is_Not_Link(word):\n",
        "  return word[0:4] != \"http\"\n",
        "\n",
        "def remove_Punctuation(doc_split):\n",
        "  i = 0;\n",
        "  while i < len(doc_split):\n",
        "    word = doc_split[i];\n",
        "    if is_Not_Link(word):\n",
        "      for elements in word:\n",
        "        if elements in All_punct:\n",
        "          doc_split[i] = word.replace(elements, \"\")\n",
        "    else:\n",
        "      del doc_split[i]\n",
        "    i = i + 1\n",
        "  return doc_split\n",
        "\n",
        "def remove_Stopwords(doc_split):\n",
        "  doc_with_Stopwords = doc_split.copy();\n",
        "  for i in range(len(doc_split)):\n",
        "    word = doc_split[i];\n",
        "    if word in nltk.corpus.stopwords.words('english'):\n",
        "      doc_with_Stopwords.remove(word);\n",
        "\n",
        "  return doc_with_Stopwords\n",
        "\n",
        "def new_analyzer(doc):\n",
        "  doc_split = doc.split();\n",
        "  doc_split = remove_Punctuation(doc_split);\n",
        "  doc_split = remove_Stopwords(doc_split);\n",
        "  return (Lemmatizer.lemmatize(w.lower()) for w in doc_split);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV02dxaTsbyP",
        "outputId": "ddc5bc9f-921d-4a9e-8a48-830c87babe25"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk.corpus.stopwords.words('english'))"
      ],
      "metadata": {
        "id": "KRFmi9X46sE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit"
      ],
      "metadata": {
        "id": "1Sqi2438Ibd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_stop_words_stemmed = CountVectorizer(analyzer=new_analyzer, max_features=5000)\n",
        "bag_of_words = vectorizer_stop_words_stemmed.fit(X_train[\"tweet\"])\n",
        "\n",
        "print(bag_of_words.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aBmH9uJtACD",
        "outputId": "6a812f1d-4cef-49e5-8529-ec119f156e12"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '#', '#2020presidentialelection', '#america', '#asymptomatic', '#auspol', '#bacteria', '#beer', '#bihar', '#breakfast', '#cdnpoli', '#china', '#corona', '#coronacheck', '#coronaoutbreak', '#coronaupdates', '#coronaupdatesindia', '#coronavirus', '#coronavirusfacts', '#coronavirusindia', '#coronavirusoutbreak', '#coronaviruspandemic', '#coronavirusupdate', '#coronavirusupdates', '#coronawatch', '#covid', '#covid-19', '#covid19', '#covid19associated', '#covid19india', '#covid19like', '#covid19nigeria', '#covid19pakistan', '#covid19science', '#covid2019', '#covid_19', '#covid__19', '#covidindiaseva', '#covidupdates', '#covidview', '#covidー19', '#datoscoronavirus', '#death', '#delhi', '#disease', '#donaldtrump', '#dranthonyfauci', '#dyk', '#facemasks', '#factcheck', '#fakenews', '#faq', '#fatalityrate', '#flu', '#food', '#foxnews', '#fullyimmunizeeverychild', '#gujarat', '#haryana', '#hcps', '#hcq', '#health', '#healthcare', '#healthworkers', '#hiv', '#hollywood', '#homequarantine', '#hydroxychloroquine', '#icmrfightscovid19', '#immunity', '#immunizationforall', '#india', '#indiafightscorona', '#indiafightscovid19', '#indiawillwin', '#institutionalquarantine', '#josephbiden', '#kayburley', '#kerala', '#laborday', '#life', '#lockdown', '#lucknow', '#maharashtra', '#mainbhinewschecker', '#malaria', '#marijuana', '#mask', '#masks', '#media', '#michigan', '#mrna', '#n95', '#nashville', '#ncdcrrt', '#newschecker', '#newyork', '#nigeria', '#novel', '#nyc', '#onpoli', '#pandemic', '#pmqs', '#ppe', '#ptfcovid19', '#qanda', '#quarantine', '#recoveryrate', '#reopeningsafely', '#rnc2020', '#sepsis', '#slowthespread', '#socialdistancing', '#sofi2020', '#stayathome', '#stayhome', '#stayhomestaysafe', '#staysafe', '#stopthespread', '#swasthabharat', '#symptomatic', '#takeresponsibility', '#tamilnadu', '#tb', '#telangana', '#thailand🇹🇭', '#thankshealthheroes', '#tigers', '#time', '#un75', '#unemployment', '#unga', '#unlock4', '#usa', '#uttarpradesh', '#vaccine', '#vaccineswork', '#vermont', '#virus', '#wearamask', '#whatsapp', '#whitehouse', '#who', '#whoimpact', '#wildfire', '#worldmaskweek', '#wuhan', '$100', '$50', '&amp', '&gt&gt&gt', '(#pmsby', '(1.6%', '(1.7%', '(1.8%', '(1/2', '(2/4', '(21.9%', '(3/4', '(4025079', '(76.3%👍', '(77.8%👍', '(a', '(act', '(asymptomatic)', '(barcelona', '(cfr', '(cont.', '(continued', '(coronavirus', '(covid-19', '(covid-19)', '(dcgi', '(eg', '(ie', '(india', '(pmjjby', '(ppe)', '(tpm', '(who', '+', '+1', '.@mohfwindia', '0', '01', '02', '03', '04', '05', '06', '079', '08', '0800', '085', '0900', '0930', '0950', '1', '1%', '10', '10%', '10.5l', '100', '100%', '100+', '1000', '1000+', '10000', '100000', '100000+', '10001100000', '1000190000', '100k', '101', '102', '1040', '105', '1054', '107', '10k', '10pm', '10th', '11', '1100', '110000', '111', '1130', '114', '115', '115000', '1154', '1155pm', '116', '117', '1170', '1176', '118', '1184', '119', '11th', '12', '120', '120000', '1206', '1217', '1219', '123', '128', '12th', '13', '130', '130000', '134', '13th', '14', '140', '145', '1455', '1481', '14day', '14th', '15', '150', '1500', '15000', '150000', '15001100000', '1504', '1529', '153504', '1551', '155k', '156', '158', '15th', '16', '160', '16151', '167', '16th', '17', '170', '174', '176', '179', '17th', '18', '18th', '19', '190', '19000', '195', '19th', '1m', '1ondo', '1plateau', '1st', '1…', '1⃣', '2', '20', '20%', '200', '2000', '20000', '200000', '2001', '2005', '2008', '2009', '200k', '2010', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2020👇', '2021', '2022', '204', '20k', '21', '21000', '214', '2159', '21k', '22', '2200', '22nd', '23', '232', '233', '23k', '24', '2404585', '242', '247', '24th', '25', '25000', '25th', '26', '2621', '26th', '27', '2700', '276', '27th', '28', '288', '28k', '28th', '29', '299', '29k', '29th', '2bauchi', '2gombe', '2m', '2nd', '2pm', '3', '30', '300', '3000', '30000', '300k', '30th', '31', '31k', '31st', '32', '323', '33', '34', '35', '350', '35k', '36', '37', '38', '385', '38k', '39', '3bauchi', '3borno', '3rd', '4', '40', '400', '4000', '400000', '41', '42', '42k', '43', '4322', '43k', '44', '4422', '44k', '45', '47', '47k', '48', '481', '49', '49000', '4th', '4x', '5', '50', '500', '5000', '50000', '500000', '501', '50k', '51', '52', '53', '54', '55', '55000', '56', '56k', '57', '57k', '58', '59', '5g', '5th', '5x', '6', '60', '600', '6000', '60000', '61', '62', '63', '64', '65', '65+', '65k', '66', '67', '675', '68', '69', '6th', '7', '7.5', '70', '70k', '7103', '72', '73', '74', '75', '76', '77', '78', '7day', '7th', '8', '80', '80%', '800', '8000', '81', '83', '8316', '85', '86', '87', '89', '8am', '8th', '9', '90', '900', '90000+', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9th', '=', '??', '???covid19', '@aajtak', '@aamaadmiparty', '@africacdc', '@airnewsalerts', '@alexismadrigal', '@ani', '@arvindkejriwal', '@ashwinikchoubey', '@biharhealthdept', '@boomlivein', '@butchthorne', '@cdc_hivaids', '@cdcdirector', '@cdcemergency', '@cdcgov', '@cdcmmwr', '@cdctravel', '@chikwei', '@cmoguj', '@cmomaharashtra', '@cnn', '@conservvoice', '@couchmaria', '@covid19tracking', '@covidindiaseva', '@covidnewsbymib', '@csogok', '@ddnewslive', '@dgpgujarat', '@dreoehanire', '@drharshvardhan', '@drhvoffice', '@drjohnwhyte', '@drtedros', '@factchecknet', '@fmohnigeria', '@followlasg', '@gavi', '@geraintmeysydd', '@govrondesantis', '@harvardgh', '@hhsgov', '@hmoindia', '@icmrdelhi', '@imperialcollege', '@julie34479', '@matthancock', '@mbuhari', '@minhealthnz', '@mohfw_india', '@mohfwindia', '@mygovindia', '@narendramodi', '@nature', '@nih', '@niosh', '@nitiaayog', '@normanbrennan', '@nsitharaman', '@ntanewsnow', '@nytimes', '@peterwa97559477', '@pib_india', '@pibindia', '@pjpaton', '@pmoindia', '@prakashjavdekar', '@profbhargava', '@ptfcovid19', '@ptinews', '@realdonaldtrump', '@riccigeri', '@smileygirl19683', '@statedept', '@surgeon_general', '@theatlantic', '@thelancet', '@tony80554056', '@vmaledew', '@webmd', '@whatsapp', '@who', '@whoafro', '@whos', '@yayitsrob', 'a', 'a&ampe', 'aaj', 'aamir', 'abbott', 'abia', 'abia1', 'abia2', 'abia6', 'abia9', 'ability', 'able', 'abortion', 'about', 'absolute', 'abuja', 'acc', 'accelerate', 'accelerating', 'accelerator', 'accept', 'accepted', 'access', 'accidentally', 'according', 'account', 'accounting', 'accurate', 'accused', 'achieve', 'achievement', 'achieves', 'acquired', 'across', 'act', 'actaccelerator', 'acting', 'action', 'activated', 'active', 'actively', 'activist', 'activity', 'actor', 'actress', 'actual', 'actually', 'acute', 'ad', 'adamawa1', 'add', 'added', 'adding', 'addition', 'additional', 'address', 'adhere', 'adjust', 'adjustment', 'administration', 'administrator', 'admins', 'admission', 'admit', 'admits', 'admitted', 'adult', 'advance', 'advantage', 'advice', 'advise', 'advised', 'adviser', 'advises', 'advising', 'advisory', 'affair', 'affect', 'affected', 'affecting', 'africa', 'african', 'after', 'again', 'age', 'aged', 'agency', 'agent', 'aggressive', 'ago', 'agreed', 'agreement', 'agrees', 'ahead', 'aid', 'aiims', 'aim', 'aimed', 'air', 'airborne', 'airline', 'airport', 'airway', 'akwa', 'al', 'alabama', 'album', 'alcohol', 'alert', 'ali', 'alive', 'alkaline', 'all', 'allah', 'alleged', 'allegedly', 'allergy', 'allocation', 'allow', 'allowance', 'allowed', 'allows', 'alltime', 'almost', 'alone', 'along', 'alongside', 'already', 'also', 'alternative', 'although', 'always', 'am', 'amazing', 'amazon', 'ambulance', 'america', 'american', 'americold', 'amid', 'amidst', 'amit', 'amitabh', 'among', 'amongst', 'amount', 'an', 'analysis', 'anambra', 'anambra1', 'anambra2', 'and', 'andhra', 'andor', 'and…', 'angela', 'anger', 'angry', 'animal', 'announce', 'announced', 'announcement', 'announces', 'announcing', 'another', 'answer', 'anthony', 'antibiotic', 'antibody', 'antigen', 'antimalarial', 'antiviral', 'antonio', 'anxiety', 'any', 'anybody', 'anyone', 'anything', 'apart', 'api', 'apologise', 'app', 'appalling', 'apparently', 'appear', 'appeared', 'appears', 'apple', 'apply', 'appointed', 'approach', 'appropriate', 'approval', 'approved', 'approximately', 'april', 'ar', 'arabia', 'are', 'area', 'arent', 'aren’t', 'argar', 'argentina', 'arizona', 'arkansas', 'arm', 'army', 'aroha', 'around', 'arrange', 'arrest', 'arrested', 'arrival', 'arrived', 'arriving', 'arsenicum', 'article', 'asia', 'asian', 'aside', 'ask', 'asked', 'asking', 'asks', 'aspect', 'aspirin', 'ass', 'assam', 'assessment', 'assign', 'assigned', 'assist', 'assistance', 'associate', 'associated', 'association', 'assume', 'asymptomatic', 'at', 'athlete', 'attack', 'attacked', 'attempt', 'attempted', 'attend', 'attendance', 'attended', 'attending', 'attention', 'attributed', 'auckland', 'audio', 'aug', 'august', 'australia', 'australian', 'authority', 'authorization', 'autopsy', 'availability', 'available', 'average', 'avifavir', 'avoid', 'avoiding', 'awaiting', 'aware', 'awareness', 'away', 'ayurveda', 'ayurvedic', 'ayush', 'az', 'azim', 'azithromycin', 'b', 'baba', 'baby', 'back', 'backbone', 'backfill', 'backlog', 'backlogged', 'bacteria', 'bacterium', 'bad', 'bag', 'bakery', 'baking', 'balance', 'bame', 'ban', 'bangalore', 'bank', 'banned', 'banning', 'bar', 'barack', 'based', 'basic', 'basically', 'basis', 'bat', 'bath', 'battle', 'bauchi', 'bauchi1', 'bauchi2', 'bauchi3', 'bauchi8', 'bay', 'bayelsa1', 'bayelsa14', 'bbc', 'be', 'beach', 'beard', 'beat', 'beaten', 'beating', 'became', 'because', 'become', 'becomes', 'becoming', 'bed', 'beef', 'been', 'beer', 'before', 'began', 'begin', 'beginning', 'begun', 'behaviour', 'behind', 'being', 'belief', 'believe', 'belong', 'benchmark', 'benefit', 'bengal', 'benue', 'benue1', 'benue3', 'bereavement', 'berlin', 'besides', 'best', 'betacoronaviruses', 'betadine', 'better', 'beware', 'beyond', 'bharat', 'bicarbonate', 'biden', 'bidensoetoro', 'big', 'biggest', 'bihar', 'bill', 'billion', 'billionaire', 'bima', 'bioengineered', 'biological', 'biology', 'biotech', 'bioweapon', 'bird', 'birth', 'bit', 'bizarre', 'bjp', 'black', 'blame', 'blamed', 'bleach', 'bless', 'block', 'blog', 'blood', 'blowing', 'blue', 'board', 'body', 'boiled', 'boiling', 'bolivia', 'bollywood', 'bolsonaro', 'bolton', 'book', 'boost', 'border', 'boris', 'borno', 'borno1', 'borno12', 'borno2', 'borno6', 'borno8', 'both', 'bought', 'bounce', 'bound', 'bowl', 'box', 'boy', 'brain', 'branch', 'brazil', 'brazilian', 'break', 'breakdown', 'breaking', 'breastfeeding', 'breath', 'breathe', 'breathing', 'brexit', 'brian', 'briefing', 'bring', 'bringing', 'brings', 'britain', 'british', 'briton', 'broad', 'broader', 'broiler', 'broke', 'broken', 'brother', 'brought', 'budget', 'bug', 'build', 'building', 'built', 'burden', 'buried', 'burning', 'bury', 'bus', 'business', 'busy', 'but', 'buy', 'buying', 'by', 'c', 'c19', 'ca', 'cabbage', 'cabinet', 'calculate', 'california', 'california’s', 'call', 'called', 'calling', 'came', 'camel', 'camila', 'camp', 'campaign', 'can', 'canada', 'canadian', 'cancel', 'cancellation', 'cancelled', 'cancer', 'candidate', 'candle', 'cannot', 'cant', 'can’t', 'capacity', 'capital', 'caption', 'capture', 'captured', 'capturing', 'caput', 'car', 'carbon', 'card', 'cardiac', 'care', 'careful', 'carefully', 'carolina', 'carona', 'carried', 'carrier', 'carry', 'carrying', 'case', 'caseload', 'cases+deaths', 'casestill', 'cases”', 'cases\\u2063', 'casual', 'casualty', 'cat', 'catch', 'catching', 'category', 'cattle', 'caught', 'cause', 'caused', 'causing', 'caveat', 'ccp', 'cdc', 'cdc’s', 'celebrate', 'celebrating', 'celebratory', 'celebrity', 'cell', 'center', 'central', 'centre', 'centreled', 'ceo', 'certain', 'certainly', 'certificate', 'cfr', 'cghs', 'chain', 'chair', 'chairman', 'challenge', 'challenging', 'chance', 'chancellor', 'change', 'changed', 'changing', 'channel', 'charge', 'charity', 'charles', 'chart', 'cheap', 'check', 'checked', 'checker', 'checking', 'checkup', 'chemical', 'chemist', 'chemistry', 'chest', 'chhattisgarh', 'chicago', 'chicken', 'chicken.', 'chief', 'child', 'childcare', 'childhood', 'childrens', 'child’s', 'chile', 'chin', 'china', 'china.', 'chinatown', 'chinese', 'chip', 'chlorine', 'chloroquine', 'choice', 'choose', 'choosing', 'chose', 'chris', 'christchurch', 'chronic', 'chuck', 'chunk', 'church', 'chyna', 'cinema', 'circuit', 'circulate', 'circulated', 'circulates', 'circulating', 'circulation', 'circumstance', 'circus', 'cite', 'cited', 'citizen', 'city', 'civil', 'civilization', 'ciyal', 'claim', 'claimed', 'claiming', 'claire', 'clara', 'clarification', 'clarified', 'clarifies', 'clarify', 'class', 'clean', 'cleaner', 'cleaning', 'clear', 'clearance', 'cleared', 'clearly', 'clever', 'click', 'climate', 'climb', 'climbing', 'clinic', 'clinical', 'clinically', 'clinician', 'clinton', 'clip', 'clo2', 'clock', 'clorox', 'close', 'closed', 'closely', 'closer', 'closing', 'closure', 'clot', 'cloth', 'clothes', 'club', 'cluster', 'cluster\\u2063', 'clínicas', 'cm', 'cnn', 'cns', 'coach', 'coaching', 'cobra', 'coca', 'cocaine', 'coca’s', 'code', 'coded', 'coffee', 'coffin', 'cohort', 'coin', 'cold', 'collaboration', 'collaborative', 'collapse', 'collapsing', 'collates', 'colleague', 'collection', 'collective', 'college', 'colloidal', 'colombia', 'color', 'colorado', 'colour', 'columbia', 'column', 'combat', 'combating', 'combination', 'combined', 'combo', 'come', 'coming', 'commemorative', 'commercial', 'commission', 'commit', 'commitment', 'commits', 'committed', 'committee', 'commodity', 'common', 'commonly', 'communal', 'communicate', 'communicated', 'communicating', 'communication', 'communist', 'community', 'communitybased', 'comorbidities', 'company', 'company’s', 'comparable', 'compare', 'compared', 'comparing', 'comparison', 'compassionate', 'complaint', 'complete', 'completed', 'completely', 'completes', 'completing', 'complex', 'complexity', 'compliance', 'complicated', 'complication', 'complicit', 'component', 'compound', 'comprehensive', 'comprehensively', 'comprising', 'compulsory', 'computer', 'concentrated', 'concentration', 'concern', 'concerned', 'concerning', 'concluded', 'conclusion', 'conclusive', 'condemned', 'condition', 'conduct', 'conducted', 'conducting', 'conference', 'confidence', 'confident', 'confirm', 'confirmation', 'confirmed', 'confirming', 'confirms', 'confuse', 'confused', 'confusing', 'congregation', 'congress', 'connect', 'connected', 'connecticut', 'connecting', 'connection', 'consecutive', 'consent', 'consequence', 'consider', 'considerable', 'consideration', 'considered', 'considering', 'consistent', 'consistently', 'conspiracy', 'constant', 'constantly', 'constituent', 'constrained', 'constructed', 'consult', 'consultation', 'consume', 'consuming', 'consumption', 'contact', 'contacted', 'contacted\\u2063', 'contacting', 'contagion', 'contain', 'containing', 'containment', 'contains', 'contaminated', 'content', 'context', 'continent', 'continue', 'continued', 'continues', 'continuing', 'continuous', 'continuously', 'contract', 'contracted', 'contracting', 'contrary', 'contribute', 'contributed', 'contributing', 'contribution', 'control', 'controlled', 'controller', 'controlling', 'controversial', 'controversy', 'convalescent', 'convened', 'convention', 'conversation', 'conversion', 'convert', 'converted', 'converting', 'cool', 'coordinate', 'coordinated', 'coordination', 'cop', 'cope', 'copied', 'coping', 'core', 'corona', 'coronacheck', 'coronavac', 'coronavirus', 'coronavirus.', 'coronavirus.�', 'coronaviruses', 'coronavirusthemed', 'coronavirus”', 'coronil', 'corporation', 'corps', 'corpse', 'correct', 'corrected', 'correction', 'correctly', 'correctness', 'correlation', 'corridor', 'corrientes', 'corticosteroid', 'cost', 'costco', 'cough', 'coughing', 'could', 'couldnt', 'couldn’t', 'council', 'count', 'counted', 'counter', 'counterpart', 'counting', 'countries@drtedros', 'country', 'country’s', 'county', 'couple', 'coupled', 'course', 'court', 'court’s', 'cov2', 'covax', 'covaxin', 'cover', 'coverage', 'covered', 'covering', 'covid', 'covid-19', 'covid-19.', 'covid-19.�', 'covid-19s', 'covid-19\\u200b', 'covid-19\\u2063', 'covid1', 'covid19', 'covid19nigeria', 'covid19related', 'covid19’s', 'covidiots', 'covidnet', 'covidrelated', 'covidsafe', 'cow', 'cr', 'crazy', 'cream', 'create', 'created', 'creating', 'credit', 'creeping', 'crematorium', 'creted', 'crew', 'cricket', 'crime', 'criminal', 'criminalized', 'crisis', 'cristiano', 'criterion', 'critical', 'critically', 'crore', 'cross', 'crossed', 'crossing', 'crowd', 'crowded', 'crown', 'crucial', 'cruise', 'cry', 'ct', 'cuba', 'cultural', 'cummings', 'cumulative', 'cumulatively', 'cunial', 'cuomo', 'cup', 'cupboard', 'curbside', 'cure', 'cured', 'cureddischargedmigrated', 'cureddischargedmigrated+active', 'curedrecovered', 'curfew', 'currency', 'current', 'currently', 'currently;', 'curve', 'customer', 'cut', 'cutting', 'cv', 'cv19', 'c…', 'd', 'da', 'dad', 'dadar', 'daily', 'dakota', 'damage', 'danger', 'dangerous', 'daniel', 'dark', 'dashboard', 'data', 'dataset', 'date', 'dating', 'daughter', 'david', 'day', 'dc', 'dcgi', 'de', 'dead', 'deadly', 'deal', 'dear', 'death', 'debt', 'debunked', 'debunking', 'decade', 'deceased', 'december', 'decide', 'decided', 'decision', 'declared', 'decline', 'declined', 'declining', 'decrease', 'decreased', 'decreasing', 'dedicated', 'deep', 'defeat', 'defense', 'definitely', 'definition', 'degree', 'dehradun', 'delaware', 'delay', 'delayed', 'deleted', 'delhi', 'delivered', 'delivering', 'delivery', 'delta', 'delta10', 'delta12', 'delta3', 'delta6', 'delta7', 'demand', 'demanding', 'democrat', 'democratic', 'demographic', 'demonstrated', 'denied', 'denies', 'departing', 'department', 'departure', 'depending', 'depends', 'deploy', 'deployed', 'depression', 'deputy', 'desantis', 'describes', 'describing', 'description', 'design', 'despite', 'destroy', 'destroyed', 'detail', 'detect', 'detected', 'detection', 'determine', 'develop', 'developed', 'developer', 'developing', 'development', 'dexamethasone', 'dg', 'diabetes', 'diagnose', 'diagnosed', 'diagnosis', 'diagnostic', 'diagnostics', 'did', 'didnt', 'didn’t', 'dido', 'die', 'died', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'digital', 'dioxide', 'dip', 'direct', 'direction', 'directive', 'directly', 'director', 'directorgeneral', 'directs', 'dirty', 'disaster', 'discharge', 'discharged', 'discontinued', 'discover', 'discovered', 'discrepancy', 'discus', 'discussion', 'disease', 'disinfect', 'disinfectant', 'disinfection', 'disorder', 'disparity', 'disproportionately', 'disrupted', 'disruption', 'distance', 'distancing', 'distributed', 'distributing', 'distribution', 'district', 'diverse', 'dna', 'do', 'doc', 'doctor', 'doctored', 'document', 'documentary', 'doesnt', 'doesn’t', 'dog', 'doha', 'dollar', 'domestic', 'dominic', 'donald', 'donate', 'donated', 'donation', 'done', 'dont', 'don’t', 'door', 'dos', 'dose', 'double', 'doubled', 'doubling', 'doubt', 'doug', 'down', 'download', 'dozen', 'dr', 'drink', 'drinking', 'drive', 'driven', 'driver', 'driving', 'drop', 'droplet', 'dropped', 'drove', 'drug', 'dublin', 'duck', 'due', 'during', 'duterte', 'duty', 'dy', 'dying', 'dynamic', 'each', 'earlier', 'early', 'earn', 'earth', 'ease', 'easier', 'easily', 'easing', 'east', 'easy', 'eat', 'eating', 'ebola', 'ebonyi11', 'ebonyi3', 'ebonyi4', 'ebonyi9', 'economic', 'economy', 'ecuador', 'ed', 'edo', 'edo1', 'edo17', 'edo22', 'education', 'educational', 'edward', 'effect', 'effective', 'effectively', 'effectiveness', 'efficient', 'efficiently', 'effort', 'eight', 'either', 'ekiti', 'ekiti1', 'ekiti2', 'ekiti4', 'ekiti6', 'elbow', 'elderly', 'elected', 'election', 'elective', 'elevated', 'eligible', 'eliminate', 'eliminates', 'elizabeth', 'else', 'email', 'emerged', 'emergency', 'emerging', 'emirate', 'emission', 'emphasis', 'employee', 'employment', 'empty', 'enable', 'encourage', 'encouraged', 'encourages', 'encouraging', 'end', 'ended', 'ending', 'enforce', 'enforcement', 'engagement', 'engaging', 'england', 'enhanced', 'enjoy', 'enough', 'enrollment', 'ensure', 'ensured', 'ensuring', 'enter', 'entered', 'entire', 'entitled', 'entrance', 'entry', 'enugu', 'enugu15', 'enugu2', 'enugu6', 'epidemic', 'epidemiological', 'epidemiologist', 'equipment', 'equitable', 'equity', 'er', 'eradicate', 'erratic', 'erroneously', 'error', 'especially', 'essential', 'established', 'establishes', 'estimate', 'estimated', 'et', 'etc', 'ethnic', 'ethnicity', 'eu', 'europe', 'european', 'evaluate', 'evaluation', 'evangelical', 'evangelicals', 'even', 'evening', 'event', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everywhere', 'eviction', 'evidence', 'exact', 'exactly', 'exaggerated', 'exam', 'examination', 'examines', 'example', 'exceed', 'exceeded', 'exceeds', 'except', 'excess', 'exclusive', 'excuse', 'executive', 'exempt', 'exemption', 'exercise', 'exhausted', 'exist', 'existed', 'existing', 'exists', 'expand', 'expanded', 'expanding', 'expansion', 'expect', 'expected', 'expecting', 'experience', 'experiencing', 'expert', 'explain', 'explained', 'explains', 'exponential', 'exponentially', 'exporting', 'exposed', 'exposure', 'expresident', 'expressly', 'extended', 'extending', 'extends', 'extension', 'extensive', 'extent', 'extra', 'extreme', 'extremely', 'eye', 'fabiflu', 'face', 'facebook', 'facemask', 'facility', 'facing', 'fact', 'fact-check', 'factchecking', 'factor', 'fail', 'failed', 'failing', 'failure', 'fair', 'faith', 'fake', 'fall', 'fallen', 'falling', 'false', 'falsehood', 'family', 'famous', 'fan', 'faq', 'far', 'fast', 'faster', 'fastest', 'fatal', 'fatality', 'father', 'fatigue', 'fauci', 'favipiravir', 'fbi', 'fct', 'fct14', 'fct25', 'fct35', 'fct60', 'fda', 'fear', 'feature', 'feb', 'february', 'federal', 'feel', 'feeling', 'fell', 'fellowship', 'felt', 'female', 'fennel', 'fever', 'fewer', 'fewest', 'fibrosis', 'field', 'fifth', 'fight', 'fighting', 'figure', 'filed', 'filipino', 'filled', 'film', 'filmed', 'final', 'finally', 'finance', 'financial', 'financially', 'find', 'finding', 'fine', 'fined', 'fire', 'fired', 'firing', 'first', 'fiscal', 'fit', 'five', 'fixed', 'fl', 'flag', 'flattened', 'flawed', 'flight', 'floor', 'florida', 'flour', 'flouting', 'flu', 'flying', 'focus', 'focused', 'folk', 'follow', 'followed', 'following', 'follows', 'followup', 'food', 'foot', 'footage', 'for', 'force', 'forced', 'forecast', 'foreign', 'foreseeable', 'forever', 'forged', 'forget', 'forgotten', 'form', 'former', 'fortaleza', 'forward', 'fought', 'found', 'foundation', 'founder', 'four', 'fourmonth', 'fourteen', 'fourth', 'fox', 'fraction', 'framework', 'france', 'francis', 'fraud', 'free', 'freedom', 'freely', 'freeview', 'freezing', 'french', 'frequency', 'frequently', 'fresh', 'freshly', 'friday', 'friend', 'frm', 'from', 'front', 'frontline', 'frozen', 'fruit', 'frustration', 'ft', 'fuck', 'fuel', 'full', 'fully', 'function', 'functional', 'fund', 'fundamental', 'fundamentally', 'funded', 'funding', 'funeral', 'fungal', 'funneled', 'funny', 'furlough', 'future', 'ga', 'gain', 'galicia', 'game', 'gandhi', 'ganga', 'gap', 'gargle', 'gargling', 'garib', 'garlic', 'gate', 'gather', 'gathered', 'gathering', 'gave', 'gay', 'gear', 'gender', 'general', 'generally', 'generate', 'generated', 'generation', 'genetic', 'genexpert', 'genius', 'genocide', 'genomic', 'gentleman', 'genuine', 'geographical', 'george', 'georgia', 'gerais', 'germ', 'german', 'germany', 'get', 'getting', 'ghana', 'ghana’s', 'ghislaine', 'gift', 'gifted', 'gilead', 'ginger', 'girl', 'give', 'given', 'giving', 'glad', 'global', 'globally', 'globe', 'glove', 'go', 'goal', 'god', 'goi', 'going', 'gold', 'gombe', 'gombe1', 'gombe2', 'gombe21', 'gombe3', 'gombe30', 'gombe4', 'gombe5', 'gombe6', 'gone', 'gonna', 'good', 'goodbye', 'goodwill', 'google', 'gop', 'got', 'gotten', 'gourd', 'gov', 'gove', 'government', 'government’s', 'governor', 'govt', 'gowdy', 'gown', 'gp', 'gps', 'grade', 'graded', 'graduate', 'graf', 'grand', 'grandparent', 'grant', 'granted', 'graph', 'graphic', 'grateful', 'gratitude', 'grave', 'graveyard', 'great', 'greater', 'greatest', 'greatly', 'greece', 'green', 'grenons', 'gretchen', 'grieve', 'grim', 'grime', 'grocery', 'ground', 'groundbreaking', 'group', 'grow', 'growing', 'grown', 'growth', 'guarantee', 'guatemalan', 'guess', 'guest', 'guidance', 'guide', 'guideline', 'guidelinesnotifications', 'guinean', 'gujarat', 'gun', 'guy', 'gym', 'h1n1', 'ha', 'habit', 'hack', 'had', 'hadio', 'hadnt', 'hail', 'hair', 'hairdresser', 'haji', 'hajipur', 'half', 'hall', 'halt', 'hamster', 'hancock', 'hand', 'handed', 'handing', 'handle', 'handling', 'hangover', 'hank', 'hantavirus', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'harder', 'hardest', 'harding', 'hardship', 'hare', 'haripriya', 'harm', 'harmful', 'harmless', 'harmless”', 'harris', 'harvard', 'haryana', 'hasnt', 'hasn’t', 'hat', 'hate', 'have', 'havent', 'haven’t', 'having', 'hav…', 'hcq', 'he', 'head', 'headache', 'heading', 'headline', 'headquarters', 'headroom', 'headteacher', 'heal', 'health', 'healthcare', 'healthline', 'healthy', 'health\\u2063', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heath', 'heavily', 'heavy', 'height', 'held', 'heleno', 'hell', 'hello', 'help', 'helped', 'helping', 'helpline', 'hence', 'her', 'herbal', 'herd', 'here', 'here’s', 'herman', 'hero', 'he’s', 'hhs', 'hi', 'hidden', 'hiding', 'high', 'higher', 'highest', 'highincome', 'highlight', 'highlighting', 'highly', 'highrisk', 'hill', 'hillary', 'hindu', 'hinted', 'his', 'hispanic', 'historic', 'historical', 'history', 'hit', 'hitting', 'hiv', 'hivaids', 'hmh', 'hoax', 'hold', 'holding', 'holiday', 'home', 'homeless', 'homemade', 'homeopathic', 'homeopathy', 'homeschooling', 'hon', 'honey', 'hong', 'honjo', 'honourable', 'honoured', 'hope', 'hopefully', 'hoping', 'hopkins', 'horizon', 'horny', 'horse', 'hosp', 'hospital', 'hospitalists', 'hospitality', 'hospitalization', 'hospitalizationsicu', 'hospitalized', 'hospitallevel', 'host', 'hot', 'hotel', 'hotline', 'hotspot', 'hour', 'house', 'household', 'housing', 'how', 'however', 'hr', 'huge', 'hugging', 'human', 'humanitarian', 'humanity', 'hundred', 'hunger', 'hungry', 'hurricane', 'hurt', 'hussein', 'hyderabad', 'hydroxychloroquine', 'hygiene', 'hypoxia', 'i', 'ibom', 'ibom11', 'ibuprofen', 'ice', 'icmr', 'icu', 'icu\\u2063', 'icymi', 'id', 'idaho', 'idea', 'identification', 'identified', 'identify', 'identifying', 'idiocy', 'ie', 'if', 'ignoring', 'ii', 'ill', 'illegal', 'illinois', 'illness', 'im', 'image', 'immediate', 'immediately', 'immune', 'immunity', 'immunization', 'immunosuppression', 'imo', 'imo1', 'imo2', 'imo3', 'impact', 'impacted', 'impeachment', 'imperial', 'implant', 'implement', 'implemented', 'importance', 'important', 'imported', 'impose', 'imposed', 'improve', 'improved', 'improvement', 'improves', 'improving', 'imran', 'in', 'incident', 'include', 'included', 'includes', 'including', 'inclusion', 'income', 'incomplete', 'increase', 'increased', 'increasing', 'incubation', 'independent', 'index', 'india', 'india.', 'indian', 'indiana', 'india’s', 'indicate', 'indicated', 'indicates', 'indicating', 'indicator', 'indigenous', 'indigenously', 'individual', 'indonesian', 'indoors', 'indore', 'industrial', 'industry', 'ineffective', 'inequity', 'infect', 'infected', 'infecting', 'infection', 'infectious', 'infects', 'inflammation', 'inflammatory', 'influenza', 'info', 'inform', 'information', 'informed', 'inhalation', 'inhale', 'inhaling', 'initial', 'initiated', 'initiation', 'initiative', 'injecting', 'injection', 'inmate', 'inside', 'insight', 'insists', 'instagram', 'instant', 'instead', 'institute', 'institution', 'institutional', 'instruction', 'insurance', 'intended', 'intense', 'intensive', 'interest', 'interested', 'interim', 'international', 'internet', 'interpret', 'intervention', 'interview', 'introduce', 'introduced', 'introduces', 'introduction', 'invalid', 'invention', 'inventor', 'invest', 'investigate', 'investigated', 'investigating', 'investigation', 'investigator', 'investment', 'invisible', 'invite', 'invoking', 'involve', 'involved', 'involving', 'in…', 'iodine', 'ipc', 'iphone', 'iran', 'ireland', 'irish', 'irrefutably', 'is', 'islam', 'islamic', 'island', 'isnt', 'isn’t', 'isolate', 'isolated', 'isolating', 'isolation', 'isolation\\u200b', 'israel', 'israeli', 'issue', 'issued', 'is”', 'it', 'italian', 'italy', 'item', 'it’s', 'ive', 'ivermectin', 'i…', 'jacksonville', 'jail', 'jaipur', 'jair', 'jamaat', 'james', 'jan', 'janeiro', 'janta', 'january', 'japan', 'japanese', 'japan’s', 'jazz', 'jeevan', 'jennifer', 'jersey', 'jesus', 'jesús', 'jet', 'jharkhand', 'jhu', 'ji', 'jigawa2', 'jigawa8', 'jihadi', 'jinping', 'job', 'jobless', 'joe', 'jogger', 'john', 'johnson', 'join', 'joined', 'joint', 'jones', 'journal', 'journalist', 'joão', 'judaism', 'judy', 'juice', 'july', 'jump', 'jumped', 'jumping', 'june', 'jurisdiction', 'just', 'justify', 'justin', 'jyoti', 'k', 'k12', 'ka', 'kaduna', 'kaduna10', 'kaduna11', 'kaduna12', 'kaduna14', 'kaduna15', 'kaduna17', 'kaduna18', 'kaduna19', 'kaduna23', 'kaduna30', 'kaduna6', 'kaduna8', 'kaduna9', 'kalonji', 'kalyan', 'kamala', 'kano', 'kano1', 'kano10', 'kano12', 'kano16', 'kano2', 'kano3', 'kano4', 'kano5', 'kano6', 'kano73', 'kano9', 'kansa', 'karnataka', 'kate', 'katsina', 'katsina1', 'katsina14', 'katsina2', 'katsina21', 'katsina3', 'katsina6', 'katsina7', 'kebbi1', 'kebbi2', 'kebbi3', 'keep', 'keeping', 'keir', 'kejriwal', 'kemp', 'kentucky', 'kenya', 'kenyan', 'kept', 'kerala', 'kettle', 'key', 'kg', 'khan', 'kia', 'kicillof', 'kick', 'kid', 'kidney', 'kill', 'killed', 'killer', 'killing', 'kind', 'kindly', 'king', 'kingdom', 'kiss', 'kit', 'kitchen', 'kiwi', 'knew', 'knock', 'know', 'knowledge', 'known', 'kong', 'korea', 'kota', 'kowheori19', 'kroger', 'kudos', 'kumar', 'kuwait', 'kwara', 'kwara1', 'kwara10', 'kwara11', 'kwara15', 'kwara2', 'kwara3', 'kwara4', 'kwara5', 'kwara6', 'ky', 'la', 'lab', 'labconfirmed', 'label', 'labeled', 'labor', 'laboratory', 'laborer', 'labour', 'lack', 'lady', 'lag', 'lagos', 'lagos-', 'lagos123', 'lagos156', 'lagos33', 'laid', 'lakh', 'lancashire', 'landmark', 'language', 'lanka', 'lankan', 'lankas', 'large', 'largely', 'larger', 'largest', 'last', 'lasting', 'late', 'later', 'latest', 'latex', 'launch', 'launched', 'launching', 'laureate', 'law', 'lawmaker', 'lawsuit', 'layer', 'laying', 'le', 'lead', 'leader', 'leadership', 'leading', 'leaf', 'league', 'leaked', 'leapfrogged', 'learn', 'learned', 'learning', 'learns', 'learn…', 'least', 'leave', 'leaving', 'lebanon', 'led', 'left', 'legal', 'legionnaire', 'legislator', 'lemon', 'length', 'leni', 'lenox', 'lesson', 'let', 'letter', 'let’s', 'level', 'lewis', 'lgas', 'li', 'liaison', 'liberty', 'license', 'licking', 'lieber', 'life', 'lifesaving', 'lifethreatening', 'lift', 'lifted', 'light', 'lighting', 'like', 'likely', 'limeng', 'limit', 'limited', 'limiting', 'line', 'link', 'linked', 'linking', 'lion', 'liquefies', 'liquid', 'liquor', 'list', 'listed', 'listen', 'listening', 'lit', 'literally', 'little', 'live', 'liver', 'living', 'llano', 'load', 'local', 'locally', 'located', 'location', 'lock', 'lockdown', 'lockdown.', 'locked', 'log', 'logged', 'logic', 'logo', 'lol', 'london', 'londoner', 'long', 'longer', 'longlasting', 'longterm', 'look', 'looked', 'looking', 'lorry', 'los', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'louisiana', 'love', 'loved', 'low', 'lower', 'lowerincome', 'lowest', 'ltc', 'ltd', 'lucky', 'luke', 'lumped', 'lung', 'lying', 'lysol', 'm', 'ma', 'macedonia', 'macedonian', 'machine', 'madagascan', 'madagascar', 'maddow', 'made', 'madhya', 'madrid', 'maduro', 'magazine', 'magic', 'magne', 'maharashtra', 'mail', 'main', 'maine', 'maintain', 'maintained', 'maintaining', 'maintains', 'major', 'majority', 'make', 'maker', 'making', 'malaria', 'malaysia', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manager', 'managing', 'manatū', 'mandate', 'mandated', 'mandatory', 'manipulated', 'manipulation', 'manipur', 'manmade', 'mannequin', 'mantri', 'manual', 'manufacture', 'manufactured', 'manufacturer', 'manufacturing', 'many', 'man’s', 'map', 'marapr', 'march', 'margaret’s', 'marine', 'mark', 'market', 'maryland', 'mask', 'masking', 'mass', 'massachusetts', 'massive', 'material', 'matt', 'matter', 'maximum', 'maxwell', 'may', 'maybe', 'mayor', 'mcconnell', 'mean', 'meaning', 'meant', 'meanwhile', 'measure', 'meat', 'meatpacking', 'mechanical', 'mechanism', 'medical', 'medicare', 'medication', 'medicine', 'medium', 'medscape', 'meet', 'meeting', 'melbourne', 'melinda', 'member', 'membrane', 'men', 'mental', 'mentioned', 'merkel', 'mers', 'message', 'messaging', 'messed', 'messy', 'met', 'metformin', 'method', 'metre', 'metric', 'metro', 'mexico', 'michigan', 'michigan’s', 'microchip', 'mid-may', 'middle', 'middleincome', 'middlemore', 'midnight', 'midst', 'midwest', 'might', 'migrant', 'mike', 'milan', 'mild', 'milestone', 'military', 'milk', 'million', 'min', 'mind', 'mine', 'mineral', 'minister', 'ministry', 'minority', 'minute', 'miq', 'miracle', 'misinformation', 'misleading', 'missed', 'missing', 'mission', 'mississippi', 'missouri', 'mistake', 'mitch', 'mitigate', 'mix', 'mla', 'mm', 'mobile', 'mobility', 'mode', 'model', 'modelling', 'moderate', 'modi', 'molecular', 'moment', 'monday', 'money', 'monitor', 'monitoring', 'monkey', 'montanari', 'month', 'more', 'morning', 'mortality', 'mortgage', 'mosque', 'mosquito', 'most', 'mostly', 'mother', 'mountain', 'mouth', 'mouthwash', 'move', 'moved', 'movement', 'moving', 'mp', 'mr', 'mri', 'mrna1273', 'mt', 'much', 'multiple', 'multisystem', 'mumbai', 'murder', 'music', 'muslim', 'must', 'mustard', 'my', 'myanmar', 'mystery', 'n', 'n95', 'nadu', 'nagpur', 'namaz', 'name', 'named', 'nanavati', 'nancy', 'narendra', 'nasal', 'nasarawa1', 'nasarawa2', 'nasarawa3', 'nasarawa8', 'nashville', 'nation', 'national', 'nationally', 'nationwide', 'nation’s', 'natural', 'nature', 'nba', 'ncdc', 'ne', 'near', 'nearly', 'nears', 'nebraska', 'necessarily', 'necessary', 'need', 'needed', 'negative', 'negligence', 'neighbor', 'neighbour', 'neil', 'neither', 'net', 'netherlands', 'network', 'nevada', 'never', 'new', 'newborn', 'newcase', 'newest', 'newly', 'news', 'newsletter', 'newspaper', 'next', 'nh', 'nicola', 'niger', 'niger1', 'niger2', 'nigeria', 'nigerian', 'nigeria’s', 'night', 'nih', 'nine', 'nipah', 'nj', 'no', 'nobel', 'nobody', 'none', 'nonessential', 'nonhispanic', 'normal', 'normally', 'north', 'northeast', 'northern', 'nose', 'nostradamus', 'not', 'note', 'noted', 'nothing', 'notice', 'noting', 'novel', 'november', 'novotel', 'now', 'now)', 'number', 'nurse', 'nursing', 'nutrition', 'nv', 'ny', 'nyc', 'nz', 'obama', 'obamacare', 'obesity', 'observation', 'observed', 'obtain', 'obviously', 'occur', 'occurred', 'october', 'odd', 'odisha', 'of', 'off', 'offense', 'offer', 'offered', 'offering', 'office', 'officer', 'official', 'officially', 'often', 'of…', 'ogun', 'ogun1', 'ogun12', 'ogun14', 'ogun2', 'ogun29', 'ogun3', 'ogun4', 'ogun6', 'ogun7', 'ogun9', 'oh', 'ohio', 'oil', 'ok', 'oklahoma', 'old', 'older', 'olive', 'olympics', 'on', 'once', 'ondo', 'ondo1', 'ondo16', 'ondo3', 'ondo5', 'one', 'one’s', 'ongoing', 'onion', 'online', 'only', 'onset', 'onto', 'open', 'opening', 'operation', 'opportunity', 'option', 'or', 'order', 'ordered', 'oregon', 'organisation', 'organization', 'organization\\u200b', 'organization\\u2063', 'origin', 'original', 'originated', 'os', 'osun', 'osun1', 'osun2', 'osun20', 'osun3', 'other', 'others', 'our', 'out', 'outbreak', 'outcome', 'outlet', 'outside', 'outwards', 'over', 'overall', 'overcome', 'overloaded', 'overnight', 'overseas', 'overwhelmed', 'overwhelming', 'owner', 'oxford', 'oxygen', 'oyo', 'oyo17', 'oyo18', 'oyo20', 'oyo8', 'pacific', 'pack', 'package', 'packed', 'packet', 'page', 'paid', 'pain', 'pak', 'pakistan', 'pakistani', 'palm', 'panama', 'pandemic', 'pandemic.', 'pandemic.�', 'panel', 'panic', 'pant', 'papad', 'paper', 'paracetamol', 'paraguayan', 'paralyzed', 'parameter', 'parent', 'parental', 'paris', 'park', 'parliament', 'part', 'partial', 'partially', 'participant', 'participate', 'participating', 'particle', 'particular', 'particularly', 'partner', 'partnership', 'party', 'party’s', 'pas', 'pass', 'passed', 'passenger', 'passengerexpress', 'passing', 'past', 'pasted', 'patanjali', 'patel', 'patent', 'patented', 'path', 'patient', 'patientswho', 'patients’', 'patient’s', 'patil', 'patrick', 'patron', 'pattern', 'paul', 'pauline', 'paulo', 'pause', 'paused', 'paw', 'pay', 'payer', 'paying', 'payment', 'pcr', 'peace', 'peak', 'peaked', 'pediatric', 'pegged', 'pelosi', 'pelted', 'pelting', 'pending', 'pennsylvania', 'penny', 'people', 'peoples’', 'people’s', 'people”', 'pepper', 'per', 'perambra', 'percapita', 'percent', 'percentage', 'performance', 'performed', 'performing', 'perhaps', 'period', 'permanent', 'permanently', 'permission', 'permitted', 'peroxide', 'persistent', 'person', 'personal', 'personality', 'personnel', 'persontoperson', 'perspective', 'pet', 'petal', 'petrol', 'ph', 'pharma', 'pharmaceutical', 'phase', 'phe', 'philippine', 'phone', 'phone.', 'photo', 'photograph', 'physical', 'physically', 'physician', 'pib', 'pick', 'picked', 'picking', 'picture', 'pie', 'piece', 'pig', 'pigeon', 'pile', 'pill', 'pilot', 'pin', 'piss', 'pitanga', 'place', 'placebo', 'placed', 'plague', 'plain', 'plan', 'plandemic', 'plane', 'planet', 'planned', 'planning', 'plant', 'plasma', 'plastic', 'plate', 'plateau', 'plateau1', 'plateau10', 'plateau11', 'plateau13', 'plateau17', 'plateau18', 'plateau2', 'plateau21', 'plateau23', 'plateau40', 'plateau8', 'plateaued', 'platform', 'play', 'played', 'player', 'playing', 'plaza', 'plea', 'pleads', 'please', 'pleased', 'pledge', 'plenty', 'plot', 'pls', 'plus', 'plz', 'pm', 'pneumonia', 'podcast', 'poem', 'point', 'pointed', 'pointing', 'poison', 'pole', 'police', 'policeman', 'policy', 'polio', 'political', 'politician', 'politifact', 'poll', 'polling', 'pollutant', 'pollution', 'pondicherry', 'pool', 'pooled', 'poor', 'pope', 'popular', 'population', 'port', 'portal', 'portfolio', 'portion', 'portuguese', 'pose', 'posed', 'position', 'positive', 'positives.', 'positivity', 'possibility', 'possible', 'post', 'posted', 'poster', 'posting', 'postpone', 'postponed', 'potential', 'potentially', 'powder', 'power', 'powerful', 'ppe', 'ppl', 'practice', 'practicing', 'pradesh', 'pradhan', 'praise', 'praised', 'pray', 'prayer', 'precaution', 'precautionary', 'precipitously', 'predict', 'predicted', 'prediction', 'predicts', 'preexisting', 'pregnant', 'premier', 'premji', 'prepare', 'prepared', 'preparedness', 'prepares', 'preparing', 'prescribe', 'prescribed', 'prescribing', 'prescription', 'present', 'presentation', 'presented', 'presenting', 'presently', 'president', 'presidential', 'press', 'pressure', 'presymptomatic', 'pretty', 'prevalence', 'prevent', 'prevented', 'preventing', 'prevention', 'preventive', 'prevents', 'previous', 'previously', 'price', 'priest', 'primarily', 'primary', 'primate', 'prime', 'prince', 'princess', 'principal', 'prior', 'prioritised', 'priority', 'prison', 'priti', 'privacy', 'private', 'priyanka', 'prize', 'probability', 'probable', 'probably', 'problem', 'procedure', 'process', 'processed', 'procurement', 'produce', 'produced', 'product', 'production', 'prof', 'professional', 'professor', 'profile', 'program', 'progress', 'progression', 'progressive', 'prohibited', 'project', 'projecting', 'projection', 'promise', 'promising', 'prompt', 'proof', 'propaganda', 'proper', 'properly', 'property', 'prophylactic', 'proportion', 'proposed', 'prospect', 'protect', 'protected', 'protecting', 'protection', 'protective', 'protects', 'protein', 'protest', 'protesting', 'protestors', 'protocol', 'proud', 'prove', 'proved', 'proven', 'provide', 'provided', 'provider', 'provides', 'providing', 'province', 'proving', 'pub', 'public', 'publication', 'publish', 'published', 'pulled', 'pune', 'punishable', 'pupil', 'purchase', 'purchasing', 'purported', 'purportedly', 'purpose', 'push', 'pushed', 'pushing', 'put', 'putin', 'putting', 'pvt', 'p…', 'q', 'qanon', 'qr', 'quality', 'quarantine', 'quarantined', 'quarantining', 'quarter', 'queen', 'question', 'queue', 'quick', 'quickly', 'quietly', 'quinine', 'quite', 'quote', 'quoted', 'quran', 'r', 'r&ampd', 'ra', 'raab', 'race', 'racial', 'racist', 'radiation', 'radio', 'rahul', 'rai', 'railway', 'raise', 'rajasthan', 'rally', 'ram', 'ramdev', 'ramped', 'ramu', 'range', 'rapid', 'rapidly', 'rash', 'ratan', 'rate', 'rated', 'rather', 'ratio', 'raw', 'ray', 'rayner', 're-opening', 'reach', 'reached', 'reaching', 'reacts', 'read', 'readily', 'reading', 'ready', 'real', 'reality', 'really', 'realtime', 'reason', 'reassured', 'receive', 'received', 'receiving', 'recent', 'recently', 'recognize', 'recommend', 'recommendation', 'recommended', 'recommends', 'record', 'recorded', 'recording', 'recover', 'recovered', 'recovering', 'recovery', 'red', 'redfield', 'reduce', 'reduced', 'reduces', 'reducing', 'reduction', 'refer', 'reference', 'referred', 'reflect', 'reflects', 'refuse', 'refused', 'refusing', 'regarding', 'regardless', 'regime', 'region', 'regional', 'register', 'registered', 'registration', 'registry', 'regular', 'regularly', 'regulation', 'reject', 'related', 'relationship', 'relative', 'relatively', 'relaxed', 'release', 'released', 'releasing', 'reliable', 'reliably', 'relief', 'religious', 'relying', 'remain', 'remained', 'remaining', 'remains', 'remdesivir', 'remedy', 'remember', 'reminder', 'removed', 'rent', 'reopen', 'reopened', 'reopening', 'reopenings', 'reopens', 'repeat', 'repeatedly', 'report', 'reported', 'reportedly', 'reporter', 'reporting', 'report\\u2063', 'represent', 'representative', 'represented', 'representing', 'republican', 'request', 'requested', 'requesting', 'require', 'required', 'requirement', 'requires', 'requiring', 'rescue', 'research', 'researcher', 'residence', 'resident', 'resigned', 'resolution', 'resorting', 'resource', 'respect', 'respectively', 'respirator', 'respiratory', 'respond', 'responder', 'responding', 'response', 'responsibility', 'responsible', 'rest', 'restart', 'restaurant', 'restriction', 'restrictive', 'result', 'resulted', 'resume', 'resurgence', 'retail', 'retested', 'return', 'returned', 'returnees', 'returning', 'reveal', 'revealed', 'revealing', 'reveals', 'review', 'reviewed', 'revised', 'richard', 'rid', 'right', 'rio', 'rise', 'risen', 'rising', 'risk', 'risking', 'risky', 'river', 'river3', 'rivers1', 'rivers12', 'rivers2', 'rivers3', 'rna', 'road', 'rob', 'robert', 'roche', 'rodrigo', 'role', 'rolled', 'rolling', 'rollout', 'ron', 'ronaldo', 'room', 'rose', 'roskill', 'rotorua', 'roughly', 'round', 'routine', 'row', 'rt', 'rtpcr', 'rudd', 'ruin', 'rule', 'ruled', 'ruling', 'rumor', 'rumour', 'run', 'running', 'runny', 'rupee', 'rural', 'rushed', 'russia', 'russian', 'russia’s', 'ryanair', 'rydges', 's1s2', 'saad', 'sacred', 'sacrifice', 'sadiq', 'sadly', 'sadness', 'safe', 'safely', 'safety', 'sage', 'said', 'sail', 'saint', 'sake', 'salad', 'salary', 'sale', 'saline', 'saliva', 'salt', 'salute', 'salvador', 'same', 'sample', 'san', 'sander', 'sanitiser', 'sanitizer', 'sanitizers', 'sanskrit', 'sara', 'sarah', 'sars', 'sars-cov-2', 'sarscov2', 'sat', 'satellite', 'saturday', 'saudi', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'sc', 'scale', 'scaled', 'scaling', 'scam', 'scan', 'scare', 'scary', 'scenario', 'scene', 'schedule', 'scheduled', 'scheme', 'school', 'science', 'scientific', 'scientifically', 'scientist', 'scope', 'score', 'scotland', 'scramble', 'scream', 'screaming', 'screen', 'screening', 'screenshot', 'scrub', 'scrutiny', 'sea', 'sealed', 'search', 'season', 'seasonal', 'seat', 'seated', 'second', 'secondary', 'secondhighest', 'secret', 'secretary', 'secretly', 'section', 'sector', 'secure', 'secured', 'securing', 'security', 'see', 'seed', 'seeing', 'seek', 'seeking', 'seem', 'seemingly', 'seems', 'seen', 'segment', 'selected', 'self', 'self-isolate', 'self-isolation', 'selfchecker', 'selfisolate', 'selfisolating', 'selfisolation', 'selfmedicate', 'selfquarantine', 'selfquarantined', 'sell', 'selling', 'senate', 'senator', 'send', 'sending', 'sends', 'senegal', 'senegalese', 'senior', 'sense', 'sent', 'seoul', 'sep', 'separate', 'separated', 'sept', 'september', 'sequencing', 'serial', 'series', 'serious', 'seriously', 'seriousness', 'serology', 'serum', 'serve', 'server', 'service', 'set', 'setting', 'settle', 'setup', 'seven', 'sevenday', 'several', 'severe', 'severely', 'severity', 'sex', 'sexual', 'shadow', 'shah', 'shaheen', 'shall', 'shame', 'shape', 'share', 'shared', 'sharepic', 'sharing', 'sharp', 'shave', 'shaving', 'she', 'sheep', 'sheet', 'shelf', 'shelter', 'shenzhen', 'shield', 'shift', 'shifting', 'ship', 'shipped', 'shipping', 'shit', 'shiva', 'shocked', 'shocking', 'shoe', 'shoot', 'shooting', 'shop', 'shopper', 'shopping', 'shore', 'short', 'shortage', 'shortly', 'shortness', 'shot', 'should', 'shouldnt', 'shouting', 'show', 'showcasing', 'showed', 'showing', 'shown', 'shrinking', 'shut', 'shutdown', 'shuts', 'shutting', 'sick', 'sickness', 'side', 'sign', 'signal', 'signed', 'significant', 'significantly', 'signing', 'silent', 'silver', 'similar', 'simple', 'simply', 'since', 'singapore', 'singer', 'singh', 'singing', 'single', 'singleday', 'sip', 'sir', 'sister', 'site', 'sitting', 'situation', 'six', 'sixth', 'size', 'skill', 'skilled', 'skin', 'sky', 'slack', 'slaughter', 'sleep', 'slightly', 'slow', 'slowed', 'slowing', 'slowly', 'small', 'smaller', 'smoke', 'smoking', 'sneeze', 'sneezing', 'so', 'soap', 'social', 'society', 'soda', 'sodium', 'sokoto', 'sokoto1', 'sokoto2', 'sold', 'solid', 'solidarity', 'solution', 'solve', 'some', 'somehow', 'someone', 'something', 'sometimes', 'son', 'soon', 'sooner', 'sop', 'sore', 'soros', 'sort', 'sound', 'source', 'south', 'southeast', 'southern', 'space', 'spain', 'spanish', 'speak', 'speaker', 'speaking', 'special', 'specialist', 'specific', 'specimen', 'speed', 'speedy', 'spend', 'spent', 'spike', 'spit', 'spitting', 'spoke', 'spoken', 'sport', 'spot', 'spray', 'spread', 'spreading', 'spring', 'sri', 'st', 'stable', 'stacked', 'stadium', 'staff', 'stage', 'stand', 'standard', 'standing', 'stanford', 'star', 'starmer', 'start', 'started', 'starting', 'state', 'stated', 'statement', 'states/uts', 'statesuts', 'statewise', 'state’s', 'stating', 'station', 'statistic', 'stats', 'status', 'stay', 'stayathome', 'staying', 'steadily', 'steady', 'steam', 'steep', 'step', 'steroid', 'stick', 'stigma', 'still', 'stimulus', 'stock', 'stomach', 'stone', 'stop', 'stopped', 'stopping', 'store', 'storm', 'story', 'straight', 'strain', 'stranded', 'strategic', 'strategy', 'street', 'strengthen', 'strengthening', 'stress', 'stressful', 'strict', 'strong', 'stronger', 'struggle', 'struggling', 'student', 'study', 'stuff', 'stupid', 'sturgeon', 'subject', 'submarine', 'substance', 'substantial', 'substantially', 'success', 'successful', 'successfully', 'successive', 'such', 'sudden', 'suffer', 'suffering', 'sufficient', 'suggest', 'suggested', 'suggesting', 'suggestion', 'suggests', 'suicide', 'sum', 'summary', 'summer', 'sun', 'sunday', 'sunlight', 'super', 'supermarket', 'supplement', 'supply', 'support', 'supported', 'supporter', 'supporting', 'supposed', 'supposedly', 'suppress', 'suppressed', 'supreme', 'suraksha', 'surat', 'sure', 'surface', 'surge', 'surgery', 'surge”', 'surgical', 'surpass', 'surpassed', 'surprised', 'surveillance', 'survey', 'survival', 'survive', 'survived', 'suspect', 'suspected', 'suspended', 'sustained', 'swab', 'sweden', 'sweet', 'swimming', 'swine', 'switzerland', 'symptom', 'symptomatic', 'syndrome', 'system', 'systematic', 'são', 'table', 'tablet', 'tablighi', 'tackle', 'tag', 'taiwan', 'tak', 'take', 'taken', 'taking', 'talk', 'talked', 'talking', 'tally', 'tamil', 'tank', 'taraba3', 'target', 'task', 'taste', 'tasuku', 'tata', 'tax', 'tb', 'tea', 'teacher', 'teaching', 'team', 'tech', 'technology', 'teen', 'telangana', 'telemedicine', 'tell', 'telling', 'temperature', 'temple', 'temporary', 'ten', 'tennessee', 'term', 'territory', 'test', 'tested', 'testing', 'texas', 'text', 'thailand', 'than', 'thane', 'thank', 'thanks', 'that', 'thats', 'that’s', 'that”', 'the', 'their', 'then', 'theory', 'therapeutic', 'therapy', 'there', 'therefore', 'there’s', 'thermal', 'these', 'they', 'theyre', 'they’re', 'the…', 'thing', 'think', 'thinking', 'third', 'this', 'those', 'though', 'thought', 'thousand', 'thread', 'threat', 'threatens', 'three', 'throat', 'thrombosis', 'through', 'throughout', 'throwing', 'thrown', 'thursday', 'thus', 'tick', 'ticked', 'tiger', 'tighter', 'till', 'time', 'timeline', 'timely', 'time”', 'tip', 'tipping', 'to', 'today', 'today\\u200b', 'today’s', 'together', 'toilet', 'tokoroa', 'told', 'toll', 'tom', 'tomorrow', 'tonight', 'took', 'tool', 'toolkit', 'top', 'topic', 'total', 'totally', 'totaltestresults', 'tota…', 'touch', 'touched', 'touching', 'tough', 'touted', 'towards', 'tower', 'town', 'trace', 'traced', 'tracer', 'tracing', 'track', 'tracked', 'tracker', 'tracking', 'trade', 'traditional', 'train', 'trained', 'training', 'transferred', 'transmission', 'transmit', 'transmitted', 'transmitting', 'transparency', 'transport', 'transportation', 'travel', 'traveler', 'travelled', 'traveller', 'travelling', 'treat', 'treated', 'treating', 'treatment', 'trend', 'trending', 'trial', 'tribal', 'trick', 'tried', 'trillion', 'trip', 'trouble', 'truck', 'trudeaus', 'true', 'truenat', 'truly', 'trump', 'trump’s', 'trust', 'truth', 'try', 'trying', 'tshirt', 'tuesday', 'tune', 'tunisian', 'turkey', 'turn', 'turned', 'turning', 'tv', 'tweet', 'tweeted', 'twenty', 'twice', 'twitter', 'two', 'tx', 'type', 't…', 'u', 'uganda', 'uk', 'ultimately', 'umbrella', 'un', 'unable', 'uncertainty', 'unchanged', 'unclear', 'uncomfortable', 'under', 'undergo', 'underlying', 'understand', 'understanding', 'understands', 'underway', 'unemployed', 'unemployment', 'unfortunately', 'unicef', 'union', 'unique', 'unit', 'united', 'universal', 'university', 'unknown', 'unless', 'unlike', 'unlikely', 'unprecedented', 'unwell', 'up', 'update', 'updated', 'update\\u200b', 'updating', 'upgraded', 'upon', 'upper', 'upsurge', 'upto', 'urge', 'urged', 'urgent', 'urgently', 'urging', 'urine', 'us', 'usa', 'usage', 'use', 'used', 'useful', 'useless', 'user', 'using', 'usual', 'usually', 'ut', 'utah', 'uttar', 'uv', 'v', 'vaccinated', 'vaccination', 'vaccine', 'validated', 'vallance', 'value', 'van', 'varies', 'various', 'vast', 'vati', 'vatican', 'vegetable', 'vegetarian', 'vehicle', 'ventilation', 'ventilator', 'verified', 'vermont', 'verse', 'version', 'via', 'vice', 'victim', 'victoria', 'victorian', 'video', 'view', 'viewed', 'vinegar', 'violated', 'violating', 'violation', 'viral', 'virginia', 'virologist', 'virology', 'virtual', 'virus', 'virus.', 'virus.�', 'virus”', 'visa', 'visit', 'visited', 'visiting', 'vital', 'vitamin', 'vk', 'vladimir', 'voice', 'volleyball', 'volume', 'voluntary', 'volunteer', 'vote', 'voting', 'vp', 'vte', 'vulnerable', 'w', 'wa', 'waikato', 'wait', 'waitakere', 'waiting', 'wake', 'wale', 'walking', 'wall', 'want', 'wanted', 'war', 'ward', 'warm', 'warn', 'warned', 'warning', 'warns', 'warrior', 'wash', 'washing', 'washington', 'wasnt', 'watch', 'watching', 'water', 'wave', 'way', 'we', 'weak', 'weapon', 'wear', 'wearing', 'weather', 'webinar', 'website', 'wed', 'wedding', 'wednesday', 'weed', 'week', 'weekend', 'weekly', 'well', 'wellbeing', 'wellington', 'wenliang', 'went', 'were', 'west', 'western', 'wet', 'weve', 'we‘ve', 'we’ll', 'we’re', 'we’ve', 'what', 'whatever', 'whats', 'whatsapp', 'what’s', 'when', 'where', 'whereas', 'whether', 'which', 'while', 'whistleblower', 'white', 'whitty', 'who', 'whole', 'whose', 'who’s', 'why', 'wide', 'widely', 'widespread', 'wife', 'will', 'william', 'window', 'winning', 'winter', 'wipe', 'wiped', 'wisconsin', 'wise', 'with', 'within', 'without', 'witness', 'woman', 'wonder', 'wonderful', 'wondering', 'wont', 'won’t', 'word', 'wore', 'work', 'worked', 'worker', 'working', 'workplace', 'world', 'worldwide', 'world’s', 'world”', 'worse', 'worship', 'worst', 'worth', 'would', 'wouldnt', 'writing', 'written', 'wrong', 'wrongly', 'wrote', 'wuhan', 'wwn', 'xi', 'yan', 'yeah', 'year', 'yemen', 'yes', 'yesterday', 'yet', 'yobe1', 'yobe2', 'yobe3', 'yoga', 'yojana', 'york', 'york’s', 'you', 'youll', 'young', 'younger', 'your', 'youre', 'youth', 'youtube', 'you’re', 'you’ve', 'zealand', 'zealander', 'zealand’s', 'zero', 'zika', 'zinc', 'zone', '|', '£10000', '£500', '\\u200b', '\\u200b\\u2063', '\\u200b\\u2063\\u2063', '–', '—', '“a', '“all', '“as', '“big', '“every', '“i', '“if', '“in', '“only”', '“seamless”', '“the', '“this', '“totally', '“we', '“we’re', '•', '…', '\\u2063', '\\u2063\\u2063', '\\u2063\\u2063\\u2063\\u2063', '▪️', '▶️1.60', '◾', '✅', '✅indias', '✅more', '✅observe', '✅over', '✅wash', '❗', '➡', '➡️active', '➡️confirmed', '➡️deaths', '➡️interventions', '➡️recovered', '➡️states', '➡️total', '⠀', '🌍', '🏫', '👇', '👉', '👉india', '👉the', '👍', '📍', '📍#covid19', '📍increasing', '📍statewise', '📍steady', '📍total', '📢#coronavirusupdates', '📱', '📺', '🔰full', '🔰read', '🔰report', '🔴', '😷', '🙌']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform"
      ],
      "metadata": {
        "id": "l7IRYu7XtBRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words = vectorizer_stop_words_stemmed.transform(X_train[\"tweet\"])\n",
        "bag_of_words = pd.DataFrame(bag_of_words.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())"
      ],
      "metadata": {
        "id": "laKfx_8Fx4Nb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words.shape[1]"
      ],
      "metadata": {
        "id": "D68kVvh8wXfW",
        "outputId": "6350ef75-2650-45c4-8d12-cb21b0f79b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal"
      ],
      "metadata": {
        "id": "ilGGPtUT0xFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-LjzAEbc0Knv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "metadata": {
        "id": "e8pMorDV1DI9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer='Adam'\n",
        "loss='binary_crossentropy'\n",
        "metric='accuracy'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_shape=(bag_of_words.shape[1],)))\n",
        "model.add(Activation(LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(30, use_bias=True))\n",
        "model.add(Activation(LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(1, use_bias=True))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss=loss, optimizer=adam_optimizer, metrics=[metric])"
      ],
      "metadata": {
        "id": "lW8SiL-t01M0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_array = np.asarray(bag_of_words)\n",
        "Y_train_array = np.asarray(Y_train)\n",
        "\n",
        "training = model.fit(X_train_array, Y_train_array, epochs=200, batch_size=100, validation_split=0.2)"
      ],
      "metadata": {
        "id": "gY0iDNOLDG88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18eb822e-3e93-48b3-e997-370febcc0037"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 5.5515e-08 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.9264\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.4465e-08 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9264\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.3464e-08 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.9264\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.2443e-08 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9264\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.1444e-08 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.9264\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.0466e-08 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.9264\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 4.9527e-08 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.9256\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 4.8599e-08 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.9256\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 4.7636e-08 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.9256\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.6721e-08 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.9256\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 4.5834e-08 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.9256\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.4968e-08 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.9256\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.4066e-08 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.9256\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.3217e-08 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9256\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.2403e-08 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.9256\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 4.1550e-08 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.9256\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.0974e-08 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.9256\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.9942e-08 - accuracy: 1.0000 - val_loss: 0.9786 - val_accuracy: 0.9256\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.9155e-08 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.9256\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.8399e-08 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.9256\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.7677e-08 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.9256\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.6897e-08 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.9256\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.6243e-08 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.9256\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.5474e-08 - accuracy: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.9256\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.4771e-08 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.9256\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4088e-08 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.9256\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.3520e-08 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.9256\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.2752e-08 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9256\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2139e-08 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.9256\n",
            "Epoch 30/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.1500e-08 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.9256\n",
            "Epoch 31/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.0856e-08 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.9256\n",
            "Epoch 32/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.0425e-08 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.9256\n",
            "Epoch 33/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.9666e-08 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.9256\n",
            "Epoch 34/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.9077e-08 - accuracy: 1.0000 - val_loss: 0.9945 - val_accuracy: 0.9256\n",
            "Epoch 35/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8536e-08 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.9256\n",
            "Epoch 36/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7933e-08 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.9256\n",
            "Epoch 37/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7608e-08 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.9256\n",
            "Epoch 38/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6852e-08 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.9264\n",
            "Epoch 39/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.6314e-08 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.9256\n",
            "Epoch 40/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5802e-08 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.9256\n",
            "Epoch 41/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5391e-08 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.9264\n",
            "Epoch 42/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4802e-08 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.9264\n",
            "Epoch 43/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4293e-08 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.9256\n",
            "Epoch 44/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3840e-08 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.9256\n",
            "Epoch 45/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3374e-08 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.9256\n",
            "Epoch 46/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2907e-08 - accuracy: 1.0000 - val_loss: 1.0065 - val_accuracy: 0.9256\n",
            "Epoch 47/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2446e-08 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.9256\n",
            "Epoch 48/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2254e-08 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.9256\n",
            "Epoch 49/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1587e-08 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.9256\n",
            "Epoch 50/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.1173e-08 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9256\n",
            "Epoch 51/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0746e-08 - accuracy: 1.0000 - val_loss: 1.0113 - val_accuracy: 0.9256\n",
            "Epoch 52/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0358e-08 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9256\n",
            "Epoch 53/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9964e-08 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.9256\n",
            "Epoch 54/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9557e-08 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.9256\n",
            "Epoch 55/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 1.8998e-08 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.9256\n",
            "Epoch 56/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8644e-08 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.9256\n",
            "Epoch 57/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8299e-08 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.9256\n",
            "Epoch 58/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.7921e-08 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.9256\n",
            "Epoch 59/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.7567e-08 - accuracy: 1.0000 - val_loss: 1.0199 - val_accuracy: 0.9256\n",
            "Epoch 60/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.7394e-08 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.9256\n",
            "Epoch 61/200\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 1.6905e-08 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.9256\n",
            "Epoch 62/200\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 1.6648e-08 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.9264\n",
            "Epoch 63/200\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 1.6287e-08 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.9264\n",
            "Epoch 64/200\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 1.5992e-08 - accuracy: 1.0000 - val_loss: 1.0257 - val_accuracy: 0.9264\n",
            "Epoch 65/200\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 1.5672e-08 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.9264\n",
            "Epoch 66/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.5395e-08 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.9264\n",
            "Epoch 67/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.5131e-08 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.9256\n",
            "Epoch 68/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.4825e-08 - accuracy: 1.0000 - val_loss: 1.0297 - val_accuracy: 0.9256\n",
            "Epoch 69/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.4534e-08 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.9256\n",
            "Epoch 70/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.4331e-08 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.9256\n",
            "Epoch 71/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.4019e-08 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.9256\n",
            "Epoch 72/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.3747e-08 - accuracy: 1.0000 - val_loss: 1.0336 - val_accuracy: 0.9256\n",
            "Epoch 73/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.3516e-08 - accuracy: 1.0000 - val_loss: 1.0348 - val_accuracy: 0.9247\n",
            "Epoch 74/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.3257e-08 - accuracy: 1.0000 - val_loss: 1.0357 - val_accuracy: 0.9247\n",
            "Epoch 75/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.3023e-08 - accuracy: 1.0000 - val_loss: 1.0368 - val_accuracy: 0.9247\n",
            "Epoch 76/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 1.2786e-08 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.9247\n",
            "Epoch 77/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 1.2573e-08 - accuracy: 1.0000 - val_loss: 1.0388 - val_accuracy: 0.9247\n",
            "Epoch 78/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 1.2318e-08 - accuracy: 1.0000 - val_loss: 1.0398 - val_accuracy: 0.9238\n",
            "Epoch 79/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 1.2091e-08 - accuracy: 1.0000 - val_loss: 1.0405 - val_accuracy: 0.9238\n",
            "Epoch 80/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.1875e-08 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.9238\n",
            "Epoch 81/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.1669e-08 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.9238\n",
            "Epoch 82/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.1507e-08 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.9238\n",
            "Epoch 83/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.1260e-08 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.9238\n",
            "Epoch 84/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.1062e-08 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.9238\n",
            "Epoch 85/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.0861e-08 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.9238\n",
            "Epoch 86/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.0672e-08 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.9238\n",
            "Epoch 87/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.0481e-08 - accuracy: 1.0000 - val_loss: 1.0490 - val_accuracy: 0.9238\n",
            "Epoch 88/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.0298e-08 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.9238\n",
            "Epoch 89/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.0104e-08 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.9238\n",
            "Epoch 90/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 9.9281e-09 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.9238\n",
            "Epoch 91/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 9.7662e-09 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.9238\n",
            "Epoch 92/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 9.5905e-09 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.9238\n",
            "Epoch 93/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 9.4305e-09 - accuracy: 1.0000 - val_loss: 1.0551 - val_accuracy: 0.9238\n",
            "Epoch 94/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 9.2652e-09 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.9229\n",
            "Epoch 95/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 9.0988e-09 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.9229\n",
            "Epoch 96/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 8.9545e-09 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.9229\n",
            "Epoch 97/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 8.7925e-09 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.9229\n",
            "Epoch 98/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 8.6281e-09 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.9229\n",
            "Epoch 99/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 8.4819e-09 - accuracy: 1.0000 - val_loss: 1.0607 - val_accuracy: 0.9229\n",
            "Epoch 100/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 8.3594e-09 - accuracy: 1.0000 - val_loss: 1.0621 - val_accuracy: 0.9229\n",
            "Epoch 101/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 8.2183e-09 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.9229\n",
            "Epoch 102/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 8.0842e-09 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.9229\n",
            "Epoch 103/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.9301e-09 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9229\n",
            "Epoch 104/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.8064e-09 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.9229\n",
            "Epoch 105/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.7050e-09 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.9229\n",
            "Epoch 106/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.5627e-09 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.9229\n",
            "Epoch 107/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.4426e-09 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.9229\n",
            "Epoch 108/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.3258e-09 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.9229\n",
            "Epoch 109/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.2135e-09 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.9229\n",
            "Epoch 110/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 7.0976e-09 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.9229\n",
            "Epoch 111/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 6.9705e-09 - accuracy: 1.0000 - val_loss: 1.0729 - val_accuracy: 0.9229\n",
            "Epoch 112/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.8693e-09 - accuracy: 1.0000 - val_loss: 1.0745 - val_accuracy: 0.9221\n",
            "Epoch 113/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.7890e-09 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.9221\n",
            "Epoch 114/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.6479e-09 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.9221\n",
            "Epoch 115/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.5569e-09 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.9221\n",
            "Epoch 116/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.4548e-09 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 0.9221\n",
            "Epoch 117/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.3650e-09 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.9221\n",
            "Epoch 118/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.2676e-09 - accuracy: 1.0000 - val_loss: 1.0808 - val_accuracy: 0.9221\n",
            "Epoch 119/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 6.1695e-09 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.9221\n",
            "Epoch 120/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 6.0580e-09 - accuracy: 1.0000 - val_loss: 1.0823 - val_accuracy: 0.9221\n",
            "Epoch 121/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.9781e-09 - accuracy: 1.0000 - val_loss: 1.0837 - val_accuracy: 0.9221\n",
            "Epoch 122/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.8894e-09 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9221\n",
            "Epoch 123/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 5.7996e-09 - accuracy: 1.0000 - val_loss: 1.0852 - val_accuracy: 0.9221\n",
            "Epoch 124/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.7806e-09 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.9221\n",
            "Epoch 125/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.6198e-09 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.9221\n",
            "Epoch 126/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.5464e-09 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9221\n",
            "Epoch 127/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.5229e-09 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.9221\n",
            "Epoch 128/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.4130e-09 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.9221\n",
            "Epoch 129/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 5.3133e-09 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.9221\n",
            "Epoch 130/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.2491e-09 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.9221\n",
            "Epoch 131/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.2114e-09 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.9221\n",
            "Epoch 132/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.1084e-09 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.9221\n",
            "Epoch 133/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.0492e-09 - accuracy: 1.0000 - val_loss: 1.0960 - val_accuracy: 0.9221\n",
            "Epoch 134/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.9719e-09 - accuracy: 1.0000 - val_loss: 1.0970 - val_accuracy: 0.9221\n",
            "Epoch 135/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.9092e-09 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.9221\n",
            "Epoch 136/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.8499e-09 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.9221\n",
            "Epoch 137/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.7970e-09 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.9212\n",
            "Epoch 138/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.7277e-09 - accuracy: 1.0000 - val_loss: 1.1013 - val_accuracy: 0.9212\n",
            "Epoch 139/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.6767e-09 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.9212\n",
            "Epoch 140/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.5969e-09 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.9212\n",
            "Epoch 141/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.6165e-09 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.9212\n",
            "Epoch 142/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.4792e-09 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.9212\n",
            "Epoch 143/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.4536e-09 - accuracy: 1.0000 - val_loss: 1.1066 - val_accuracy: 0.9212\n",
            "Epoch 144/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.3741e-09 - accuracy: 1.0000 - val_loss: 1.1067 - val_accuracy: 0.9212\n",
            "Epoch 145/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.3459e-09 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.9212\n",
            "Epoch 146/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.2737e-09 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.9212\n",
            "Epoch 147/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.2157e-09 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.9212\n",
            "Epoch 148/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.1772e-09 - accuracy: 1.0000 - val_loss: 1.1115 - val_accuracy: 0.9212\n",
            "Epoch 149/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.1434e-09 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 0.9212\n",
            "Epoch 150/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.0646e-09 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.9212\n",
            "Epoch 151/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.0225e-09 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.9212\n",
            "Epoch 152/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.9933e-09 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.9212\n",
            "Epoch 153/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.9589e-09 - accuracy: 1.0000 - val_loss: 1.1165 - val_accuracy: 0.9212\n",
            "Epoch 154/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.8833e-09 - accuracy: 1.0000 - val_loss: 1.1175 - val_accuracy: 0.9212\n",
            "Epoch 155/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.8581e-09 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.9212\n",
            "Epoch 156/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.8124e-09 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.9212\n",
            "Epoch 157/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.7722e-09 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.9212\n",
            "Epoch 158/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.7217e-09 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.9212\n",
            "Epoch 159/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.6839e-09 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.9212\n",
            "Epoch 160/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.6516e-09 - accuracy: 1.0000 - val_loss: 1.1235 - val_accuracy: 0.9212\n",
            "Epoch 161/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.6109e-09 - accuracy: 1.0000 - val_loss: 1.1244 - val_accuracy: 0.9212\n",
            "Epoch 162/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.5860e-09 - accuracy: 1.0000 - val_loss: 1.1257 - val_accuracy: 0.9212\n",
            "Epoch 163/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.5273e-09 - accuracy: 1.0000 - val_loss: 1.1265 - val_accuracy: 0.9212\n",
            "Epoch 164/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4978e-09 - accuracy: 1.0000 - val_loss: 1.1277 - val_accuracy: 0.9212\n",
            "Epoch 165/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4741e-09 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.9212\n",
            "Epoch 166/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.4133e-09 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.9212\n",
            "Epoch 167/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4267e-09 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.9212\n",
            "Epoch 168/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.3343e-09 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.9212\n",
            "Epoch 169/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.3061e-09 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.9212\n",
            "Epoch 170/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 3.2637e-09 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.9212\n",
            "Epoch 171/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2555e-09 - accuracy: 1.0000 - val_loss: 1.1349 - val_accuracy: 0.9212\n",
            "Epoch 172/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2119e-09 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.9212\n",
            "Epoch 173/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.1869e-09 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.9212\n",
            "Epoch 174/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.1714e-09 - accuracy: 1.0000 - val_loss: 1.1377 - val_accuracy: 0.9212\n",
            "Epoch 175/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.1085e-09 - accuracy: 1.0000 - val_loss: 1.1377 - val_accuracy: 0.9212\n",
            "Epoch 176/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.0969e-09 - accuracy: 1.0000 - val_loss: 1.1396 - val_accuracy: 0.9212\n",
            "Epoch 177/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.0702e-09 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.9212\n",
            "Epoch 178/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.0620e-09 - accuracy: 1.0000 - val_loss: 1.1415 - val_accuracy: 0.9212\n",
            "Epoch 179/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 3.0214e-09 - accuracy: 1.0000 - val_loss: 1.1424 - val_accuracy: 0.9212\n",
            "Epoch 180/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.9899e-09 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.9212\n",
            "Epoch 181/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.9657e-09 - accuracy: 1.0000 - val_loss: 1.1435 - val_accuracy: 0.9212\n",
            "Epoch 182/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.9529e-09 - accuracy: 1.0000 - val_loss: 1.1450 - val_accuracy: 0.9212\n",
            "Epoch 183/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.9111e-09 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.9212\n",
            "Epoch 184/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8903e-09 - accuracy: 1.0000 - val_loss: 1.1466 - val_accuracy: 0.9212\n",
            "Epoch 185/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8813e-09 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.9212\n",
            "Epoch 186/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8442e-09 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9212\n",
            "Epoch 187/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8232e-09 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.9212\n",
            "Epoch 188/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.7964e-09 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.9212\n",
            "Epoch 189/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7813e-09 - accuracy: 1.0000 - val_loss: 1.1513 - val_accuracy: 0.9212\n",
            "Epoch 190/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7555e-09 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.9212\n",
            "Epoch 191/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7227e-09 - accuracy: 1.0000 - val_loss: 1.1529 - val_accuracy: 0.9212\n",
            "Epoch 192/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7175e-09 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.9212\n",
            "Epoch 193/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6745e-09 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.9212\n",
            "Epoch 194/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.9212\n",
            "Epoch 195/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.6492e-09 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.9212\n",
            "Epoch 196/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6323e-09 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.9212\n",
            "Epoch 197/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6011e-09 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.9212\n",
            "Epoch 198/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5888e-09 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.9212\n",
            "Epoch 199/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5588e-09 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.9212\n",
            "Epoch 200/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5551e-09 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.9212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "model.save(\"basic_model\")\n",
        "saved_model = keras.models.load_model(\"basic_model\")"
      ],
      "metadata": {
        "id": "rCRKAKT9oRpN",
        "outputId": "f8a6ffcf-5095-4db0-ba85-d3660f5cf6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag = vectorizer_stop_words_stemmed.transform(X_validation[\"tweet\"])\n",
        "X_Validation_Bag_df = pd.DataFrame(X_Validation_Bag.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())"
      ],
      "metadata": {
        "id": "40thu1nco6Nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14eab99-c833-4a33-b15a-b554d88de5fb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Validation_Bag_df_array = np.asarray(X_Validation_Bag_df)\n",
        "Y_Validation_Predict = saved_model.predict(X_Validation_Bag_df_array)"
      ],
      "metadata": {
        "id": "0Fy5rxxbnw3U",
        "outputId": "abdb5cb6-fbbb-4122-9365-850bd764fcd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Validation_Predict"
      ],
      "metadata": {
        "id": "YpPOc0IL5Wyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformPrediction(df, predNumber, predLabel):\n",
        "  copy = df.copy()\n",
        "  for i in range(len(copy)):\n",
        "    if copy[i][0] > 0.5:\n",
        "      predNumber.append([1])\n",
        "      predLabel.append([\"real\"])\n",
        "    else:\n",
        "      predNumber.append([0])\n",
        "      predLabel.append([\"fake\"])\n"
      ],
      "metadata": {
        "id": "EWu5_-xv-smt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predValidationNumbers = []\n",
        "predValidationLabels = []\n",
        "transformPrediction(Y_Validation_Predict, predValidationNumbers, predValidationLabels)"
      ],
      "metadata": {
        "id": "i1hDHEULlcDX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationNumbers = []\n",
        "validationLabels = []\n",
        "copy = np.asarray(Y_validation).copy()\n",
        "for i in range(len(copy)):\n",
        "  if copy[i] > 0.5:\n",
        "    validationNumbers.append([1])\n",
        "    validationLabels.append([\"real\"])\n",
        "  else:\n",
        "    validationNumbers.append([0])\n",
        "    validationLabels.append([\"fake\"])"
      ],
      "metadata": {
        "id": "ODiTBndqlzWX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(Y_validation)"
      ],
      "metadata": {
        "id": "hnmR9lfkk3J1",
        "outputId": "2181f223-2a8b-4ddc-adb1-cd0ed4af3494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(predValidationLabels,validationLabels))"
      ],
      "metadata": {
        "id": "AhJZ1LxVaC0D",
        "outputId": "32648e5c-cf10-41c4-a4f9-fa209c9dda45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.909250175192712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K fold"
      ],
      "metadata": {
        "id": "lsp7hcI0Xlx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "WBbrhQ1qayX_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "k = 5\n",
        "\n",
        "def k_folds(X, y, k):\n",
        "  assert(len(X) == len(y))\n",
        "  folds_X = []\n",
        "  folds_y = []\n",
        "  initial_pos = 0\n",
        "\n",
        "  for i in range(k):\n",
        "    to_pos = min(math.ceil(len(X)/k)*(i+1), len(X))\n",
        "    \n",
        "    x_fold = X[initial_pos:to_pos]\n",
        "    y_fold = y[initial_pos:to_pos]\n",
        "\n",
        "    folds_X.append(x_fold)\n",
        "    folds_y.append(y_fold)\n",
        "    initial_pos = to_pos\n",
        "\n",
        "  return folds_X, folds_y"
      ],
      "metadata": {
        "id": "Mf9ISG6OXlV_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_to_eval, Y_to_eval):\n",
        "    Y_Prediction = model.predict(np.asarray(X_to_eval))\n",
        "    numbers = []\n",
        "    prediction_labels = []\n",
        "    transformPrediction(Y_Prediction, numbers, prediction_labels)\n",
        "\n",
        "    validationLabels = []\n",
        "    copy = np.asarray(Y_to_eval).copy()\n",
        "    for i in range(len(copy)):\n",
        "      if copy[i] > 0.5:\n",
        "        validationLabels.append([\"real\"])\n",
        "      else:\n",
        "        validationLabels.append([\"fake\"])\n",
        "\n",
        "    return accuracy_score(prediction_labels, validationLabels)"
      ],
      "metadata": {
        "id": "DAADQdFEYKtZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_val(folds_X, folds_y, model):\n",
        "  assert(len(folds_X) == len(folds_y))\n",
        "  X_to_train = []\n",
        "  y_to_train = []\n",
        "  X_to_eval = 0\n",
        "  y_to_eval = 0\n",
        "  scores = []\n",
        "  for i in range(len(folds_X)):\n",
        "    X_to_train = []\n",
        "    y_to_train = []\n",
        "    for j in range(len(folds_X)):\n",
        "      if  i == j:\n",
        "        X_to_eval = folds_X[i]\n",
        "        y_to_eval = folds_y[i]\n",
        "      else:\n",
        "        X_to_train.append(folds_X[j])\n",
        "        y_to_train.append(folds_y[j])\n",
        "    \n",
        "    X_train = np.concatenate(X_to_train)\n",
        "    y_train = np.concatenate(y_to_train)\n",
        "    model.fit(X_train,y_train, epochs=200, batch_size=100, validation_split=0.2)\n",
        "    score = evaluate(model, X_to_eval, y_to_eval)\n",
        "    scores.append(score)\n",
        "  return np.mean(np.array(scores)), scores"
      ],
      "metadata": {
        "id": "iWHnyEvRY_5_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds_X, folds_y = k_folds(np.asarray(bag_of_words), np.asarray(Y_train), 5)\n"
      ],
      "metadata": {
        "id": "iYJyO491ZBgK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean, k_fold_result_arr = k_fold_cross_val(folds_X, folds_y, model)"
      ],
      "metadata": {
        "id": "1lH1Uz4HbMln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHDI7I_deLIG",
        "outputId": "2d6af07d-b834-4312-9f81-c572a19d923a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9601903976312638"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_result_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOadql0keOYu",
        "outputId": "2651c940-c8cc-4e88-e6a0-0964aec6abf8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9194395796847635,\n",
              " 0.9702276707530648,\n",
              " 0.9903677758318739,\n",
              " 0.999124343257443,\n",
              " 0.9217926186291739]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "dQyZTFSjXjir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['id'].astype('str')\n",
        "test['tweet'].astype('str')\n",
        "\n",
        "test_bag = vectorizer_stop_words_stemmed.transform(test[\"tweet\"])\n",
        "test_bag = pd.DataFrame(test_bag.toarray(), columns = vectorizer_stop_words_stemmed.get_feature_names())\n",
        "\n",
        "test_bag_array = np.asarray(test_bag)\n",
        "test_prediction = saved_model.predict(test_bag_array)\n",
        "\n",
        "copy = test_prediction.copy()\n",
        "predNumber = [];\n",
        "predLabel = [];\n",
        "for i in range(len(copy)):\n",
        "  if copy[i][0] > 0.5:\n",
        "    predNumber.append([1])\n",
        "    predLabel.append([\"real\"])\n",
        "  else:\n",
        "    predNumber.append([0])\n",
        "    predLabel.append([\"fake\"])\n",
        "\n",
        "prediction = pd.DataFrame(predLabel, columns=['label'])\n",
        "prediction.index += 1\n",
        "prediction = prediction.to_csv('prediction.csv')"
      ],
      "metadata": {
        "id": "hZMa_5ZcWMWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('prediction.csv')"
      ],
      "metadata": {
        "id": "odAqKelbXH36",
        "outputId": "00458ec1-e224-4c76-cd59-02824c9cced5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d945c047-a51a-4677-9dcd-38afe0cc6a0d\", \"prediction.csv\", 20300)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
